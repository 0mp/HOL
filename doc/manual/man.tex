\documentclass[12pt,fleqn,a4paper]{report}

%\documentstyle[12pt,fleqn,/home/kxs/hol/9.beta.1/Manual/LaTeX/alltt,
%               /home/kxs/hol/9.beta.1/Manual/LaTeX/layout,amssymb]{report}
%\input{/home/kxs/hol/9.beta.1/Manual/LaTeX/commands}

\usepackage{epsfig}
\usepackage{alltt}
\input{../../Manual/LaTeX/commands}

%\newcommand{\eg}       {\mbox{\it e.g.}}
%\newcommand{\ie}       {\mbox{\it i.e.}}
%\newcommand{\etc}      {\mbox{\it etc}}
%\newcommand{\HOL}      {\mbox{\sc hol}}

% \newcommand{\comment}[1]{\marginpar{\tiny \raggedright #1}}
\newcommand{\comment}[1]{}

\newcommand{\inbox}[1]  {\begin{center}
                         \framebox{\parbox{0.984\textwidth}{#1}}
                         \end{center}}
% note on the following newcommands, the mbox command permits their use
% both inside and outside of math mode!

\newcommand{\ident}      {\mbox{\it ident}}
\newcommand{\tactic}      {\mbox{\it tactic}}
\newcommand{\dtype}      {\mbox{\it dtype}}
\newcommand{\clause}      {\mbox{\it clause}}
 \newcommand{\primtactic}      {\mbox{\it primtactic}}
 \newcommand{\numeral}    {\mbox{\it numeral}}
 \newcommand{\charseq}    {\mbox{\it charseq}}
 \newcommand{\vstr}       {\mbox{\it vstr}}
 \newcommand{\type}       {\mbox{\it hol\_type}}
 \newcommand{\term}       {\mbox{\it term}}
 \newcommand{\bs}         {\mbox{$\backslash$}}
 \newcommand{\SUC}       {\mbox{\tt SUC}}
 \newcommand{\CONS}       {\mbox{\tt CONS}}
 \newcommand{\INSERT}    {\mbox{\tt INSERT}}
 \newcommand{\NOT}       {\mbox{\tt ~}}
 \newcommand{\AND}       {\mbox{\tt /\bs}}
 \newcommand{\OR}       {\mbox{\tt \bs/}}
 \newcommand{\IMP}       {\mbox{\tt ==>}}
 %\newcommand{\T}       {\mbox{\tt T}}
 %\newcommand{\F}       {\mbox{\tt F}}
 \newcommand{\LET}       {\mbox{\tt let}}
 \newcommand{\IN}       {\mbox{\tt in}}
 \newcommand{\und}       {\mbox{\tt and}}
 \newcommand{\ALL}       {\mbox{\tt !}}
 \newcommand{\EXISTS}       {\mbox{\tt ?}}
 \newcommand{\EXISTSONE}       {\mbox{\tt ?!}}
 \newcommand{\CHOOSE}       {\mbox{\tt @}}

 %\newcommand{\EQALPHA} {\mbox{$\equiv_\alpha$}}

 \begin{document}

 \title {HOL98 Draft User's Manual \\ Taupo Release \\ Version 1}
 \author{Konrad Slind \\ {\tt kxs@cl.cam.ac.uk} \\
         Cambridge University Computer Laboratory}
 \maketitle

\begin{center}
  \framebox{\parbox{0.9\textwidth}{\textbf{Preliminary Note}
      \textit{It has been decided that the material in this manual
        should be shifted into the traditional manual structure of
        HOL88.  Rather than being maintained, this manual is actually
        being plundered for other documents.  If you have this version
        of the manual, it will have only been released because the
        process of plundering has not yet finished, and it still
        contains useful material.  You should not assume that this
        manual is well-formed.}}}
\end{center}

\section*{Introduction}

 {\bf Hol98} is the latest in a line of verification systems originating
 from the original HOL system \cite{hol88:book}, which was itself
 derived from Edinburgh LCF \cite{lcf:book}. However, Hol98 is a
 definite break with the past: it has been re-designed to address the
 requirements of industrial-scale formal proof in the late 1990s.

 Hol98 provides an extensible set of facilities both for doing
 verification and for writing verification tools. The system contains the
 work of many people, accumulated over decades. (To those who know the
 authorship of the tools, there is a slight flavour of being in a
 museum.) As a result, Hol98 offers many ways to achieve a given task;
 this is understandable---but tremendously frustrating for beginners.
 The point of this document therefore, is to give a brief survey of the
 important facilities available in Hol98; we will give only the `big
 picture', along with some hints for deeper exploration. The reader who
 completes the document should have an idea of how to formalize and prove
 simple things in Hol98, as well as an idea of how to go about extending
 the system to his or her own purposes.

  We proceed as follows. In Chapter One, we give a quick lesson on how
 to start Hol98.  In Chapter Two, the syntax of HOL (higher-order logic,
 the logic that Hol98 implements) is described. The basic methods of
 proof that the system provides are surveyed in Chapter Three. In
 Chapter Four, brief summaries of the available theories and libraries
 are given. In Chapter Five, we describe the means by which users can
 build and maintain their own logical objects. In Chapter Six we discuss
 a package for high-level interactive proof. Some medium-length
 examples are the subject of Chapter Seven (at present we have only a
 detailed proof of Euclid's theorem to offer).  Chapter Eight (currently
 absent) contains listings of the most important parts of the
 programmer's interface.

% Those readers interested in a formal description of the HOL
% logic---which was written by Mike Gordon and Andrew Pitts---are invited
% to read Appendices A and B, which have been taken from
% \cite{hol88:book}.

SML'97 \cite{SML97} plays the role of a {\it programming metalanguage\/}
 in which the HOL logic is defined. Currently, the implementation is in
 MoscowML,\footnote{\tt
 http://www.dina.kvl.dk/\~{}sestoft/mosml.html}
 an implementation of a subset of SML'97.  Thus Hol98 comprises a number
 of ML\footnote{We will use ML and SML as synonyms for SML'97.}
 modules. There are two main ways to utilize these modules: they can be
 used during an interactive proof effort; or they can be used as
 libraries in the writing of custom proof tools.  Both usages require
 some knowledge of ML, the former much less than the latter. We shall
 assume that the reader knows some Standard ML. Several good texts on
 SML already exist; the ones by Paulson \cite{lcp:ml} and Ullman
 \cite{ullman:mlbook} have been updated for SML'97.

 Finally, you will find that this user's manual is filled with
 gaps. There are many positive ways to deal with these, among them being
 (1) asking a guru, either locally or on the \verb+info-hol+ mailing
 list, (2) attempting to extrapolate the relevant information from
 \cite{hol88:book} (which should in any case be used as a background
 reference to the often facile treatments given here), or (3) diving
 into the sources, which is the path to guruhood.

\subsection*{Acknowledgements}

As mentioned, Hol98 can be regarded as a conglomeration and synthesis of
the work of many people over a long period of time. We shall refrain
from an exhaustive listing of authorship (in this draft) since we would
not like to omit anyone! Therefore, we limit ourselves to the much
smaller set of people who directly contributed to this release.  Mike
Gordon had the initial idea for tagged inference and pointed out that
tags should be abstract. Ken Larsen got us started on using MoscowML,
and made the initial port of many of the core libraries. He also
implemented \verb+Holmake+. Mark Staples developed the PVS
\verb+autopilot+ example. Michael Norrish wrote and documented the
\verb+RecordType+ package, and served some hard time consulting on the
syntactical perversities of various Unix shells. Finally, Peter Sestoft,
the main developer of MoscowML, has been very responsive to our requests
for changes to his compiler.

\subsection*{Acknowledgements for the Athabasca 2 release}

Joe Hurd ported John Harrison's development of the real numbers and
analysis, including a decision procedure. Graham Collins donated his
theory of finite maps. Ken Larsen and Mike Gordon ported Jorn Lind's
BuDDy package (\verb+http://britta.it.dtu.dk/~jl/buddy+) to MoscowML and
integrated it with Hol98. Norbert Voelker and Louise Dennis spotted some
installation problems, one of which Michael Norrish fixed.


\tableofcontents

\chapter{Getting Started}

 Starting up Hol98 is straightforward:
 \begin{verbatim}
     <hol-dir>/bin/hol a0 ... an
 \end{verbatim}
 where an argument $a_i$ to the invocation can be either (1) a path
 (prefixed by~\verb+-I+) where the system can find code or, (2) a file to
 execute before turning control over to the user. For example, invoking
 \begin{verbatim}
     <hol-dir>/bin/hol  -I /local/foo  /home/me/my-hol-init.sml
 \end{verbatim}
 will do the following:
 \begin{itemize}
 \item The path \verb+/local/foo+ is added to the pre-existing path. If
    the user later asks for a module \verb+X+ to be loaded, the system
    will first look in each directory on the pre-existing path before
    looking in \verb+/local/foo+ for \verb+X+. Usually, no paths need be
    added to the system path.

  \item The ML file \verb+/home/me/my-hol-init.sml+ will be executed.
    The order of execution of start-up files is left-to-right. There
    is a system start-up file that gets executed before any user-given
    ones: it can be found in the file \verb+std.prelude+ in the top
    level of the Hol98 distribution directory. The code in
    \verb+std.prelude+ will load and open some standard basic support
    (tactics, conversions, simple definition principles) and set up
    the paths to all the system libraries.
 \end{itemize}

 As usual, at least in Unix systems, Hol98 can be exited by entering
 \verb+^D+. Invoking \verb+quit();+ will serve the same purpose.

\section{Help}
 There are several kinds of help available in Hol98, all accessible
 through the same incantation:
 \begin{verbatim}
     help <string>;
 \end{verbatim}

 The kinds of help available are:

 \begin{description}

 \item [MoscowML help.] This is uniformly excellent. Information for
   library routines is available, whether the library is loaded or not
   via \verb+help "Lib"+.

\item [HOL overview.] This is a short summary of important information
  about Hol98.

\item [HOL help.] This is the on-line help from Hol88 and Hol90, and
  is intended to document all HOL-specific functions available to the
  user. It is very detailed and often accurate; however, it can be
  out-of-date, refer to HOL90 or HOL88, or even be missing!

\item [HOL structure information.]  For most structures in the Hol98
  source, one can get a listing of the entrypoints found in the
  accompanying signature. This is helpful for locating functions and
  is automatically derived from the system sources, so it is alway
  up-to-date.

\item [Theory facts.] These are automatically derived from theory
  files, so they are always up-to-date. The signature of each theory
  is available (since theories are represented by structures in
  Hol98). Also, each axiom, definition, and theorem in the theory can
  be accessed by name in the help system; the theorem itself is given.
 \end{description}

 Therefore the following example queries can be made:

 \begin{table}[h]
\begin{center}
 \begin{tabular}{|l|l|} \hline
  \verb+help "installPP"+ & Moscow ML help \\
  \verb+help "hol"+ &  Hol98 overview \\
  \verb+help "aconv"+ &  on-line HOL help \\
  \verb+help "Tactic"+ & HOL source structure information \\
  \verb+help "boolTheory"+ &  theory structure signature \\
  \verb+help "list_Axiom"+ & theory structure signature and theorem
 statement \\ \hline
 \end{tabular}
\end{center}
 \end{table}

\section{Input and Output}

A person usually works with Hol98  by interacting with the ML top level
loop\footnote{So far, that is; one of the intended applications of Hol98
is for building batch theorem proving tools.} in order to build
formalizations and perform proofs. In this setting, the user often needs
to enter expressions of the HOL logic to ML, and interpret the resulting
responses. Since the ML representations of the types, terms, and
theorems of the HOL logic are quite unreadable in their `raw' form,
so-called {\it prettyprinters\/} for HOL logic expressions are
automatically invoked by the ML top level when printing output.

Similarly, types and terms often have to be constructed by the user,
\eg, in order to make definitions, state goals to prove, provide
existential witnesses, \etc\ Since it would be unbearable to make a type
or term of any size `by hand', the system comes equipped with parsers
for type and term expressions. The parser for types is called
\verb+Type+, and the parser for terms is called \verb+Term+. These
parsers take {\it quotations\/}.  A quotation {\tt `}$\ldots$ {\tt `} is
much like an SML string, except that it can span several lines without
requiring awkward backslashes, as an ML string
would.\footnote{Quotations were a feature in the original LCF
system. See the MoscowML User's Manual for more information.}

\subsection{Quotation preprocessing}

For convenience, the Athabasca release supplies a version of Hol98 that
features a {\it combined parser\/} that accepts both types and
terms. Enclosing some object language concrete syntax between
occurrences of \verb+``+ will result in the correct parser being
invoked. For example

\begin{verbatim}
    ``x /\ y /\ z ==> ?p. p``
\end{verbatim}

\noindent will parse as a term while

\begin{verbatim}
    ``:'a -> ('b -> 'h) -> bool``
\end{verbatim}

\noindent parses as an HOL type. Note that the concrete syntax given in
the quotation needs to provide a hint: the type parser will only be
called if the first character after the leading {\tt ``} is a colon (\verb+:+).

Knowledgable ML users will notice that the idiom {\tt ``}$\ldots$ {\tt
  ``} is not ML-typable; it is implemented as a pre-processor to ML,
thanks to work by Richard Boulton. Preprocessing is not the default in
this release. Users who wish to use the pre-processor should use {\tt
  <hol-dir>/bin/hol.unquote}.

\section{First proof}

In this section we show a simple goal being stated and solved in
Hol98. Full explanations of what is going on can be found in the rest of
this document, but we needn't wait to exercise the system.

First, we start up the system. The start-up phase executes a standard
prelude. (System responses occur on lines starting with \verb+>+.)

\begin{alltt}

     bash\$ /home/kxs/hol98/bin/hol

>    Enter `quit();' to quit.
>    For HOL help, type: help "hol";
>
>
>        HHH                 LL
>        HHH                  LL
>        HHH                   LL
>        HHH                    LL
>        HHH          OOOO       LL
>        HHHHHHH     OO  OO       LL
>        HHHHHHH     OO  OO       LLL
>        HHH          OOOO        LLLL
>        HHH                     LL  LL
>        HHH                    LL    LL
>        HHH                   LL      LL
>        HHH                  LL        LL98 [Athabasca 2]
>
>    [closing file "/home/kxs/hol98/std.prelude"]

\end{alltt}

Now we load an automatic first order reasoner, written by John
Harrison (and ported by Michael Norrish from Harrison's HOL-Light
system).\footnote{One might think that this sort of tool should
  already be ``part of'' Hol98; however, all of the reasoners of Hol98
  are in external libraries. This is a consequence of a fundamental
  design tenet for LCF-style systems: keep a very simple kernel to the
  implementation, and add libraries on top.}
\begin{verbatim}
    - load"mesonLib";
    > val it = () : unit
\end{verbatim}

Now we will set a goal for the reasoner to prove. In mathematical
notation, it is

\[\forall R.\ (\forall x.\  \exists y.\ R\ x\ y) = \exists f.\ \forall
 x.\ R\ x\ (f\ x).\]

 This theorem is the justification of Skolemization. It says that
every $x$ is related to a $y$ by $R$ if and only if there is
a function $f$ mapping each $x$ to its corresponding $y$. In Hol98
notation, we have:
\begin{verbatim}
    - set_goal([], Term `!R. (!x. ?y. R x y) = ?f. !x. R x (f x)`);
>   <<HOL message: inventing new type variable names: 'a, 'b.>>
>   val it =
>      Proof manager status: 1 proof.
>      1. Incomplete:
>            Initial goal:
>            ``!R. (!x. ?y. R x y) = (?f. !x. R x (f x))``
\end{verbatim}

Now we apply the reasoner to the goal with the \verb+e+ command. It says
``OK..'' and sets to work. As it searches for a proof, it prints out a
row of dots. The proof is found in about a third of a second, and
consists of 615 inference steps in the HOL logic.
\begin{verbatim}
    - e (mesonLib.MESON_TAC[]);
>   OK..
>   Meson search level: ....
>   val it =
>       Initial goal proved.
>       |- !R. (!x. ?y. R x y) = (?f. !x. R x (f x))
\end{verbatim}

Now we can extract the proved theorem, and
bind it to a name in ML.
\begin{verbatim}
    - val Skolem = top_thm();
>   val Skolem = |- !R. (!x. ?y. R x y) = (?f. !x. R x (f x)) : Thm.thm
\end{verbatim}


\chapter{Syntax}

The HOL logic is a classical higher-order predicate calculus. Its
syntax enjoys two main differences from the syntax of standard first
order logic.\footnote{We assume the reader is familiar with first
  order logic.}  First, there is no distinction in HOL between terms
and formulas: HOL has only terms. Second, each term has a type: types
are used in order to build well-formed terms. There are two ways to
construct types and terms in HOL: by use of a parser, or by use of the
programmer's interface. In this chapter, we will focus on the concrete
syntax accepted by the parsers, leaving the programmer's interface for
Chapter~\ref{api}.


\section{Types}

A HOL type can be a variable, a constant, or a compound type, which is
a constant of arity $n$ applied to a list of $n$ types.
\[
\begin{array}{rclr}
  \type & ::= & \mbox{\bf '}\ident & \mbox{(type variable)} \\
  & | &  \verb+bool+ & \mbox{(type of truth values)} \\
  & | &  \verb+ind+ & \mbox{(type of individuals)} \\
  & | &  \type\ \verb+->+\ \type & \mbox{(function arrow)} \\
  & | &  \type\ \ident\ \type\ & \mbox{(binary compound type)}\\
  & | &  \ident & \mbox{(nullary type constant)} \\
  & | & \type\; \ident & \mbox{(unary compound type)} \\
  & | & (\type_1,\ldots,\type_n) \ident & \mbox{(compound type)}
\end{array}
\]
Type constants are also known as type operators. They must be
alphanumeric. Type variables are alphanumerics written with a leading
prime ('). In Hol98, the type constants {\tt bool}, {\tt fun}, and
{\tt ind} are primitive. The introduction of new type constants is
described in Chapter \ref{thy-ops}. {\tt bool} is the two element type
of truth values. The binary operator {\tt fun} is used to denote
function types; it can be written with an infix arrow. The nullary
type constant {\tt ind} denotes an infinite set of individuals; it is
used for a few highly technical developments in the system and can be
ignored by beginners.  Thus
\begin{verbatim}
     'a -> 'b
     (bool -> 'a) -> ind
\end{verbatim}
are both well-formed types. The function arrow is "right associative",
which means that ambiguous uses of the arrow in types are resolved by
adding parentheses in a right-to-left sweep: thus the type expression
\begin{verbatim}
     ind -> ind -> ind -> ind
\end{verbatim}
is identical to
\begin{verbatim}
     ind -> (ind -> (ind -> ind)).
\end{verbatim}
The product (\verb+#+) and sum (\verb!+!) are other infix type
operators, also right associative; however, they are not loaded by
default in Hol98. How to load in useful logical context is dealt with
in Chapter~\ref{context}.

\section{Terms}

Ultimately, a HOL term can only be a variable, a constant, an
application, or a lambda term.
\[
\begin{array}{rclr}
  \term & ::= & \ident & \mbox{(variable or constant)} \\
  & | &  \term\  \term & \mbox{(combination)} \\
  & | &  \bs\ident.\  \term &
  \mbox{(lambda abstraction)}
\end{array}
\]
In the system, the usual logical operators have already been defined,
including truth (\verb+T+), falsity (\verb+F+), negation (\verb+~+),
equality (\verb+=+), conjunction (\verb+/\+), disjunction (\verb+\/+),
implication (\verb+==>+), universal (\verb+!+) and existential
(\verb+?+) quantification, and an indefinite description operator
(\verb+@+). As well, the basis includes conditional, lambda, and `let'
expressions. Thus the set of terms available is, in general, an
extension of the following grammar:
\[
\begin{array}{rclr}
  \mbox{\it term} & ::= & \term : \type & \mbox{(type constraint)} \\
  & | & \term\ \term & \mbox{(application)} \\
  & | & \verb+~+ \term & \mbox{(negation)} \\
  & | & \term\ =\ \term & \mbox{(equality)} \\
  & | & \term\ \IMP\ \term & \mbox{(implication)} \\
  & | & \term\ \verb+\/+\ \term & \mbox{(disjunction)} \\
  & | & \term\ \verb+/\+\ \term & \mbox{(conjunction)} \\
  & | & \texttt{if}\ \term\ \texttt{then}\ \term\ \texttt{else}\ \term &
  \mbox{(conditional)} \\
  & | & \bs\ident_1\ldots\ident_n.\  \term & \mbox{(lambda abstraction)} \\
  & | & \ALL \ident_1\ldots\ident_n.\ \term & \mbox{(forall)} \\
  & | & \EXISTS \ident_1\ldots\ident_n.\ \term & \mbox{(exists)} \\
  & | & \CHOOSE \ident_1\ldots\ident_n.\ \term & \mbox{(choose)} \\
  & | & \EXISTSONE \ident_1\ldots\ident_n.\ \term &\mbox{(exists-unique)} \\
  & | & \LET\; \ident = \term  & \\
  &   & [\und\ \ident = \term]^{*}\ \IN\ \term & \mbox{(let expression)} \\
  & | & \verb+T+ & \mbox{(truth)} \\
  & | & \verb+F+ & \mbox{(falsity)} \\
  & | & \ident & \mbox{(constant or variable)} \\
  & | & \verb+(+ \term \verb+)+ & \mbox{(parenthesized term)}
\end{array}
\]

Some examples may be found in Table \ref{syntaxExamples}. Term
application can be iterated. Application is left associative so that
$\term\ \term\ \term \ldots \term$ is equivalent in the eyes of the
parser to $(\ldots((\term\ \term)\ \term) \ldots)\ \term$.

The lexical structure for term identifiers is much like that for
ML: identifiers can be alphanumeric or symbolic. Variables must be
alphanumeric. A symbolic identifier is any concatenation of the characters
in the following list:
\begin{verbatim}
    #?+*/\\=<>&%@!,:;_|~-
\end{verbatim}
with the exception of the keywords \verb+\\+, \verb+;+, \verb+=>+,
\verb+|+, and \verb+:+ (colon). Any alphanumeric can be a constant except the
keywords \verb+let+, \verb+in+, \verb+and+, and \verb+of+.

 \begin{table}[h]
\begin{center}
 \begin{tabular}{|r|l|} \hline
 \verb+x = T+ & {\it x is equal to true.} \\
 \verb+!x. Person x ==> Mortal x+ & {\it All persons are mortal.} \\
 \verb+!x y z. (x ==> y) /\ (y ==> z) ==> x ==> z+ & {\it Implication is
 transitive.} \\
 \verb+!x. P x ==> Q x+ & {\it P is a subset of Q} \\
 \verb+S = \f g x. f x (g x)+ & {\it Definition of a famous combinator.} \\ \hline
 \end{tabular}
 \caption{Concrete Syntax Examples}\label{syntaxExamples}
\end{center}
 \end{table}


\subsection{Constants}

The HOL grammar gets extended when a new constant is introduced. The
introduction of new constants will be discussed in section
\ref{thy-ops}. In order to provide some notational flexibility,
constants come in various flavours or {\it fixities}: besides being an
ordinary constant (with a fixity of {\sf Prefix}), constants can also
be {\it binders}, {\it true prefixes}\footnote{The use of the term
  ``true prefix'' is forced upon us by the history of the system,
  which reserved the classification ``prefix'' for terms without any
  special syntactic features.}, {\it suffixes}, {\it infixes}, or {\it
  closefixes}.  More generally, terms can also be represented using
reasonably arbitrary {\it mixfix} specifications.  The degree to which
terms bind their associated arguments is known as precedence.  The
higher this number, the tighter the binding.  For example, when
introduced, \verb-+- has a precedence of 500, while the tighter
binding multiplication (\verb+*+) has a precedence of 600.

\subsubsection{Binders}

A binder is a construct that binds a variable; for example, the
universal quantifier. In HOL, this is represented using a trick that
goes back to Alonzo Church: a binder is a constant that takes a lambda
abstraction as its argument. The lambda binding is used to implement
the binding of the construct. This is an elegant and uniform solution.
Thus the concrete syntax \verb+!v. M+ is represented by the
application of the constant \verb+!+ to the abstraction \verb+(\v. M)+.

The most common binders are \verb+!+, \verb+?+, \verb+?!+, and
\verb+@+. Sometimes one wants to iterate applications of the same
binder, \eg,
\begin{alltt}
  !x. !y. ?p. ?q. ?r. \term.
\end{alltt}
This can instead be rendered
\begin{alltt}
  !x y. ?p q r. \term.
\end{alltt}

\subsubsection{Infixes}

Infix constants can associate in one of three different ways: right,
left or not at all.  (If \verb-+- were non-associative, then {\tt 3 +
  4 + 5} would fail to parse; one would have to write {\tt (3 + 4) +
  5} or {\tt 3 + (4 + 5)} depending on the desired meaning).  The
precedence ordering for the initial set of infixes is \verb+/\+,
\verb+\/+, \verb+==>+, \verb+=+,
 \begin{Large}\verb+,+\end{Large} (comma\footnote{When {\tt pairTheory} has
   been loaded.}). Moreover, all of these constants are right
 associative. Thus
\begin{verbatim}
     X /\ Y ==> C \/ D, P = E, Q
\end{verbatim}
 is equal to
\begin{verbatim}
     ((X /\ Y) ==> (C \/ D)), ((P = E), Q).
\end{verbatim}

\noindent An expression \[\term\ \verb+<infix>+\ \term\] is internally
represented as \[((\verb+<infix>+\ \term)\ \term)\].

\subsubsection{True prefixes}

Where infixes appear between their arguments, true prefixes appear
before theirs.  This might initially appear to be the same thing as
happens with normal function application (is $f$ in $f(x)$ not acting
as a prefix?), but in fact, it is useful to allow for prefixes to have
binding power less than that associated with function application.  An
example of this is \verb+~+, logical negation.  This is a prefix with
lower precedence than function application.  Normally
\[
   f\;x\; y\qquad \mbox{is parsed as}\qquad (f\; x)\; y
\] but \[
  \mbox{\tt \~{}}\; x\; y\qquad\mbox{is parsed as}\qquad
  \mbox{\tt \~{}}\; (x\; y)
\] because the precedence of \verb+~+ is lower than that of function
application.  The unary negation symbol would also typically be
defined as a true prefix, if only to allow one to write \[ {\it
  negop}\,{\it negop}\,3
\] (whatever {\it negop} happened to be) without needing extra parentheses.

\subsubsection{Suffixes}

Suffixes appear after their arguments.  There are no suffixes
introduced into the standard theories available in HOL, but users are
always able to introduce their own if they choose.  Suffixes are
associated with a precedence just as infixes and true prefixes are.
If \verb+p+ is a true prefix, \verb+i+ an infix, and \verb+s+ a
suffix, then there are six possible orderings for the three different
operators based on their precedences, giving five parses for
$\verb+p+\; t_1\; \verb+i+\; t_2\; \verb+s+$ depending on the relative
precedences:
\[
\begin{array}{cl}
\mbox{\begin{tabular}{c}Precedences\\(lowest to highest)\end{tabular}} &
\multicolumn{1}{c}{\mbox{Parses}}\\
\hline
p,\;i,\;s & \verb+p+\;(t_1\;\verb+i+\;(t_2\;\verb+s+))\\
p,\;s,\;i & \verb+p+\;((t_1\;\verb+i+\;t_2)\;\verb+s+)\\
i,\;p,\;s & (\verb+p+\;t_1)\;\verb+i+\;(t_2\;\verb+s+)\\
i,\;s,\;p & (\verb+p+\;t_1)\;\verb+i+\;(t_2\;\verb+s+)\\
s,\;p,\;i & (\verb+p+\;(t_1\;\verb+i+\;t_2))\;\verb+s+\\
s,\;i,\;p & ((\verb+p+\;t_1)\;\verb+i+\;t_2)\;\verb+s+\\
\end{array}
\]

\subsection{Type constraints}

A term can be constrained to be of a certain type.  For example,
\verb+X:bool+ constrains the variable \verb+X+ to have type
\verb+bool+. Similarly, \verb+T:bool+ performs a (vacuous) constraint
of the constant \verb+T+ to \verb+bool+. An attempt to constrain a
term inappropriately will raise an exception: for example,
\begin{verbatim}
  if T then (X:ind) else (Y:bool)
\end{verbatim}
will fail because both branches of a conditional must be of the same
type.  Type constraints can be seen as a suffix that binds more
tightly than everything except function application.  Thus $\term\
\ldots\ \term \ : \type$ is equal to $(\term\ \ldots\ \term)\ :
\type$, but $x < y:\mbox{\tt num}$ is a legitimate (though, again
redundant) constraint on just the variable $y$.

The inclusion of \verb+:+ in the symbolic identifiers means that some
constraints may need to be separated by white space. For example,
\begin{verbatim}
    $=:bool->bool->bool
\end{verbatim}
will be broken up by the HOL lexer as
\begin{verbatim}
    $=: bool -> bool -> bool
\end{verbatim}
and parsed as an application of the symbolic identifier \verb+$=:+ to
the argument list of terms [\verb+bool+, \verb+->+, \verb+bool+,
\verb+->+, \verb+bool+]. A well-placed space will avoid this problem:
\begin{verbatim}
    $= :bool->bool->bool
\end{verbatim}
is parsed as the symbolic identifier "=" constrained by a type.

\subsubsection{Closefixes}

Closefix terms are operators that completely enclose their arguments.
An example one might use in the development of a theory of
denotational semantics is semantic brackets.  Thus, the HOL parsing
facilities can be configured to allow one to write \texttt{denotation x}
as \texttt{[| x |]}.  Closefixes are not associated with precedences
because they can not compete for arguments with other operators.

\subsubsection{Type inference}

Consider the term \verb+x = T+.  Each term (and all of its subterms),
has a type in the HOL logic. Now, \verb+T+ has type \verb+bool+. This
means that the constant \verb+=+ has type \verb+xty -> bool -> bool+,
for some type \verb+xty+. Since the type scheme for \verb+=+ is
\verb+'a -> 'a -> bool+, we know that \verb+xty+ must in fact be
\verb+bool+ in order for the type instance to be well-formed. Knowing
this, we can deduce that the type of `x' must be \verb+bool+.

Ignoring the jargon ("scheme" and "instance") in the previous
paragraph, we have conducted a type assignment to the term structure,
ending up with a well-typed term. It would be very tedious for users
to conduct such argumentation by hand for each term entered to Hol98.
Thus, Hol98 uses an adaptation of Milner's type inference algorithm
for ML when constructing terms via parsing. At the end of type
inference, unconstrained type variables get assigned by the system.
Usually, this assignment does the right thing. However, at times, the
most general type is not what is desired and the user must add type
constraints to the relevant subterms. For tricky situations, the
global variable \verb+show_types+ can be assigned. When this flag is
set, the prettyprinters for terms and theorems will show how types
have been assigned to subterms. If you do not want the system to
assign type variables for you, the global variable
\verb+guessing_tyvars+ can be set to \verb+false+, in which case the
existence of unassigned type variables at the end of type inference
will raise an exception.

\subsection{Expanded term grammar}

There is some further syntax that is specially treated by the parser.
The theory of pairs introduces the infix pairing operator
(\begin{Large}\verb+,+\end{Large}) as well as the corresponding infix
product (\verb+#+) type operator. The theory of sets introduces
notation for the empty set \verb+{}+ (or \verb+EMPTY+), membership
(the infix \verb+IN+) insertion (the infix \verb+INSERT+), set
comprehension, enumerated sets, and many other defined constants. The
theory of lists introduces the constants \verb+NIL+ (the surface
syntax \verb+[]+ can be used) and \verb+CONS+, as well as notation for
enumerated lists. The theories of (Peano) numbers and strings
introduce the constructors \verb+0+, \verb+SUC+, \verb+""+, and
\verb+STRING+, as well as literals for numbers and strings. If the
theory of restricted quantifiers is present, syntax is provided for
constraining bound variables by predicates.

Thus, if the theories of pairs, sets, numbers, strings, lists, and
restricted quantifiers are loaded, the HOL grammar is an extension of
that in Table \ref{expanded-grammar}.
\begin{table}
  \[
  \begin{array}{rclr}
    \term & ::= & \term : \type & \mbox{(type constraint)} \\
    & | & \term\ \term & \mbox{(application)} \\
    & | & \CONS\ \term \ \term & \mbox{(list builder)} \\
    & | & \INSERT\ \term \ \term & \mbox{(set builder)} \\
    & | & \SUC\ \term & \mbox{(successor)} \\
    & | & \verb+~+ \term & \mbox{(negation)} \\
    & | & \term\ =\ \term & \mbox{(equality)} \\
    & | & \term\ \IMP\ \term & \mbox{(implication)} \\
    & | & \term\ \verb+\/+\ \term & \mbox{(disjunction)} \\
    & | & \term\ \verb+/\+\ \term & \mbox{(conjunction)} \\
    & | & \term\ \verb+<+ \ \term & \mbox{(less-than)} \\
    & | & \term\ \verb!+! \ \term & \mbox{(addition)} \\
    & | & \term\ \verb!*! \ \term & \mbox{(multiplication)} \\
    & | & \term\ \verb!-! \ \term & \mbox{(subtraction)} \\
    & | & \term\ \verb+=>+\ \term\ |\ \term & \mbox{(conditional)} \\
    & | & \bs\vstr_1\ldots\vstr_n.\ \term & \mbox{(lambda abstraction)} \\
    & | & \ALL \vstr_1\ldots\vstr_n.\ \term & \mbox{(forall)} \\
    & | & \EXISTS \vstr_1\ldots\vstr_n.\ \term & \mbox{(exists)} \\
    & | & \CHOOSE \vstr_1\ldots\vstr_n.\ \term & \mbox{(choose)} \\
    & | & \EXISTSONE \vstr_1\ldots\vstr_n.\ \term &\mbox{(exists-unique)} \\
    & | & \LET\; \vstr = \term  & \\
    &   & [\und\ \vstr = \term]^{*}\ \IN\ \term & \mbox{(let expression)} \\
    & | & \verb+T+ & \mbox{(truth)} \\
    & | & \verb+F+ & \mbox{(falsity)} \\
    & | & \verb+[]+ & \mbox{(empty list)} \\
    & | & \verb+{}+ & \mbox{(empty set)} \\
    & | & \verb+(+ \term \verb+,+ \term \verb+)+ & \mbox{(pair)} \\
    & | & \ident & \mbox{(constant or variable)} \\
    & | & \numeral & \mbox{(numeric literal)} \\
    & | & \verb+"+\charseq \verb+"+& \mbox{(string literal)} \\
    & | & \verb+(+ \term \verb+)+ & \mbox{(parenthesized term)} \\
    & | & \verb+[+ \term \verb+;+ \ldots \verb+;+ \term \verb+]+ &
    \mbox{(enumerated list)} \\
    & | & \verb+{+ \term \verb+;+ \ldots \verb+;+ \term \verb+}+ &
    \mbox{(enumerated set)} \\
    & | & \verb+{+ \term \ \verb+|+\  \term \verb+}+ & \mbox{(set comprehension)}
  \end{array}
  \]
  \caption{Expanded Term Grammar} \label{expanded-grammar}
\end{table}

In the table, the varstruct ({\it vstr\/}) construct is used. A
varstruct is (apparently) an arbitrarily nested tuple of variables,
where each variable only occurs once. The translation of varstructs
into the internal abstract syntax trees is complex, so we avoid the
explanation (for this draft).
\[
\begin{array}{rcl}
  \vstr & ::= & \ident : \type \\
  & | & \ident  \\
  & | & \vstr \verb+,+ \vstr \\
  & | & \verb+(+ \vstr \verb+)+\\
  & | & \verb+(+\vstr {\tt ::} \term\verb+)+\\
\end{array}
\] The {\tt ::} syntax is used with restricted quantifiers to allow
arbitrary predicates to restrict binding variables.  Further to the
above, the default grammar also allows restricted quantification of
all of a sequence of binding variables by putting the restriction at
the end of the sequence, thus with a universal quantification: \[
\forall x \, y \, z \, {\tt ::} \; P \, . \; Q(x,y,z)
\] Here the predicate $P$ restricts all of $x$, $y$ and $z$.

Also, in the term grammar a \charseq\ is just a finite sequence of
characters.


\section{Changes from older versions}

This section of the manual documents the (extensive) changes made to
the parsing of HOL terms and types in the Taupo release and beyond
from the point of view of a user who doesn't want to know how to use
the new facilities, but wants to make sure that their old code
continues to work cleanly.

The changes which may cause old terms to fail to parse are:
\begin{itemize}
\newcommand\condexp{\mbox{$p \; {\tt =>} \; q \; {\tt |} \; r$}}
\item The precedence of type annotations has completely changed.  It
  is now a very tight suffix (though with a precedence weaker than
  that associated with function application), instead of a weak one.
  This means that \mbox{\tt (x,y:bool \# bool)} should now be written
  as \mbox{\tt (x,y):bool \# bool}. The previous form will now be
  parsed as a type annotation applying to just the \verb+y+.  This
  change brings the syntax of the logic closer to that of SML and
  should make it generally easier to annotate tuples, as one can now
  write \[ (x\,:\,\tau_1,\;y\,:\,\tau_2,\dots z\,:\,\tau_n)
  \] instead of \[
  (x\,:\,\tau_1, \;(y\,:\,\tau_2, \dots (z\,:\,\tau_n)))
  \] where extra parentheses have had to be added just to allow one to
  write a frequently occurring form of constraint.
\item Most arithmetic operators are now left associative instead of
  right associative.  In particular, $+$, $-$, $*$ and {\tt DIV} are
  all left associative.  Similarly, the analogous operators in other
  numeric theories such as {\tt integer} and {\tt real} are also left
  associative.  This brings the HOL parser in line with standard
  mathematical practice.
\item The binding equality in {\tt let} expressions is treated exactly
  the same way as equalities in other contexts.  In previous versions
  of HOL, equalities in this context have a different, weak binding
  precedence.  This difference can be seen in the following expression
  which parses successfully in the old version:
  \[ {\tt let} \; x \; = \; \condexp \; {\tt
  in} \;Q \] In Taupo releases and later, this expression will not
  parse because the conditional expression binds to the left more
  weakly than the equality binds to the right, and the parser ends up
  believing that the binding between the \verb+let+ and the \verb+in+
  is not an equality after all, as it should be.
\item Old style conditional expressions in the right half of set
  comprehensions have to be parenthesised to avoid confusing the
  parser.  Thus \[
  \{ \; x \; | \; \condexp \; \}
   \qquad\mbox{must be written} \qquad
  \{ \; x \; | \; (\condexp) \; \}
  \] Better yet, {\tt if}-{\tt then}-{\tt else} syntax could be used
  for the conditional expression.
\item Some lexical categories are more strictly policed.  String
  literals (strings inside double quotes) and numerals can't be used
  unless the relevant theories have been loaded.  Nor can these
  literals be used as variables inside binding scopes.
\end{itemize}

\subsection{Error messages}

When complete this subsection will document all of the possibly
confusing error messages that the new parser and lexing code might
generate.

\chapter{Proof}

 Hol98 provides various mechanisms for doing proof. The user can invoke
 proof steps at very low levels of abstraction (something like doing
 assembly programming) or use sophisticated proof procedures that may
 perform tens or hundreds of thousands of inference steps in a single
 invocation. We give an overview of the different means by which proof
 can be performed in Hol98. First, the various kinds of proof procedures
 provided will be covered. Then we discuss the available definition
 principles of the system, and finallly, we go on to describe the
 standard Hol98 proof manager.

\section{Rules of inference}

 Hol98 follows the LCF tradition of implementing the primitive inference
 rules of the HOL logic as constructors for an ML abstract type
 \verb+thm+. {\it Derived\/} rules are then built by arbitrary ML
 programming. In such a design, the only way that a theorem can result is
 when an ML function having range type \verb+thm+ is fully applied to its
 arguments. In an LCF-style system, therefore, there is no way for the
 system to produce a theorem other than by eventually invoking a
 primitive rule of inference. Put another way: if one is able to get an
 ML entity of type \verb+thm+, then it has been proved via an unbroken
 chain of inference.

 In the following subsections, we examine some packages that have been
 built upon the \verb+thm+ type. In each of these, it is important to
 remember that they are ``merely'' ways of organizing proofs, \ie,
 applications of primitive rules. However, first we treat something a
 little more radical.

\section{Oracles}

Hol98 extends the LCF tradition by allowing the use of an {\it
  oracle\/} mechanism to allow arbitrary formulas to become elements
of the \verb+thm+ type. Thus Hol98 can utilize arbitrary proof
procedures.\footnote{Some care should be taken with proof procedures
  for theories lacking a formalization in the HOL logic. The product
  of such procedures can be used in HOL without damage; however, in
  the end it won't be clear --- at least in HOL --- what has been
  proven.} In spite of such liberalness, the system can still make
strong assertions about the security of ML objects of type \verb+thm+.

To avoid unsoundness, the system ensures that a tag is attached to any
theorem coming from an oracle. The system propagates this tag through
every inference that the theorem participates in.\footnote{The idea is
  due to Mike Gordon.} If it happens that falsity becomes derived, the
offending oracle can be found by examining the tags component of the
theorem. (The Hol98 authors would be quite interested to hear of cases
where falsity is derivable without the use of oracles.) A theorem
proved without use of any oracle will have an empty tag, and can be
considered to have been proved in the HOL logic.

Tagged theorems can be created via
\begin{verbatim}
    val mk_oracle_thm : tag -> term list * term -> thm
\end{verbatim}
which directly creates the requested theorem and attaches the given tag to
it. Tags may be created with
\begin{verbatim}
     Tag.read : string -> tag.
\end{verbatim}
As well as providing principled access to external reasoners, tags are
used to implement some useful `system' operations on theorems. For
example, Hol98 allows one to directly create a theorem via
\verb+mk_thm+. The tag \verb+MK_THM+ gets attached to each theorem
created with this call. This allows users to directly create useful
theorems, \eg, to use as test data for derived rules of inference.
Another tag is used to implement validity checking in tactics. Other
common pre-existing tags are for ``definition schemas'' like
\verb+string_CONV+ (which encapsulates the semantics of string
literals).

The tags in a theorem can be viewed by setting \verb+Globals.show_tags+ to
true. For example, we have\footnote{Hol98 currently also uses tags for
tracking the use of axioms in proofs.}
\begin{verbatim}
     - mk_thm([], Term `F`);

     val it = [oracles: MK_THM] [axioms: ] [] |- F : thm
\end{verbatim}
There are three elements to the left of the turnstile in the printed
representation of a theorem: the first two comprise the tags component and the
third is the standard assumption list. The tag component of a theorem
can be extracted by
 \begin{verbatim}
     Thm.tag : thm -> tag
 \end{verbatim}
\noindent and prettyprinted by
 \begin{verbatim}
     Tag.pp : ppstream -> tag -> unit.
 \end{verbatim}

\noindent{\bf Remark}

 No serious attempt is made to prevent spoofing: a person may slap tag
\verb+X+ on an assertion coming from tool \verb+Y+ if desired. However, the
tags for \verb+mk_thm+ and validity checking cannot be spoofed.

\section{Tactics}

Tactics are a well-known method for backward proof. The original
conception of Robin Milner, which is still that of tactics in
\HOL, is that a tactic can be represented by the type
\[ goal \longrightarrow goal\ list * justification, \]
{\it i.e.}, a tactic decomposes a goal\footnote{A goal $(A,c)$ has ML
type $term\ list * term$.} into subgoals plus a
justification function. The justification function takes the theorems
resulting from the solved subgoals and performs inference with them to
return a new theorem that {\it achieves} the original goal. Thus the
justification has type
 \[  thm\ list \longrightarrow thm.  \]
 A theorem $\Gamma \vdash M$ achieves a goal $(\Delta,N)$ when $M =_\alpha
 N$ and also each element of $\Gamma$ is equal, modulo $\alpha$
 convertibility, to an element of $\Delta$. A tactic $t$ {\it solves\/} a
 goal $g$ when $t\; g$ creates an empty list of subgoals and a
 justification function $f$ such that $f$ applied to the empty list
 achieves $g$.

For example, a simple tactic is \verb+CONJ_TAC+. It takes a goal and, if
it is a conjunction, splits it into two subgoals. The justification
function is \verb+CONJ+, which takes two theorems and returns a new
theorem, which has as assumptions the union of the assumptions of the
two theorems, and has as the conclusion the conjunction of the
conclusions of the two theorems. In ML code this is expressed as:

\begin{verbatim}
   fun CONJ_TAC (asl,c) =
      let val {conj1,conj2} = dest_conj c
      in
        ([(asl,conj1), (asl,conj2)], fn [th1,th2] => CONJ th1 th2)
      end
      handle HOL_ERR _ => raise TACTIC_ERR "CONJ_TAC" "";
\end{verbatim}

Tactics are composed via tacticals. The basic tacticals are \verb+THEN+,
\verb+THENL+, \verb+ORELSE+, and \verb+REPEAT+. The workhorse tacticals
can be found in Table \ref{tacticals}.

\begin{table}
\[
\begin{array}{rclr}
 \tactic & ::= & \primtactic & \mbox{(basic tactic)} \\
 & | & \verb+NO_TAC+ & \mbox{(fail)} \\
 & | & \verb+ALL_TAC+ & \mbox{(No-op)} \\
 & | & \tactic\ \verb+THEN+ \ \tactic & \mbox{(composition)} \\
 & | & \tactic\ \verb+ORELSE+ \ \tactic & \mbox{(alternative)} \\
 & | & \tactic\ \verb+THENL+ \ [\tactic, \ldots, \tactic] &
\mbox{(indexed composition)} \\
 & | & \verb+REPEAT+\ \tactic & \mbox{(iteration)} \\
\end{array}
\]
\caption{Tactics and Tacticals} \label{tacticals}
\end{table}


\section{Conversions}

Another heavily used method of arranging proofs in Hol98 is {\it
conversions\/}, which were created by Larry Paulson. In the area of
equational reasoning, they provide a high-level language similar to the
language of tactics and tacticals. The rewriters and simplifiers of
Hol98 are all implemented using conversions. Historically, conversions
have also been heavily used in interactive proof; however, the passage
of time has seen the emergence of advanced forms of rewriting---such as
conditional and contextual rewriting, as well as rewriting using
(restricted) higher order matching---which often provides a more
convenient alternative for interactive use.

\section{Theorem Continuations}

Another invention of Paulson were {\it theorem continuations}. These
provide support for interactively building tactics that perform very
specific manipulation of theorems in the course of
inference. Experienced HOL users often swear by theorem continuations,
but we will not document them here; theorem continuations are something
that one should pick up after learning higher-level proof methods.

\section{Simplifiers and Automatic Reasoners}

Hol98 comes with several simplifiers. Largely that is a tribute to the
ease with which simplifiers can be written with conversions. Each of the
following items is the name of the ML structure containing the
simplifier(s).

\begin{description}

\item [Rewrite] Performs unconditional rewriting, with various
strategies. It uses only first order matching (up to
alpha-convertibility). This has been a workhorse proof tool over the
years.

\item [Ho\_rewrite] Performs unconditional rewriting, with various
strategies. It employs restricted higher order matching, which is a
significant increase in power, since it performs such things as
quantifier movement, which was formerly done in a tedious fashion by
conversions.

\item [RW] Performs conditional and contextual rewriting, with various
strategies. It employs first order matching up to alpha conversion. This
is again a significant increase in power over unconditional rewriting,
since it can automatically apply implicational theorems by instantiating
and solving the antecedents while traversing the goal. This package was
originally designed to implement termination condition extraction when
using \verb+tflLib+ to define recursive functions.

\item [Cond\_rewrite] Performs conditional rewriting with first order
matching, and a fixed strategy. This is used to provide support for the
\verb+res_quan+ library, but is also generally useful.

\item [simpLib] Performs conditional and contextual rewriting, with a
fixed top-down strategy. It employs higher order matching and also
performs ordered rewriting for associative-commutative operators, as in
the Boyer-Moore system. This is an `Isabelle-style' simplifier, written
by Don Syme; he has significantly extended it past the original Isabelle
design, by allowing free application of decision procedures throughout
the rewriting process.

The simplifier library provides a range of pre-assembled databases
with which to work. We list the structures that must be loaded for each
of them.

\begin{center}
\begin{tabular}{|r|l|} \hline
  \verb+empty_ss+ & The empty simplification set \\
  \verb+pure_ss+ & The simplification set allowing just basic rewriting\\
  \verb+boolSimps+ & Standard logic simplifications \\
  \verb+combinSimps+ & Combinator rewrites \\
  \verb+pairSimps+ & Rewrite rules for pairs \\
  \verb+sumSimps+ & Rewrite rules for sums \\
  \verb+listSimps+ & Basic list theory rewrites \\
  \verb+ListSimps+ & Extended list theory simplifications \\
  \verb+arithSimps+ & Arithmetic simplification, using\\
                    & a linear arithmetic decision procedure \\
  \verb+SatisfySimps+ & Conversions for witness instantiation \\
  \verb+UnwindSimps+ & Point-wise unwinding of existential and\\
                     & universal formulae\\
  \verb+HOLSimps+ &  All of the above \\
  \hline
\end{tabular}
\end{center}

By default, only \verb+empty_ss+ and \verb+pure_ss+ are available when
\verb+simpLib+ is loaded.
\end{description}

\noindent Although it might seem like there ought to be only one simplification
tool supported in Hol98, each of the above tools has found a niche in
the system, and the differences among them have been significant
enough to deter consideration of their unification. It is therefore up
to the user to decide which is most suitable for the purpose at hand.


\subsection{Automatic methods}

Hol98 also provides automatic reasoners for several domains.

\begin{itemize}

\item For general first order reasoning, there is \verb+mesonLib+, which
      has been introduced already.

\item For arithmetic, tautologies, pairs, datatypes, and ground
      equational reasoning, there is \verb+decisionLib+, which
      implements the Nelson-Oppen method for combining decision procedures.

\item For in-the-logic calculations involving numbers or booleans, there
      is \verb+reduceLib+. This has been incorporated into
      \verb+decisionLib+, but the reasoners in \verb+reduceLib+ can be
      helpful when writing custom proof tools.

\item For the theory of lists, there are some useful conversions in
      \verb+listLib+.
\end{itemize}


\section{Definition principles}

One of the main thrusts in the development of the HOL system has been a
stubborn insistence on building formalizations by principles of
definition, as opposed to the assertion of axioms. Users of definition
principles have the knowledge that they have introduced no inconsistency
into the system.  Such peace of mind comes at a price, however, since
the principles of definition for the HOL logic are extremely simple. To
remedy this, high-level definition mechanisms have been built as derived
rules of inference. The definition principles listed in Table \ref{PoD}
are currently offered by Hol98.

\begin{table}[ht]
\begin{center}
\begin{tabular}{|r|l|r|} \hline
Type definition & \verb+Type_def+ & primitive \\
Recursive types & \verb+Define_type+ &  \\
Mutually recursive types & \verb+mutrecLib+ & \\
Nested recursive types & \verb+nested_recLib+ & \\
Quotient types & \verb+EquivType+ & \\
Record types & \verb+RecordType+ & \\\hline
Constant specification & \verb+Const_spec+ & primitive \\
Constant definition & \verb+Const_def+ & primitive \\
Primitive recursive functions & \verb+Prim_rec+ & \\
Mutually recursive functions & \verb+mutrecLib+ & \\
Inductively defined relations & \verb+ind_defLib+,  \verb+IndDefLib+ & \\
Wellfounded recursive functions & \verb+tflLib+ & \\
 \hline
\end{tabular}
\caption{Definition Principles}\label{PoD}
\end{center}\end{table}

Unfortunately, each one of these facilties has separate entrypoint(s),
and moreover, using some of them can be quite ungainly. For example, to
build and use recursive type typically involves several steps: first the
type has to be defined, then separate function calls need to be made to
build induction theorems, standard rewrite rule sets, `case' theorems,
\etc\ Moreover, during proof, the names of all these entities must be
remembered, and managed. A prototype library aimed at remedying this
problem can be found in Chapter~\ref{bossLib}.

\subsection{Record types}

Record types \footnote{This documentation has been supplied by Michael
Norrish} are convenient ways of bundling together a number of component
types, and giving those components names so as to facilitate access to
them.  Record types are semantically equivalent to big pair
(cross-product) types, but the ability to label the fields with names of
one's own choosing is a great convenience.  Record types as implemented
in HOL98 are similar to C's {\tt struct} types and to Pascal's records.
However, the current HOL implementation doesn't allow the equivalent of
variant records, nor for records to be recursive.

Done correctly, record types provide useful maintainability features.
If one can always access the {\tt fieldn} field of a record type by
simply writing {\tt record.fieldn}, then changes to the type that
result in the addition or deletion of other fields will not invalidate
this reference.  One failing in SML's record types is that they do not
allow the same maintainability as far as (functional) updates of
records are concerned.  The HOL implementation allows one to write
{\tt rec with fieldn := new\_value}, which replaces the old value of
{\tt fieldn} in the record {\tt rec} with {\tt new\_value}.  This
expression will not need to be changed if another field is added,
modified or deleted from the record's original definition.

\subsubsection{Defining a record type in Hol98}

\newcommand{\createrec}{{\tt create\_record}} The record type package
is defined in the structure {\tt RecordType}.  Defining a record type
is achieved with the function \createrec, which is in that structure.
This takes two parameters, a string which is the name of the new type,
and a list of string-type pairs, which are the names and types of the
record type's fields.  For example, to create a record type called
{\tt person} with boolean, string and number fields called {\tt
  employed}, {\tt name} and {\tt age}, one would enter:
\begin{verbatim}
val person_result =
  create_record "person" [("employed", ``:bool``),
                          ("age",      ``:num``),
                          ("name",     ``:string``)];
\end{verbatim}
The order in which the fields are entered is not significant. As well
as defining the type (called {\tt person}), the \createrec{} function
also defines three other sets of constants.  These are the field
access functions, update functions, and functional update functions.
The field access functions have names of the form
``$\langle$\textsl{record-type\/}$\rangle$\_$\langle$\textsl{field\/}$\rangle$''.
These functions can be used directly, or one can use standard field
selection notation to access the values of a record's field.  Thus,
one would write the expression: \mbox{\tt ``bob.employed``} in order
to return the value of {\tt bob}'s {\tt employed} field.  The
alternative, \texttt{``person\_employed bob``}, works, but would be
printed using the first syntax, with the full-stop.

The update functions are given the names
\mbox{``$\langle$\textsl{record-type\/}$\rangle$\_%
$\langle$\textsl{field\/}$\rangle$\_\texttt{update}''} for each
field in the type.  They take a value of the type of the field in
question and a record value to be modified.  They return a new record
value that is otherwise the same as the old value but with the
specified field having the new value.  They can be written with the
keyword \texttt{with} and the \texttt{:=} operator:
\begin{verbatim}
  ``bob with employed := T``
\end{verbatim}
\noindent If a chain of updates is desired, then multiple updates can
be specified inside \texttt{<|}-\texttt{|>} pairs, separated by
semi-colons, thus:

\begin{verbatim}
  ``bob with <| age := 10; name := "Child labourer" |>``
\end{verbatim}

\noindent Finally, the second sort of update functions, the so-called
``functional'' updates have names of the form
\mbox{``$\langle$\textsl{record-type\/}$\rangle$\_%
$\langle$\textsl{field\/}$\rangle$\_\texttt{fupd}''}. Rather than
specifying a new value for the record, these functions take a function
as their first parameter, which will be an endomorphism on the field
type, so that the resulting record is the same as the original, except
that the specified field has had the given function applied to it to
generate the new value for that field.  The functional update
functions allow more concision when writing updates on a record that
depend on the field's old value.

The special syntax for writing these updates is to again use the
\texttt{with} keyword, but to use the infix \texttt{updated\_by}
rather than \texttt{:=}.  Thus
\begin{alltt}
  ``bob with employed updated_by \$~``
\end{alltt} \noindent
is a record value with the opposite boolean value in the
\texttt{employed} field as held by \texttt{bob}.

\subsubsection{Specifying record literals}

The parser accepts lists of field specifications between
\texttt{<|}-\texttt{|>} pairs without the \texttt{with} keyword.
These translate to sequences of updates of an arbitrary value
(literally, the HOL value \texttt{ARB}), and are treated as literals.
Thus,
\begin{verbatim}
  ``<| age := 21; employed := F; name := "Layabout" |>``
\end{verbatim}

\subsubsection{Using the theorems produced by \createrec}

As well as defining the type and the functions described above, record
type definition also proves a suite of useful theorems.  Most of these
are returned in a big record; all are stored using {\tt save\_thm} so
that they can be recovered.

The record returned has the following fields:
\newcommand{\rewruse}{This theorem should be included in rewrites used
  for this type.}
\newcommand{\field}[1]{\mbox{\it field}_{#1}}
\newcommand{\update}{\mbox{\tt\_update}}
\begin{description}
\item[{\tt type\_axiom}] The type axiom for the record type, as
  returned by the standard datatype definition package.
\item[{\tt accessor\_fns}] The definitions of the accessor functions.
  \rewruse
\item[{\tt update\_fns}] The definitions of the update functions.
  \rewruse
\item[{\tt cases\_thm}] The usual cases theorem for a type, stating
  that for all record values, there exist component values making it
  up.
\item[{\tt fn\_upd\_thm}] The definitions of the functional update
  functions.  \rewruse
\item[{\tt acc\_upd\_thm}] A theorem stating simpler forms for
  expressions of the form $\field{i}\, (\field{j}\update\;v\; r)$.  If
  $i = j$, then the RHS is $v$, if not, it is $(\field{i}\;r)$.
  \rewruse
\item[{\tt upd\_acc\_thm}] A theorem stating that $\field{i}\update
  \;(\field{i}\;r)\;r = r$ for all of
  the fields defined in the type. \rewruse
\item[{\tt upd\_upd\_thm}] A thereom stating that $\field{i}\update
  \;v_1 \,(\field{i}\update \;v_2\;r) = \field{i}\update\;v_1\;r$.
  \rewruse
\item[{\tt upd\_canon\_thm}] A theorem that states commutativity results
  for all possible pairs of field updates.  They are constructed in
  such a way that if used as rewrites, they will canonicalise
  sequences of updates. \rewruse
\item[{\tt cons\_11\_thm}] The standard result stating the type
  constructor is injective.  \rewruse
\item[{\tt create\_term}] This last component of the record returned
  is not a theorem, but rather an ML function.  It is identical to the
  {\tt create\_term\_fn} already defined in {\tt RecordType}, but is
  pre-applied to the relevant arguments, so that it is of the type
  string-value list to term.
\end{description}

\section{A simple proof manager}\label{goalstack}

The {\it goal stack\/} provides a simple interface to tactic-based
proof. When one uses tactics to decompose a proof, many intermediate
states arise; the goalstack takes care of the necessary bookeeping. The
implementation of goalstacks reported here is a re-design of Larry
Paulson's original conception.

The abstract types {\it goalstack\/} and {\it proofs\/} are the focus of
backwards proof operations. The type \verb+proofs+ can be regarded as a
list of independent goalstacks. Most operations act on the head of the
list of goalstacks; there are operations so that the focus can
be changed.

\subsection{Starting a goalstack proof}

\begin{verbatim}
    g        : term quotation -> proofs
    set_goal : goal -> proofs
\end{verbatim}

Recall that the type \verb+goal+ is an abbreviation for
\verb+term list * term+. To start on a new goal, one gives
\verb+set_goal+ a goal. This creates a new goalstack and makes it the
focus of further operations.

A shorthand for \verb+set_goal+ is the function \verb+g+: it
invokes the parser automatically, and it doesn't allow the the goal to
have any assumptions.


Calling \verb+set_goal+, or \verb+g+, adds a new proof attempt to
the existing ones, {\it i.e.}, rather than overwriting the current
proof attempt, the new attempt is stacked on top.

\subsection{Applying a tactic to a goal}

\begin{verbatim}
    expandf : tactic -> goalstack
    expand  : tactic -> goalstack
    e       : tactic -> goalstack
\end{verbatim}

How does one actually do a goalstack proof then? In most cases, the
application of tactics to the current goal is done with the function
\verb+expand+. In the rare case that one wants to apply an
{\it invalid\/} tactic, then \verb+expandf+ is used. (For an
explanation of invalid tactics, see Chapter 24 of Gordon \& Melham.) The
abbreviation \verb+e+ may also be used to expand a tactic.


\subsection{Undo}

\begin{verbatim}
    b          : unit -> goalstack
    drop       : unit -> proofs
    dropn      : int  -> proofs
    backup     : unit -> goalstack
    restart    : unit -> goalstack
    set_backup : int  -> unit
\end{verbatim}

Often (we are tempted to say {\it usually}!) one takes a wrong path
in doing a proof, or makes a mistake when setting a goal. To undo a step
in the goalstack, the function \verb+backup+ and its abbreviation
\verb+b+ are used. This will restore the goalstack to its previous
state.


To directly back up all the way to the original goal, the function
\verb+restart+ may be used. Obviously, it is also important to get
rid of proof attempts that are wrong; for that there is \verb+drop+,
which gets rid of the current proof attempt, and \verb+dropn+, which
eliminates the top $n$ proof attempts.


Each proof attempt has its own {\it undo-list\/} of previous
states. The undo-list for each attempt is of fixed size (initially
12). If you wish to set this value for the current proof attempt, the
function \verb+set_backup+ can be used. If the size of the backup
list is set to be smaller than it currently is, the undo list will be
immediately truncated. You can not undo a ``proofs-level'' operation, such
as \verb+set_goal+ or \verb+drop+.

\subsection{Viewing the state of the proof manager}

\begin{verbatim}
    p            : unit -> goalstack
    status       : unit -> proofs
    top_goal     : unit -> goal
    top_goals    : unit -> goal list
    initial_goal : unit -> goal
    top_thm      : unit -> thm
\end{verbatim}

To view the state of the proof manager at any time, the functions
\verb+p+ and \verb+status+ can be used. The former only shows
the top subgoals in the current goalstack, while the second gives a
summary of every proof attempt.

To get the top goal or goals of a proof attempt, use \verb+top_goal+
and \verb+top_goals+. To get the original goal of a proof attempt,
use \verb+initial_goal+.

Once a theorem has been proved, the goalstack that was used to derive it
still exists (including its undo-list): its main job now is to
hold the theorem. This theorem can be retrieved with
\verb+top_thm+.

\subsection{Switch focus to a different subgoal or proof attempt}

\begin{verbatim}
    r             : int -> goalstack
    R             : int -> proofs
    rotate        : int -> goalstack
    rotate_proofs : int -> proofs
\end{verbatim}

Often we want to switch our attention to a different goal in the current
proof, or a different proof. The functions that do this are
\verb+rotate+ and \verb+rotate_proofs+, respectively. The abbreviations
\verb+r+ and \verb+R+ are simpler to type in.

\chapter{Existing Context}\label{context}

\section{Theories}

In Hol98, theories are represented by separately compiled ML
structures. The theories listed in Table \ref{nativeTheories} come
pre-built in the system (we have omitted a few of the less commonly used
ones).
\begin{table}
\begin{center}
\begin{tabular}{|r|l|} \hline
minTheory & the origin theory \\
boolTheory & definitions of logical operators and basic axioms \\
pairTheory & basic theory of pairs \\
numTheory & Peano's axioms derived from the axiom of infinity \\
prim\_recTheory, & the primitive recursion theorem \\
arithmeticTheory & Peano arithmetic development \\
integerTheory & integers, by John Harrison \\
TCTheory & transitive closure of a relation \\
primWFTheory & wellfounded relations, plus WF induction and recursion \\
WFTheory & instances of wellfoundedness at various types \\
setTheory & sets as a separate type (includes finite sets) \\
pred\_setTheory & sets as predicates (includes finite sets) \\
bagTheory & bags (also known as \emph{multi-sets})\\
listTheory & lists  \\
rich\_listTheory & extended theory of lists \\
optionTheory & the ``option'' type \\
finite\_mapTheory & finite maps from $\alpha$ to $\beta$ \\
ltreeTheory & polymorphic finitely branching trees \\
combinTheory & combinators \\
sumTheory & disjoint sums \\
restr\_binderTheory & definitions of binder restrictions \\
res\_quanTheory & restricted quantifier support \\
asciiTheory & ascii \\
stringTheory & strings \\
wordTheory & ({\it plus others}) theory of bitstrings \\
realTheory & ({\it plus others}) real numbers and analysis \\
HOLTheory & equivalent to HOL theory from hol88/90\\  \hline
\end{tabular}
\caption{Native Theories}\label{nativeTheories}
\end{center}
\end{table}

The only theory that is initially loaded by an invocation of Hol98 is
\verb+boolTheory+. To gain access to any other theory when working
interactively, simply invoke
\begin{verbatim}
    load "xTheory";
\end{verbatim}
where \verb+x+ is the name of the theory. Once the theory has been
loaded by the system, access to its contents is through the ``dot''
notation of ML, \eg, \verb+xTheory.FOO_DEF+, or if you prefer, by
``opening'' the structure and then directly accessing its contents.

We will consider the construction of theories in Chapter \ref{thy-ops}.

\section{Libraries}

Hol98 currently offers the libraries found in Table \ref{nativeLibs}.

\begin{table}
\begin{center}
\begin{tabular}{|r|l|} \hline
    decisionLib     & cooperating decision procedures \\
    mesonLib        & model-elimination first order reasoner \\
    simpLib         & Isabelle-style simplifier \\
    ind\_defLib     & inductive defn. package \\
    IndDefLib       & generalized inductive defn. package \\
    tflLib          & wellfounded recursive definitions \\
    mutrecLib,      & mutually recursive datatype definitions \\
    nestrecLib      & nested  recursive datatype definitions \\
    mutualLib       & improved mutual/nested datatypes  \\
    goalstackLib    & simple manager for building tactic proofs \\
    basicHol90Lib   & derived rules, tactics, conversions, rewriting, etc. \\
    optionLib       & option type \\
    pairLib         & extended support for pairs \\
    setLib          & sets as a separate type \\
    pred\_setLib    & sets as predicates \\
    listLib         & extensive development of lists \\
    stringLib       & characters and strings \\
    wordLib         & theories and proof support for bitstrings \\
    unwindLib       & unwinding existential quantifiers \\
    res\_quanLib    & bounded quantification \\
    hol88Lib        & support for hol88 compatibility \\
    liteLib         & support for portability with HOL-Light \\
    ho\_matchLib    & higher-order versions of various proof tools \\
    refuteLib       & support for refutation procedures \\
    reduceLib       & basic reasoners for nums and bools \\
    tautLib         & tautology prover \\
    arithLib        & linear arith. decision procedures \\
    BoyerMooreLib   & automatic proof procedure based on the one in Nqthm \\
    bossLib         & collection of automatic tools \\
    realLib         & theories for the real numbers and analysis. \\
    robddLib        & Reduced Ordered Binary Decision Diagrams \\
 \hline
\end{tabular}
\caption{Native Libraries}\label{nativeLibs}
\end{center}
\end{table}

As for theories, a library is represented by a separately compiled ML
structure and can thus be brought into an interactive session by
invoking ``load'', \eg,
\begin{verbatim}
    load "xLib";
\end{verbatim}
One difference between libraries and theories is that a library can in
general consist of a collection of theories and support ML
structures. Thus sometimes, but not always, the functionality of a
library is distributed through a collection of ML structures, all of
which have been brought into the interactive session by the call to
``load''. It (unfortunately) falls to the user to know about the
functionality of a library. Some libraries provide ``help'' and manuals
for their use; others do not.

\begin{figure}
\centerline{\psfig{figure=hol98.pic}}
\caption{System dependencies}
\end{figure}


\chapter{Building Logical Developments}\label{thy-ops}

This chapter deals with theories and \verb+Holmake+. Theories are a
simple structuring mechanism, with which formalizations can be broken
into chunks. Holmake is a tool for handling all the ML code and theories
associated with a large formalization.

\section{Theories}

Building theories can be considered to be the main point of work in
Hol98. A {\it theory} is a related collection of types, constants,
axioms, definitions, and theorems, plus `pointers' to ancestor theories.
In Hol98, theories are built in an interactive manner: axioms,
definitions and theorems can be entered into, or deleted from, the
theory under construction at any time. The system maintains the required
dependencies so that inconsistency cannot result. Once the user has
built the theory to his or her satisfaction, it can be exported to disk,
to be reloaded at a later date, without having to replay the proofs that
created the theory in the first place. This is known as persistence.

In Hol98, there is always a single current theory. When Hol98 starts up,
the current theory is called \verb+scratch+. Its only parent is the
theory \verb+bool+.  Every theory except for the initial theory (named
\verb+min+ in Hol98) has one or more parent theories (found by calling
\verb+parents+). The transitive closure of the parent relation provides
the ancestry of a theory and is computed by the \verb+ancestry+
function.


\subsection{Building a theory}

One makes a theory by a call to \verb+new_theory+.  This allocates a new
`scratch area' where subsequent theory operations take effect.  Elements
stored in this area may be overwritten by subsequent additions, or
deleted outright. Any theory elements that were built on
those elements are now held to be {\it out-of-date}, and will not be
included in the theory when it is exported to disk. Moreover,
out-of-date constants and types are printed surrounded by odd-looking
syntax to alert the user.
\begin{verbatim}
    new_theory   : string -> unit

    new_type     : {Name : string, Arity : int} -> unit
    new_constant : {Name : string, Ty : hol_type} -> unit
    new_infix    : {Name : string, Ty : hol_type, Prec :int} -> unit
    new_binder   : {Name : string, Ty : hol_type} -> unit
    set_fixity   : string -> fixity -> unit

    new_axiom    : string * term -> thm
    save_thm     : string * thm -> thm
    store_thm    : string * term * tactic -> thm
\end{verbatim}

The \verb+new_+ functions listed above add types and constants to the
current HOL signature. These entrypoints are rarely invoked directly by
the user; instead, definition principles are typically used to update
the logic signature. The function \verb+set_fixity+ can be used to
change the parsing status of a constant after it has been
declared. Notice that there is no entrypoint for adding a new parent;
that is because a theory can be added as a parent to the current theory
simply by \verb+load+ing it. The entire ancestry of the new parent is
then recursively and silently loaded.

Usually, when \verb+new_theory+ is called, the contents of the current
theory are written to disk before the new theory is constructed. That
is, unless  the theory is already consistent with disk (this is kept
track of internally). If however, \verb+new_theory+ is invoked with the
same name as the current theory, it is assumed that the user wishes to
clear the scratchpad and start over, so internally that is what is
done. This allows the current theory to be repeatedly re-loaded without
having to restart the ML session.

The functions \verb+new_axioms+ and \verb+save_thm+ add axioms and
theorems into the current theory, under the given name. This name should
be an acceptable  ML identifier. The function \verb+store_thm+ takes a
term and a tactic and treats the term as a goal to apply the tactic
to. The proved theorem is stored in the current theory under the given name.
\begin{verbatim}
    delete_type    : string -> unit
    delete_const   : string -> unit
    delete_axiom   : string -> unit
    delete_theorem : string -> unit
    uptodate_type  : hol_type -> bool
    uptodate_term  : term -> bool
    uptodate_thm   : thm -> bool
    scrub          : unit -> unit
\end{verbatim}

There are also some functions that allow any element of a theory to be
deleted. Any other elements that depend on that element become
out-of-date. There is also a complementary suite of functions that tell
whether an item is current with respect to the current theory.

Finally, the following situation can often occur: an item held in the
current theory all of a sudden becomes out-of-date because something it
was built from got deleted. For reasons of efficiency, it is undesirable
for the system to re-check all dependencies after every modification to
the theory; thus the function \verb+scrub+ is made available so that the
user can decide when to clean up a theory in disarray.

\subsection{Information functions}

The following functions can be used to find out information about theory
items. Most of them are fairly self-explanatory and so we won't cover them.
\begin{verbatim}
    arity       : string -> int     (* of a type constant *)
    fixity      : string -> fixity  (* of a term constant *)
    precedence  : string -> int

    is_type     : string -> bool
    is_constant : string -> bool
    is_binder   : string -> bool
    is_infix    : string -> bool

    parents     : string -> string list  (* of a theory *)
    ancestry    : string -> string list

    (* items from given theory *)
    types       : string -> {Name : string, Arity : int} list
    constants   : string -> term list
    infixes     : string -> term list
    binders     : string -> term list

    (* named theorem from current theory *)
    axiom       : string -> thm
    definition  : string -> thm
    theorem     : string -> thm

    (* all items in a certain class from current theory only *)
    axioms      : unit -> (string * thm) list
    theorems    : unit -> (string * thm) list
    definitions : unit -> (string * thm) list

    print_theory : unit -> unit      (* The whole picture *)
    current_theory : unit -> string
\end{verbatim}

The function \verb+print_theory+ can be used to give a listing of the
types, constants, axioms, definitions, and theorems of the current
theory.


\subsection{Theories and the file system}

Hol98 provides persistent theories: once a user has finished working on
a theory, it can be written out to a file, to be used in future
formalization efforts. Before the current theory is written out, all
out-of-date entities are scrubbed out. Also the parenthood of the theory
is computed: it is the fringe of the theory graph at the time
\verb+export_theory+ is called.
\begin{verbatim}
    export_theory : unit -> unit
\end{verbatim}
There is also a more general export operation---\verb+prim_export_theory+ ---
which invokes user-supplied prettyprinters just before printing the end
of the theory signature and structure. This can be used to, for example,
store theory-specific proof tools with the theory.

When \verb+export_theory+ is invoked from an interactive session, the
theory is exported, but not compiled. This makes it difficult to
\verb+load+ the theory in a later session. Currently,
\verb+export_theory+ is only useful when invoked under the control of
\verb+Holmake+.

\section{Holmake}

The purpose of \verb+Holmake+\footnote{{\tt Holmake} was first written
  by Ken Larsen and then extended by Michael Norrish.} is to maintain
dependencies in a Hol98 source directory. A single invocation of {\tt
  Holmake} will compute dependencies between files, (re-)compile plain
ML code, (re-)compile and execute theory scripts, and (re-)compile the
resulting theory modules. {\tt Holmake} does not require the user to
provide any dependency information,\eg, a Makefile. {\tt Holmake} can
be very convenient to use, but there are some conventions and
restrictions on it that must be followed, which we will describe in
the sequel.

{\tt Holmake} can be accessed through
\begin{verbatim}
   <hol-dir>/bin/Holmake.
\end{verbatim}

The model of user development that {\tt Holmake} is designed to
support is that there are two modes of work: theory construction and
system revision.  In `theory construction' mode, the user builds up a
theory by interacting with HOL, perhaps over many sessions. In `system
rebuild' mode, a module that others depend on has been altered, so all
intervening modules have to be brought up to date. System re-build
mode is simpler so we deal with it first.

\subsection{System Rebuild}

A system rebuild happens when an existing theory has been improved in
some way (augmented with a new theorem, a change to a definition, etc.),
or perhaps some support ML code has been added. The user needs to find
and recompile just those modules affected by the change. This is what an
invocation of {\tt Holmake} does, by identifying the out-of-date modules and
re-compiling and re-executing them.


\subsection{Theory construction}

To start a theory construction, some context (semantic, and also proof
support) is established, typically by loading parent theories and
useful libraries. In the course of building the theory, the user keeps
track of the ML---which, for example, establishes context, makes
definitions, builds and invokes tactics, and saves theorems---in a
text file. This file is used to achieve inter-session persistence of
the theory being constructed, i.e., the text file resulting from
session $n$ is ``\verb+use+''d to start session $n+1$; after that,
theory construction resumes.

Once the user finishes the perhaps long and arduous task of constructing
a theory, the user should
\begin{enumerate}
\item make the script separately compilable;
\item invoke {\tt Holmake}. This will (a) compile and execute the
  script file; and (b) compile the resulting theory file. After this,
  the theory file is available for use.
\end{enumerate}

\subsection{Making the script separately compilable}

First, the invocation
\begin{verbatim}
    val _ = export_theory();
\end{verbatim}
should be added at the end of the file. When the script is finally
executed, this call writes the theory to disk.

Second, we address a crucial environmental issue: if a theory script
has been constructed using\verb+ <holdir>/bin/hol+, then it has been
developed in an environment where some commonly used structures, \eg,
\verb+Tactic+, have already been loaded and opened for the user's
convenience. When we wish to apply {\tt Holmake} to a script developed
in this way, we have to take some extra steps to ensure that the
compilation environment also provides these structures.  In the common
case, this is simple; one must only add, at the head of the theory
script, the following ``boilerplate'':
\begin{verbatim}
    open HolKernel Parse basicHol90Lib;
    infix THEN THENL THENC ORELSE ORELSEC THEN_TCL ORELSE_TCL ## |->;
    infixr -->;
\end{verbatim}
This will duplicate the starting environment that one obtains with
\verb+<holdir>/bin/hol+ and \verb+<holdir>/bin/hol.unquote+.

Now the script should be separately compilable. Invoke {\tt Holmake}
to check; MoscowML will flag any unaccounted-for identifiers it finds.
The user has to resolve these, either by using the `dot' notation to
locate the identifier for the compiler, or by \verb+open+ing the
relevant module. This ``compile/resolve-identifier'' loop should
continue until {\tt Holmake} succeeds in compiling the module.

The following notes may be of some help.

\begin{enumerate}
\item The filenames of theory scripts must follow the following
  convention: a HOL theory script for theory ``x'' should be named
\begin{verbatim}
  xScript.sml.
\end{verbatim}
  If there is a corresponding signature (and there needn't be), it
  should---following Moscow ML convention---be named
  \verb+xScript.sig+. When \verb+export_theory+ is called during an
  invocation of \verb+Holmake+, the files
\begin{verbatim}
    xTheory.{sig,sml}
\end{verbatim}
will be generated and then compiled.

\item In the MoscowML batch compiler, modules are not allowed to have
  unbound top-level expressions. Hence, something like the following
  is not allowed:
\begin{verbatim}
    new_theory "ted";
\end{verbatim}
To make Moscow ML happy, one must instead write something like
\begin{verbatim}
    val _ = new_theory "ted";
\end{verbatim}

\item In the interactive system, one has to explicitly \verb+load+
  modules; on the other hand, the batch compiler will load modules
  automatically.  For example, in order to execute \verb+open Foo+ (or
  refer to values in \verb+Foo+) in the interactive system, one must
  first have executed \verb+load "Foo"+. Contrarily, the batch
  compiler will reject files having occurrences of \verb+load+, since
  \verb+load+ is only defined for the interactive system.

\item Take care not to have the string "Theory" embedded in the name
  of any of your files. Hol98 generates files containing this string,
  and when it cleans up after itself, it removes such files using a
  regular expression. This will also remove other files with names
  containing "Theory". For example, if, in your development directory,
  you had a file of ML code named
\begin{verbatim}
   MyTheory.sml
\end{verbatim}
  and you also were managing a Hol98 development there with {\tt
    Holmake}, then MyTheory.sml would get deleted if {\tt Holmake
    clean} was invoked.

\item We can see that some users may not wish to use (some of) the
  support provided by \verb+basicHol90Lib+, since it is becoming
  dated. In that case, the same general principle set out above will
  apply: the user must ensure that the compilation environment for a
  theory script is the same as the interactive environment it was
  developed in.

\end{enumerate}

\subsection{Summary}

A complete theory construction is performed by the following steps:
\begin{itemize}
\item Construct theory script, perhaps over many sessions;
\item Transform script into separately compilable form;
\item Invoke {\tt Holmake} to generate the theory and compile it.
\end{itemize}

After that, the theory is usable as a module in MoscowML.


\subsection{What {\tt Holmake} doesn't do}

{\tt Holmake} only works properly on the current directory.  Holmake
will rebuild files in the current directory if something it depends on
from another directory is fresher than it is, but it will not do any
analysis on files in other directories.  If one is developing a system
over more than one directory, one should write a master Makefile (or
shell script) that invokes {\tt Holmake} in the subsidiary
directories, in the correct order, \ie., such that there never is an
out-of-date dependence leading outside of the current directory. This
should always be achievable, simply by ordering the directories in the
order that one would have to ``\verb+use+'' files in them.

\subsection{{\tt Holmake}'s command-line arguments}

Like {\tt make}, {\tt Holmake} takes command-line arguments
corresponding to the targets that the user desires to build.  If there
are none, then {\tt Holmake} will attempt to build all ML modules and
HOL theories it can detect in the current directory.  In addition,
there are three special targets that can be used:
\begin{description}
\item[{\tt clean}] Removes all compiled files.
\item [{\tt cleanDeps}] Removes all of the pre-computed dependency
  files.  This can be an important thing to do if, for example, you
  have introduced a new {\tt .sig} file on top of an existing {\tt
  .sml} file.
\item [{\tt cleanAll}] Removes all compiled files as well as all of
  the hidden dependency information.
\end{description}

Finally, the user can directly affect the workings of \verb+Holmake+
with the following command-line options:
\begin{description}
\item[\tt -I <directory>] Look in specified directory for additional
  MoscowML object files, including other HOL theories.  This option
  can be repeated, with multiple {\tt -I}'s to allow for multiple
  directories to be referenced.
\item[\tt -d <file>] Ignore the given file and don't try to build it.
  The file may be rebuilt anyway if other files you have specified
  depend on it.  This is useful to stop Holmake from attempting to
  compile files that are interactive scripts (include use of {\tt
  load} or {\tt use}, for example).
\item[{\tt --help} or {\tt -h}] Prints out a useful option summary and
  exits.
\item[\tt --holdir <directory>] Associate this build with the given
  HOL directory, rather than the one this version of {\tt Holmake} was
  configured to use by default.
\item[{\tt --rebuild\_deps} or {\tt -r}] Forces {\tt Holmake} to
  always rebuild the dependency information, whether or not it thinks
  it needs to.
\item[{\tt --version} or {\tt -v}] Show some brief version
  information.  As of this writing, {\tt Holmake} is at version 2.04.
\end{description}

{\tt Holmake} should never exit with the MoscowML message ``Uncaught
exception''.  Such behaviour is a bug, please report it!

\chapter{High-level interactive proof support}\label{bossLib}

\newcommand\bossLib{{\tt bossLib}}
The library \bossLib\ marshalls some of the most widely used
theorem proving tools in HOL and provides them with a convenient
interface for interaction. The library currently focuses on two things:
definition of datatypes and functions; and composition of automated
reasoners. Loading \bossLib\ commits one to working in a context
that already supplies the theories of booleans, pairs, the option type,
arithmetic, and lists.

\section{Datatype definition}

There are several useful consequences of an object logic datatype
definition: structural induction, rewrite rules for constructors, \etc\
However, these have not traditionally been automatically derived
at the invocation of the definition package: the user would have to
build the required theorems by explicitly invoking various proof
procedures.  To remedy this, \bossLib\ offers the
\verb+Hol_datatype+ function.\footnote{\bossLib\ does not yet
support mutually recursive or nested datatypes.} The syntax of
declarations that \verb+Hol_datatype+ accepts is found in Table
\ref{datatype}.
\begin{table}[h]
\begin{center}
\begin{tabular}{|rcl|} \hline
\verb+Hol_datatype +\ \verb+`+\ident & \verb+=+ & [\clause\ \verb+|+]* \clause\verb+`+ \\
       & & \\
\clause & \verb+::=+ & \ident \\
        & \verb+|+ & \ident\ \verb+of+\ [\type\ \verb+=>+]* \type\\ \hline
\end{tabular}
\caption{Datatype Declaration}\label{datatype}
\end{center}
\end{table}

There is an underlying database of datatype facts that supports the
activities of \verb+bossLib+. This database already contains the
relevant entries for the types \verb+bool+, \verb+prod+, \verb+num+,
\verb+option+, and \verb+list+.  When a datatype is defined by
\verb+Hol_datatype+, the following information is derived and stored in
the database.

\begin{itemize}
\item initiality theorem for the type
\item injectivity of the constructors
\item distinctness of the constructors
\item structural induction theorem
\item case analysis theorem
\item definition of the `case' constant for the type
\item congruence theorem for the case constant
\item definition of the `size' of the type
\end{itemize}

The following functions use information in the database to ease the
application of Hol98's underlying functionality:
\begin{verbatim}
        type_rws     : string -> thm list
        Induct       : tactic
        Cases        : tactic
        Cases_on     : term quotation -> tactic
        Induct_on    : term quotation -> tactic
\end{verbatim}

\begin{itemize}

\item
The function \underline{\tt type\_rws} will search for the given type
by name in the underlying database and return useful
rewrite rules for that type. The rewrite rules of the
datatype are built from the injectivity and distinctness theorems, along
with the case constant definition. The pre-existing rewrite rules in the
database are already integrated into the simplification sets provided
by \verb+bossLib+; however rewrite rules arising from an invocation of
\verb+Hol_datatype+, or which come from a user-defined theory, will have
to be manually added into the simpsets used by the simplifier.

\item
The \underline{\tt Induct} tactic makes it convenient to invoke
induction. When it is applied to a goal, the leading universal
quantifier is examined; if its type is that of a known datatype, the
appropriate structural induction tactic is extracted and applied.

\item
The \underline{\tt Cases} tactic makes it convenient to invoke case
analysis. The leading universal quantifier in the goal is examined; if
its type is that of a known datatype, the appropriate structural
case analysis theorem is extracted and applied.

\item The \underline{\tt Cases\_on} tactic takes a quotation, which is
parsed into a term $M$, and then $M$ is searched for in the goal. If $M$
is a variable, then a variable with the same name is searched for. Once
the term to split over is known, its type and the associated facts are
obtained from the underlying database and used to perform the case
split. If some free variables of $M$ are bound in the goal, an attempt
is made to remove (universal) quantifiers so that the case split has
force. Finally, $M$ need not appear in the goal, although it should at
least contain some free variables already appearing in the goal. Note
that the \verb+Cases_on+ tactic is more general than \verb+Cases+, but
it does require an explicit term to be given.

\item The \underline{\tt Induct\_on} tactic takes a quotation, which is
parsed into a term $M$, and then $M$ is searched for in the goal. If $M$
is a variable, then a variable with the same name is searched for. Once
the term to induct on is known, its type and the associated facts are
obtained from the underlying database and used to perform the induction.
If $M$ is not a variable, a new variable $v$ not already occurring in
the goal is created, and used to build a term $v = M$ which the goal is
made conditional on before the induction is performed. First however,
all terms containing free variables from $M$ are moved from the
assumptions to the conclusion of the goal, and all free variables of $M$
are universally quantified. \verb+Induct_on+ is more general than
\verb+Induct+, but it does require an explicit term to be given.

\end{itemize}

Two supplementary entrypoints have been provided for more exotic
inductions:
\begin{description}
\item [completeInduct\_on] performs complete
induction on the term denoted by the given quotation. Complete induction allows one to assume a
(seemingly) stronger induction hypothesis than ordinary mathematical
induction: to wit, when inducting on
$n$, one is allowed to assume the property holds for {\it all\/} $m$
smaller than $n$. Formally: $\forall P.\ (\forall x.\ (\forall y.\ y < x
\supset P\, y) \supset P\,x) \supset \forall x.\ P\,x$. This allows the
inductive hypothesis to be used more than once, and allows instantiating
the inductive hypothesis to other than the predecessor. Complete
induction and ordinary mathematical induction are each derivable from
the other, hence the use of `seemingly'.
\item [measureInduct\_on] takes a quotation, and breaks it apart
to find a term and a measure function with which to induct.
\end{description}

\section{Function definition}

\begin{verbatim}
    Define : term quotation -> thm
\end{verbatim}

The \underline{\tt Define} function is a general-purpose function definition
mechanism. It will define non-recursive and primitive recursive
functions and attempt to define recursive-but-not-primitive-recursive
functions. For these more difficult recursions, it attempts to find a
measure under which recursive calls become smaller (and to prove that
they do indeed become smaller). Currently, it examines the domain type
of the function being defined and synthesizes a ``size'' measure.  Then it
does some basic simplifications and then attempts to automatically prove
the termination constraints.  If this termination proof fails, then the
termination constraints remain on the hypotheses. An induction theorem
for the function is also automatically derived: the definition and the
induction principle are conjoined.

\noindent {\bf Example.} Invoking
\begin{verbatim}
      Define
        `(gcd 0 y = y)  /\
         (gcd (SUC x) 0 = SUC x) /\
         (gcd (SUC x) (SUC y) =
             ((y <= x) => gcd (x-y)   (SUC y)
                       |  gcd (SUC x) (y-x)))`;
\end{verbatim}
proves all termination conditions and returns
\begin{verbatim}
      |- ((gcd 0 y = y)           /\
          (gcd (SUC x) 0 = SUC x) /\
          (gcd (SUC x) (SUC y) =
               (y <= x => (gcd (x - y) (SUC y))
                       |  (gcd (SUC x) (y - x)))))
          /\
          !P. (!y. P 0 y)       /\
              (!x. P (SUC x) 0) /\
              (!x y. (~(y <= x) ==> P (SUC x) (y - x)) /\
                       (y <= x  ==> P (x - y) (SUC y))
                        ==> P (SUC x) (SUC y))
                 ==>
                   !v v1. P v v1.
\end{verbatim}

\begin{itemize}

\item Nested recursive functions are currently rejected by
      \verb+Define+. Use \verb+tflLib.Rfunction+ for such cases.

\item \verb+Define+ assumes that the function being defined is to be
      parsed as a prefix. To define an infix or binder, first make a
      prefix definition with \verb+Define+ and then use the function
      \verb+set_fixity+.

\item \verb+Define+ assumes that the function being defined is to be
      given a theory-level binding built from the name of the defined
      constant. However, this sometimes will create a badly formed ML
      identifier, which will lead to failure of theory compilation. As a
      result, \verb+Define+ will warn the user when a malformed name has
      been generated. The user should then use \verb+set_MLname+ to
      override the system-generated name.

      {\bf Example.} The system responds to
\begin{verbatim}
    Define `## f g (x,y) = (f x, g y)`
\end{verbatim}
      with (omitting some messages)
\begin{verbatim}
   The name "##_def" should be changed to an alphanumeric.
   Use "set_MLname".
   > val it = |- !f g x y. ## f g (x,y) = (f x,g y) : Thm.thm
\end{verbatim}
      If we then invoke (for example)
\begin{verbatim}
    set_fixity "##" (Infix 450);
    set_MLname "##_def" "fpair_def";
\end{verbatim}
      then \verb+##+ will henceforth be an infix operator, and the
theory-level binding for its definition will be accepted by ML.
\end{itemize}


\section{Automated reasoners}

\verb+bossLib+ brings together the most powerful reasoners in Hol98 and
tries to make it easy to compose them in a simple way. We take our basic
reasoners from \verb+mesonLib+, \verb+simpLib+, and \verb+decisionLib+,
but the point of \verb+bossLib+ is to provide a layer of abstraction so
the user has to know only a few entrypoints.\footnote{In the mid 1980's
Graham Birtwistle advocated such an approach, calling it `Ten Tactic
HOL'.}

\begin{verbatim}
    PROVE      : thm list -> term quotation -> thm
    PROVE_TAC  : thm list -> tactic

    DECIDE     : term quotation -> thm
    DECIDE_TAC : tactic
\end{verbatim}

The inference rule \underline{\tt PROVE} (and the corresponding tactic
\underline{\tt PROVE\_TAC}) takes a list of theorems and a quotation, and
attempts to prove the term using a first order reasoner. The inference
rule \underline{\tt DECIDE} (and the corresponding tactic \underline{\tt
DECIDE\_TAC}) applies a decision procedure that (at least) handles
statements of linear arithmetic.

\begin{verbatim}
    RW_TAC   : simpset -> thm list -> tactic
    &&       : simpset * thm list -> simpset  (* infix *)
    bool_ss  : simpset
    arith_ss : simpset
    list_ss  : simpset
\end{verbatim}

The rewriting tactic \underline{\tt RW\_TAC} works by
first adding the given theorems into the given \underline{\tt simpset}; then it
simplifies the goal as much as possible; then it performs case splits on any
conditional expressions in the goal; then it repeatedly (1) eliminates
all hypotheses of the form $v = M$ or $M = v$ where $v$ is a variable
not occurring in $M$, (2) breaks down any equations between constructor
terms occurring anywhere in the goal. The infix combinator \verb+&&+ is used to
build a new simpset from a given simpset and a list of theorems.

Simplification sets for its native datatypes are provided
by \verb+bossLib+. In general, these are extended versions of those
found in \verb+simpLib+. The simpset for pure logic and pairs and the
\verb+option+ type is named \verb+bool_ss+. The simpset for arithmetic
is named \verb+arith_ss+, and the simpset for lists is named
\verb+list_ss+. The simpsets provided by {\tt bossLib} strictly increase
in strength: {\tt bool\_ss} is contained in {\tt arith\_ss}, and {\tt
arith\_ss} is contained in {\tt list\_ss}.

\begin{verbatim}
    STP_TAC  : simpset -> tactic -> tactic
    ZAP_TAC  : simpset -> thm list -> tactic
\end{verbatim}

The compound reasoners of \verb+bossLib+ take a basic approach: they
simplify the goal as much as possible with \verb+RW_TAC+ and then a
`finishing' tactic is applied. The primitive entrypoint for this is
\underline{\tt STP\_TAC}. Currently, the most powerful reasoner is
\underline{\tt ZAP\_TAC}, which features a finishing tactic that first
tries a tautology checking tactic; if that fails, \verb+DECIDE_TAC+ is
called; if that fails, \verb+PROVE_TAC+ is called with the second
argument. Although this general approach (simplify as much as possible,
then apply automated reasoners in sequence) is crude, we have found that
it allows one to make good progress in a high percentage of proof
situations.

\begin{verbatim}
    by : term quotation * tactic -> tactic (* infix 8 *)
    SPOSE_NOT_THEN : (thm -> tactic) -> tactic
\end{verbatim}

The function \underline{\tt by} is an infix operator that takes a
quotation and a tactic $tac$. The quotation is parsed into a term
$M$. When the invocation ``$M\ \mbox{\tt by}\ tac$'' is applied to a
goal $(A,g)$, a new subgoal $(A,M)$ is created and $tac$ is applied to
it. If the goal is proved, the resulting theorem is broken down and
added to the assumptions of the original goal; thus the proof proceeds
with the goal $((M::A), g)$. (Note however, that case-splitting will
happen if the breaking-down of $\ \vdash M$ exposes disjunctions.) Thus
\underline{\tt by} allows a useful style  of `assertional' or
`Mizar-like' reasoning to be mixed with ordinary tactic
proof`\footnote{Proofs in the Mizar system are readable documents,
unlike almost all tactic-based proofs.}


\underline{\tt SPOSE\_NOT\_THEN} initiates a proof by
contradiction by assuming the negation of the goal and driving the
negation inwards through quantifiers. It provides the resulting theorem
as an argument to the supplied function, which will use the theorem to
build and apply a tactic.

\noindent{\bf Note.} When the library \verb+bossLib+ is loaded, the
infix parsing status of \verb+&&+ and ``{\tt by}'' must be re-asserted
by the user.




\chapter{The Programmer's Interface}\label{api}

\bibliographystyle{plain}
\bibliography{/home/kxs/latex/biblio}
\end{document}
