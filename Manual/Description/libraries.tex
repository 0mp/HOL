\chapter{Commonly-used Libraries}\label{HOLlibraries}

\newcommand{\simpset}{simpset}

\section{A simple proof manager}\label{sec:goalstack}

The \texttt{goal stack} provides a simple interface to tactic-based
proof. When one uses tactics to decompose a proof, many intermediate
states arise; the goalstack takes care of the necessary bookeeping. The
implementation of goalstacks reported here is a re-design of Larry
Paulson's original conception.

The goalstack library is automatically loaded when \HOL\ starts up.

The abstract types \textit{goalstack} and \textit{proofs} are the
focus of backwards proof operations. The type \verb+proofs+ can be
regarded as a list of independent goalstacks. Most operations act on
the head of the list of goalstacks; there are operations so that the
focus can be changed.

\subsection{Starting a goalstack proof}

\begin{verbatim}
    g        : term quotation -> proofs
    set_goal : goal -> proofs
\end{verbatim}

Recall that the type \verb+goal+ is an abbreviation for
\verb+term list * term+. To start on a new goal, one gives
\verb+set_goal+ a goal. This creates a new goalstack and makes it the
focus of further operations.

A shorthand for \verb+set_goal+ is the function \verb+g+: it
invokes the parser automatically, and it doesn't allow the the goal to
have any assumptions.


Calling \verb+set_goal+, or \verb+g+, adds a new proof attempt to the
existing ones, \textit{i.e.}, rather than overwriting the current
proof attempt, the new attempt is stacked on top.

\subsection{Applying a tactic to a goal}

\begin{verbatim}
    expandf : tactic -> goalstack
    expand  : tactic -> goalstack
    e       : tactic -> goalstack
\end{verbatim}

How does one actually do a goalstack proof then? In most cases, the
application of tactics to the current goal is done with the function
\verb+expand+. In the rare case that one wants to apply an
{\it invalid\/} tactic, then \verb+expandf+ is used. (For an
explanation of invalid tactics, see Chapter 24 of Gordon \& Melham.) The
abbreviation \verb+e+ may also be used to expand a tactic.


\subsection{Undo}

\begin{verbatim}
    b          : unit -> goalstack
    drop       : unit -> proofs
    dropn      : int  -> proofs
    backup     : unit -> goalstack
    restart    : unit -> goalstack
    set_backup : int  -> unit
\end{verbatim}

Often (we are tempted to say {\it usually}!) one takes a wrong path
in doing a proof, or makes a mistake when setting a goal. To undo a step
in the goalstack, the function \verb+backup+ and its abbreviation
\verb+b+ are used. This will restore the goalstack to its previous
state.


To directly back up all the way to the original goal, the function
\verb+restart+ may be used. Obviously, it is also important to get
rid of proof attempts that are wrong; for that there is \verb+drop+,
which gets rid of the current proof attempt, and \verb+dropn+, which
eliminates the top $n$ proof attempts.


Each proof attempt has its own {\it undo-list\/} of previous
states. The undo-list for each attempt is of fixed size (initially
12). If you wish to set this value for the current proof attempt, the
function \verb+set_backup+ can be used. If the size of the backup
list is set to be smaller than it currently is, the undo list will be
immediately truncated. You can not undo a ``proofs-level'' operation, such
as \verb+set_goal+ or \verb+drop+.

\subsection{Viewing the state of the proof manager}

\begin{verbatim}
    p            : unit -> goalstack
    status       : unit -> proofs
    top_goal     : unit -> goal
    top_goals    : unit -> goal list
    initial_goal : unit -> goal
    top_thm      : unit -> thm
\end{verbatim}

To view the state of the proof manager at any time, the functions
\verb+p+ and \verb+status+ can be used. The former only shows
the top subgoals in the current goalstack, while the second gives a
summary of every proof attempt.

To get the top goal or goals of a proof attempt, use \verb+top_goal+
and \verb+top_goals+. To get the original goal of a proof attempt,
use \verb+initial_goal+.

Once a theorem has been proved, the goalstack that was used to derive it
still exists (including its undo-list): its main job now is to
hold the theorem. This theorem can be retrieved with
\verb+top_thm+.

\subsection{Switch focus to a different subgoal or proof attempt}

\begin{verbatim}
    r             : int -> goalstack
    R             : int -> proofs
    rotate        : int -> goalstack
    rotate_proofs : int -> proofs
\end{verbatim}

Often we want to switch our attention to a different goal in the current
proof, or a different proof. The functions that do this are
\verb+rotate+ and \verb+rotate_proofs+, respectively. The abbreviations
\verb+r+ and \verb+R+ are simpler to type in.
\section{The {\tt boss} library}
\label{sec:bossLib}
\newcommand\bossLib{{\tt bossLib}}

The library \bossLib\ marshalls some of the most widely used theorem
proving tools in \HOL\ and provides them with a convenient interface
for interaction. The library currently focuses on three things:
definition of datatypes and functions; high-level interactive proof
operations, and composition of automated reasoners. Loading \bossLib\
commits one to working in a context that already supplies the theories
of booleans, pairs, sums, the option type, arithmetic, and lists.

\subsection{Datatype definition}

There are several useful consequences of an object logic datatype
definition: structural induction, rewrite rules for constructors,
\etc\ However, these have not traditionally been automatically derived
at the invocation of the definition package: the user would have to
build the required theorems by explicitly invoking various proof
procedures.  To remedy this, \bossLib\ offers the \verb+Hol_datatype+
function.  This function allows for the definition of mutually
recursive types, nested recursive types and record types.  The syntax
of declarations that \verb+Hol_datatype+ accepts is found in Table
\ref{datatype}.

\newcommand{\ident}      {\mbox{\it ident}}
\newcommand{\clause}      {\mbox{\it clause}}
\newcommand{\type}       {\mbox{\it hol\_type}}
{
\newcommand{\binding} {\mbox{\it binding}}
\newcommand{\recdspec}  {\mbox{\it record-spec}}
\newcommand{\constr} {\mbox{\it constructor-spec}}

\begin{table}[htbp]
\begin{center}
\begin{tabular}{|rcl|}
\hline
\multicolumn{3}{|l|}
{\texttt{Hol\_datatype `}[\binding\ \texttt{;}]* \binding\texttt{`}}\\
& &\\
\binding & \verb+::=+ & \ident\ \verb+=+ \constr\\
         & \verb+|+ & \ident\ \verb+=+ \recdspec\\
& & \\
\constr & \verb+::=+ & [\clause\ \verb+|+]* \clause \\
& & \\
\clause & \verb+::=+ & \ident \\
        & \verb+|+ & \ident\ \verb+of+\ [\type\ \verb+=>+]* \type\\
& & \\
\recdspec & \verb+::=+ & \verb+<|+ [\ident\ \verb+:+ \type\ \verb+;+]*
                                   \ident\ \verb+:+ \type\ \verb+|>+\\

\hline
\end{tabular}
\caption{Datatype Declaration}\label{datatype}
\end{center}
\end{table}
}
There is an underlying database of datatype facts that supports the
activities of \verb+bossLib+. This database already contains the
relevant entries for the types \verb+bool+, \verb+prod+, \verb+num+,
\verb+option+, and \verb+list+.  When a datatype is defined by
\verb+Hol_datatype+, the following information is derived and stored in
the database.

\begin{itemize}
\item initiality theorem for the type
\item injectivity of the constructors
\item distinctness of the constructors
\item structural induction theorem
\item case analysis theorem
\item definition of the `case' constant for the type
\item congruence theorem for the case constant
\item definition of the `size' of the type
\end{itemize}


\subsubsection{Record types}

Record types are convenient ways of bundling together a number of
component types, and giving those components names so as to facilitate
access to them.  Record types are semantically equivalent to big pair
(cross-product) types, but the ability to label the fields with names
of one's own choosing is a great convenience.  Record types as
implemented in \HOL{} are similar to C's {\tt struct} types and to
Pascal's records.

Done correctly, record types provide useful maintainability features.
If one can always access the {\tt fieldn} field of a record type by
simply writing {\tt record.fieldn}, then changes to the type that
result in the addition or deletion of other fields will not invalidate
this reference.  One failing in SML's record types is that they do not
allow the same maintainability as far as (functional) updates of
records are concerned.  The HOL implementation allows one to write
\begin{verbatim}
  rec with fieldn := new_value
\end{verbatim}
which replaces the old value of {\tt fieldn} in the record {\tt rec}
with {\tt new\_value}.  This expression will not need to be changed if
another field is added, modified or deleted from the record's original
definition.

\paragraph{Defining a record type}
Record types are defined with the function \texttt{Hol\_datatype}, as
previously discussed.  For example, to create a record type called
{\tt person} with boolean, string and number fields called {\tt
  employed}, {\tt name} and {\tt age}, one would enter:
\begin{verbatim}
val _ = Hol_datatype `person = <| employed : bool ; age : num ;
                                  name : string
                               |>`;
\end{verbatim}
The order in which the fields are entered is not significant. As well
as defining the type (called {\tt person}), the datatype definition
function also defines two other sets of constants.  These are the
field access functions and functional update functions.  The field
access functions have names of the form
``$\langle$\textsl{record-type\/}$\rangle$\verb|_|$\langle$\textsl{field\/}$\rangle$''.
These functions can be used directly, or one can use standard field
selection notation to access the values of a record's field.  Thus,
one would write the expression: \mbox{\tt ``bob.employed``} in order
to return the value of {\tt bob}'s {\tt employed} field.  The
alternative, \texttt{``person\_employed bob``}, works, but would be
printed using the first syntax, with the full-stop.

The functional update functions are given the names
\mbox{``$\langle$\textsl{record-type}$\rangle$\texttt{\_}%
  $\langle$\textsl{field}$\rangle$\texttt{\_fupd}''} for each field in
the type.  They take two arguments, a function and a record to be
updated.  The function parameter is an endomorphism on the field type,
so that the resulting record is the same as the original, except that
the specified field has had the given function applied to it to
generate the new value for that field.  They can be written with the
keyword \texttt{with} and the \texttt{updated\_by} operator.  Thus
\begin{alltt}
  ``bob with employed updated_by \$~``
\end{alltt} \noindent
is a record value identical to the \texttt{bob} except that the
boolean value in the \texttt{employed} field has been inverted.

Additionally, there is syntactic sugar available to let one write a
record with one of its fields replaced by a specific value.  This is
done by using the \texttt{:=} operator instead of
\texttt{updated\_by}:
\begin{verbatim}
  ``bob with employed := T``
\end{verbatim}
This form is translated at parse-time to be a use of the corresponding
functional update, along with a use of the \textsf{K}-combinator from
the \texttt{combin} theory.  Thus, the above example  is really
\begin{verbatim}
  ``bob with employed updated_by (K T)``
\end{verbatim}
which is in turn a pretty form of
\begin{verbatim}
  ``person_employed_fupd (K T) bob``
\end{verbatim}
If a chain of updates is desired, then multiple updates can be
specified inside \texttt{<|}-\texttt{|>} pairs, separated by
semi-colons, thus:

\begin{verbatim}
  ``bob with <| age := 10; name := "Child labourer" |>``
\end{verbatim}
Both update forms (using \texttt{updated\_by} and \texttt{:=}) can be
used in a chain of updates.

\paragraph{Specifying record literals}

The parser accepts lists of field specifications between
\texttt{<|}-\texttt{|>} pairs without the \texttt{with} keyword.
These translate to sequences of updates of an arbitrary value
(literally, the HOL value \texttt{ARB}), and are treated as literals.
Thus,
\begin{verbatim}
  ``<| age := 21; employed := F; name := "Layabout" |>``
\end{verbatim}

\paragraph{Using the theorems produced by record definition}

As well as defining the type and the functions described above, record
type definition also proves a suite of useful theorems.  These are all
are saved (using {\tt save\_thm}) in the current segment.  Some are
also added to the \texttt{TypeBase}'s simplifications for the type, so
they will be automatically applied when simplifying with the
\texttt{srw\_ss()} \simpset, or with the tactics \texttt{RW\_TAC} and
\texttt{SRW\_TAC} (see Sections~\ref{sec:automated-reasoners}
and~\ref{sec:simpLib}).

All of the theorems are saved under names that begin with the name of
the type.  The list below is a sample of the theorems proved.  The
identifying strings are suffixes appended to the name of the type in
order to generate the final name of the theorem.

\newcommand{\rewruse}{This theorem is installed in the \texttt{TypeBase}.}
\newcommand{\field}[1]{\mbox{\it field}_{#1}}
\newcommand{\update}{\mbox{\tt\_fupd}}

\begin{description}
\item[\texttt{\_accessors}] The definitions of the accessor functions.
  \rewruse
\item[\texttt{\_fn\_updates}] The definitions of the functional update
  functions.
\item[\texttt{\_accfupds}] A theorem stating simpler forms for
  expressions of the form $\field{i}\, (\field{j}\update\;f\; r)$.  If
  $i = j$, then the RHS is $f (\field{i}(r))$, if not, it is $(\field{i}\;r)$.
  \rewruse
\item[\texttt{\_component\_equality}] A theorem stating that $(r_1 =
  r_2) \equiv \bigwedge_i (\field{i}(r_1) = \field{i}(r_2))$.
\item[\texttt{\_fupdfupds}] A thereom stating that $\field{i}\update
  \;f \,(\field{i}\update \;g\;r) = \field{i}\update\;(f \circ g)\;r$.
  \rewruse
\item[\texttt{\_fupdcanon}] A theorem that states commutativity results
  for all possible pairs of field updates.  They are constructed in
  such a way that if used as rewrites, they will canonicalise
  sequences of updates. Thus, for all $i < j$, \[
  \field{j}\update\;f\;(\field{i}\update\;g\;r) =
  \field{i}\update\;g\;(\field{j}\update\;f\;r)
  \] is generated.
 \rewruse
\end{description}

\paragraph{``Big'' records} The size of certain theorems proved in the
record type package increases as the square of the number of fields in
the record.  (In particular, the update canonicalisation and
\texttt{acc\_fupd} theorems have this property.) To avoid inefficieny
with big records, the implementation of record types uses a more
efficient underlying representation when the number of fields grows
too large.  The exact point at which this optimisation is applied is
controlled by the reference variable
\texttt{Datatype.big\_record\_size}.  This value is initialised to 20,
but users can change it as they choose.

Unfortunately, the big record representation has the drawback that
every update and accessor function has two forms: different terms that
are printed the same.  One form is a simple constant, and is the form
produced when a term is parsed.  The other is more complicated, but
allows for the use of smaller theorems when record values are
simplified.  Therefore, it is recommended that new, user-proved
theorems that mention big records' fields or field updates be passed
through a phase of simplification (\texttt{SIMP\_RULE}), applying the
\texttt{TypeBase}'s rewrites, before they are saved.

The pretty-printing of big records can be controlled with the
\texttt{pp\_bigrecs} trace-flag.


\subsection{Support for high-level proof steps}
\label{sec:high-level-proof-steps}

The following functions use information in the database to ease the
application of \HOL's underlying functionality:

\begin{verbatim}
     type_rws     : string -> thm list
     Induct       : tactic
     Cases        : tactic
     Cases_on     : term quotation -> tactic
     Induct_on    : term quotation -> tactic
\end{verbatim}

\begin{itemize}

\item
The function \texttt{type\_rws} will search for the given type
by name in the underlying database and return useful
rewrite rules for that type. The rewrite rules of the
datatype are built from the injectivity and distinctness theorems, along
with the case constant definition. The pre-existing rewrite rules in the
database are already integrated into the simplification sets provided
by \verb+bossLib+; however rewrite rules arising from an invocation of
\verb+Hol_datatype+, or which come from a user-defined theory, will have
to be manually added into the \simpset{}s used by the simplifier.

\item
The \texttt{Induct} tactic makes it convenient to invoke
induction. When it is applied to a goal, the leading universal
quantifier is examined; if its type is that of a known datatype, the
appropriate structural induction tactic is extracted and applied.

\item
The \texttt{Cases} tactic makes it convenient to invoke case
analysis. The leading universal quantifier in the goal is examined; if
its type is that of a known datatype, the appropriate structural
case analysis theorem is extracted and applied.

\item The \texttt{Cases\_on} tactic takes a quotation, which is
parsed into a term $M$, and then $M$ is searched for in the goal. If $M$
is a variable, then a variable with the same name is searched for. Once
the term to split over is known, its type and the associated facts are
obtained from the underlying database and used to perform the case
split. If some free variables of $M$ are bound in the goal, an attempt
is made to remove (universal) quantifiers so that the case split has
force. Finally, $M$ need not appear in the goal, although it should at
least contain some free variables already appearing in the goal. Note
that the \verb+Cases_on+ tactic is more general than \verb+Cases+, but
it does require an explicit term to be given.

\item The \texttt{Induct\_on} tactic takes a quotation, which is
parsed into a term $M$, and then $M$ is searched for in the goal. If $M$
is a variable, then a variable with the same name is searched for. Once
the term to induct on is known, its type and the associated facts are
obtained from the underlying database and used to perform the induction.
If $M$ is not a variable, a new variable $v$ not already occurring in
the goal is created, and used to build a term $v = M$ which the goal is
made conditional on before the induction is performed. First however,
all terms containing free variables from $M$ are moved from the
assumptions to the conclusion of the goal, and all free variables of $M$
are universally quantified. \verb+Induct_on+ is more general than
\verb+Induct+, but it does require an explicit term to be given.

\end{itemize}

Two supplementary entrypoints have been provided for more exotic
inductions:
\begin{description}
\item [\texttt{completeInduct\_on}] performs complete induction on the
  term denoted by the given quotation. Complete induction allows a
  seemingly \footnote{Complete induction and ordinary mathematical
    induction are each derivable from the other.} stronger induction
  hypothesis than ordinary mathematical induction: to wit, when
  inducting on $n$, one is allowed to assume the property holds for
  \emph{all} $m$ smaller than $n$. Formally: $\forall P.\ (\forall x.\
  (\forall y.\ y < x \supset P\, y) \supset P\,x) \supset \forall x.\
  P\,x$. This allows the inductive hypothesis to be used more than
  once, and also allows instantiating the inductive hypothesis to
  other than the predecessor.

\item [\texttt{measureInduct\_on}] takes a quotation, and breaks it
  apart to find a term and a measure function with which to induct.
  For example, if one wanted to induct on the length of a list
  \verb+L+, the invocation \ml{measureInduct\_on~`LENGTH L`}
  would be be appropriate.

\end{description}

\subsection{Function definition}

\begin{verbatim}
    Define   : term quotation -> thm
    xDefine  : string -> term quotation -> thm
    Hol_defn : string -> term quotation -> Defn.defn
\end{verbatim}

The \texttt{Define} function is a general-purpose function definition
mechanism. The \texttt{xDefine} function is identical to
{\small\verb+Define+} except that it takes an explicit name to use when
storing the definition in the current theory. {\small\tt Define}
accepts the following syntax:

\begin{enumerate}

\item Non-recursive definition, varstructs allowed on lhs.
\begin{verbatim}
         Define `f w (x, y, z) = x + y / w + z`;
\end{verbatim}

\item Primitive recursive (or non-recursive) over known datatype.

\begin{verbatim}
 Define
     `(fold b f [] = b) /\
      (fold b f (h::t) = f h (fold b f t))`;

\end{verbatim}

\item Non-recursive definition, over complex patterns:

\begin{verbatim}
Define
    `(g (0,x,y,z) = 1)
  /\ (g (w,0,y,z) = 2)
  /\ (g (w,x,0,z) = 3)
  /\ (g (w,x,y,0) = 4)`;
\end{verbatim}

\item Recursions (not mutual or nested) that aren't handled by 2.

\begin{verbatim}
  Define `(flatten  []           = [])
     /\   (flatten ([]::rst)     = flatten rst)
     /\   (flatten ((h::t)::rst) = h::flatten(t::rst))`;
\end{verbatim}

\item Nested recursions.
\begin{verbatim}
 Define `N x = if x>100 then x-10 else N(N(x+11))`;
\end{verbatim}

\item Mutual recursion.
\begin{verbatim}
  xDefine "even_odd"
     `(even 0 = T)
  /\  (even (SUC n) = odd n)
  /\  (odd 0 = F)
  /\  (odd (SUC n) = even n)`;
\end{verbatim}

\item Schematic definitions (mutual and nested recursive schemata are
         accepted).
\begin{verbatim}
      Define `While s = if B s then While (C s) else s`;
\end{verbatim}
\end{enumerate}

For complex recursions, {\small\verb+Define+} attempts to find a measure
under which recursive calls become smaller (and to prove that they do
indeed become smaller). Currently, it examines the domain type of the
function being defined and synthesizes a ``size'' measure.  Then it does
some basic simplifications and then attempts to automatically prove the
termination constraints.  If this termination proof fails, then the
definition attempt fails. If the termination proof succeeds, an
induction theorem for the function is also automatically derived and
stored in the current theory.

\noindent {\bf Example.} Invoking
\begin{verbatim}
      Define
        `(gcd 0 y = y)
    /\   (gcd (SUC x) 0 = SUC x)
    /\   (gcd (SUC x) (SUC y) =
             if y <= x then gcd (x-y)   (SUC y)
                       else gcd (SUC x) (y-x))`;
\end{verbatim}
proves all termination conditions and stores the theorem
\begin{verbatim}
      |- (gcd 0 y = y)           /\
         (gcd (SUC x) 0 = SUC x) /\
         (gcd (SUC x) (SUC y) =
              if y <= x then gcd (x - y) (SUC y)
                        else gcd (SUC x) (y - x))
\end{verbatim}
\noindent in the current theory under the name \verb+"gcd_def"+ and
also stores the theorem
\begin{verbatim}
          !P. (!y. P 0 y)       /\
              (!x. P (SUC x) 0) /\
              (!x y. (~(y <= x) ==> P (SUC x) (y - x)) /\
                       (y <= x  ==> P (x - y) (SUC y))
                        ==> P (SUC x) (SUC y))
                 ==>
                   !v v1. P v v1.
\end{verbatim}
\noindent in the current theory under the name \verb+"gcd_ind"+ before
returning the requested recursion equations.

Recall that, if the termination proof fails, an invocation of
\verb+Define+  (or \verb+xDefine+) fails. In such situations, the \ML\
function \verb+Hol_defn+ should be used.

\begin{verbatim}
   Hol_defn     : string -> term quotation -> Defn.defn
   WF_REL_TAC   : Defn.defn -> term quotation -> tactic
\end{verbatim}

\verb+Hol_defn+ makes the requested definition, but defers the proof of
termination to the user. For setting up termination proofs, there are
several useful entrypoints, namely

\begin{verbatim}
   Defn.tgoal  : Defn.defn -> GoalstackPure.proofs
   Defn.tprove : Defn.defn * tactic -> thm * thm
\end{verbatim}

{\small\verb+Defn.tgoal+} is analogous to {\small\verb+set_goal+} and
{\small\verb+Defn.tprove+} is analogous to {\small\verb+prove+}.

\noindent {\bf Example.} An invocation of {\small\verb+Define+} on
the following equations for Quicksort will currently fail, since the
termination proof is beyond the capabilities of our naive termination
prover. Instead, we make an application of {\small\verb+Hol_defn+}:

\begin{verbatim}
    val qsort_def =
      Hol_defn "qsort"
        `(qsort r [] = []) /\
         (qsort r (h::t) =
             APPEND (qsort r (FILTER (\x. r x h) t))
               (h :: qsort r (FILTER (\x. ~(r x h)) t)))`;
\end{verbatim}
which returns a {\small\verb+defn+}, but does not try to prove
termination. Although it is possible to directly work with elements of
type {\small\verb+defn+}, it is more convenient to invoke
`{\small\tt Defn.tgoal qsort\_def}', which sets up a termination
proof in a goalstack. The goal is just to get the unrestricted recursion
equations and induction theorem.

\begin{verbatim}
Defn.tgoal qsort_def;

> val it =
>    Proof manager status: 1 proof.
>    1. Incomplete:
>         Initial goal:
>         ((qsort r [] = []) /\
>          (qsort r (h::t) =
>           APPEND (qsort r (FILTER (\x. r x h) t))
>             (h::qsort r (FILTER (\x. ~r x h) t)))) /\
>         !P.
>           (!r. P r []) /\
>           (!r h t. P r (FILTER (\x. r x h) t) /\
>                    P r (FILTER (\x. ~r x h) t) ==> P r (h::t))
>           ==> !v v1. P v v1
\end{verbatim}

How to proceed? The function {\small\verb+WF_REL_TAC+} now shows its
utility. When given a {\small\verb+defn+} and a quotation denoting a
termination relation for the function, {\small\verb+WF_REL_TAC+}
initiates the termination proof. For our example, we obtain two subgoals
both of which are easy to prove.

\begin{verbatim}
    - e (WF_REL_TAC qsort_def `measure (LENGTH o SND)`
>   OK..
>
>   2 subgoals:
>   val it =
>      !t h r. LENGTH (FILTER (\x. r x h) t) < LENGTH (h::t)
>
>
>      !t h r. LENGTH (FILTER (\x. ~r x h) t) < LENGTH (h::t)
\end{verbatim}


Both goals are provable; once the proof is completed, we can encapsulate
it with {\small\verb+Defn.tprove+}, which takes a
{\small\verb+defn+}, builds a termination goal from it, applies the
given tactic, and, if the initial goal is proved, returns a pair
comprising the requested equations and the induction theorem.

\begin{verbatim}
   val (qsort_eqns,qsort_ind) =
      Defn.tprove
       (qsort_def,
        WF_REL_TAC qsort_def `measure (LENGTH o SND)`
        THEN ...);

   > val qsort_eqns =
   >  |- (qsort r [] = []) /\
   >     (qsort r (h::t) =
   >        APPEND (qsort r (FILTER (\x. r x h) t))
   >           (h::qsort r (FILTER (\x. ~r x h) t)))  : thm

   >  val qsort_ind =
   >   |- !P.
   >      (!r. P r []) /\
   >      (!r h t. P r (FILTER (\x. r x h) t) /\
   >               P r (FILTER (\x. ~r x h) t) ==> P r (h::t))
   >      ==> !v v1. P v v1
\end{verbatim}

\subsection{Automated reasoners}
\label{sec:automated-reasoners}

\verb+bossLib+ brings together the most powerful reasoners in \HOL{} and
tries to make it easy to compose them in a simple way. We take our basic
reasoners from \verb+mesonLib+, \verb+simpLib+, and \verb+numLib+,
but the point of \verb+bossLib+ is to provide a layer of abstraction so
the user has to know only a few entrypoints.\footnote{In the mid 1980's
Graham Birtwistle advocated such an approach, calling it `Ten Tactic
HOL'.} (These underlying libraries, and others providing similarly
powerful tools are described in detail in sections below.)

\begin{verbatim}
    PROVE      : thm list -> term quotation -> thm
    PROVE_TAC  : thm list -> tactic

    DECIDE     : term quotation -> thm
    DECIDE_TAC : tactic
\end{verbatim}

The inference rule \texttt{PROVE} (and the corresponding tactic
\texttt{PROVE\_TAC}) takes a list of theorems and a quotation, and
attempts to prove the term using a first order reasoner.  The
\texttt{PROVE} entry-points refer to the \texttt{meson} library, which
is further described in Section~\ref{sec:mesonLib} below. The
inference rule \texttt{DECIDE} (and the corresponding tactic
\texttt{DECIDE\_TAC}) applies a decision procedure that (at least)
handles statements of linear arithmetic.

\begin{verbatim}
    RW_TAC   : simpset -> thm list -> tactic
    SRW_TAC  : ssdata list -> thm list -> tactic
    &&       : simpset * thm list -> simpset  (* infix *)
    std_ss   : simpset
    arith_ss : simpset
    list_ss  : simpset
    srw_ss   : unit -> simpset
\end{verbatim}

The rewriting tactic \texttt{RW\_TAC} works by first adding the given
theorems into the given \simpset; then it simplifies the goal as much
as possible; then it performs case splits on any conditional
expressions in the goal; then it repeatedly (1) eliminates all
hypotheses of the form $v = M$ or $M = v$ where $v$ is a variable not
occurring in $M$, (2) breaks down any equations between constructor
terms occurring anywhere in the goal. Finally, \texttt{RW\_TAC} lifts
\texttt{let}-expressions within the goal so that the binding equations
appear as abbreviations\index{abbreviations!tactic-based proof} in the
assumptions.

The tactic \texttt{SRW\_TAC} is similar to \texttt{RW\_TAC}, but works
with respect to an underlying \simpset (accessible through the
function \texttt{srw\_ss}) that is updated as new context is loaded.
This \simpset{} can be augmented through the addition of ``\simpset{}
fragments'' (\texttt{ssdata} values) and theorems.  In situations
where there are many large types stored in the system,
\texttt{RW\_TAC}'s performance can suffer because it repeatedly adds
all of the rewrite theorems for the known types into a \simpset{}
before attacking the goal.  On the other hand, \texttt{SRW\_TAC} loads
rewrites into the \simpset{} underneath \texttt{srw\_ss()} just once,
making for faster operation in this situation.

\ml{bossLib} provides a number of simplification sets. In general,
these are extended versions of those found in \verb+simpLib+. The
simpset for pure logic, sums, pairs, and the \verb+option+ type is
named \verb+std_ss+. The simpset for arithmetic is named
\verb+arith_ss+, and the simpset for lists is named \verb+list_ss+.
The simpsets provided by {\tt bossLib} strictly increase in strength:
{\tt std\_ss} is contained in {\tt arith\_ss}, and {\tt arith\_ss} is
contained in {\tt list\_ss}.  The infix combinator \verb+&&+ is used
to build a new \simpset{} from a given \simpset{} and a list of
theorems. \HOL's simplification technology is described further in
Section~\ref{sec:simpLib} below and in the \REFERENCE.

\begin{verbatim}
    STP_TAC  : simpset -> tactic -> tactic
    ZAP_TAC  : simpset -> thm list -> tactic
\end{verbatim}

The compound reasoners of \verb+bossLib+ take a basic approach: they
simplify the goal as much as possible with \verb+RW_TAC+ and then a
`finishing' tactic is applied. The primitive entrypoint for this is
\texttt{STP\_TAC}. Currently, the most powerful reasoner is
\texttt{ZAP\_TAC}, which features a finishing tactic that first
tries a tautology checking tactic; if that fails, \verb+DECIDE_TAC+ is
called; if that fails, \verb+PROVE_TAC+ is called with the second
argument. Although this general approach (simplify as much as possible,
then apply automated reasoners in sequence) is crude, we have found that
it allows one to make good progress in a high percentage of proof
situations.

\begin{verbatim}
    by : term quotation * tactic -> tactic (* infix 8 *)
    SPOSE_NOT_THEN : (thm -> tactic) -> tactic
\end{verbatim}

The function \texttt{by} is an infix operator that takes a quotation
and a tactic $tac$. The quotation is parsed into a term $M$. When the
invocation ``$M\texttt{ by } \mathit{tac}$'' is applied to a goal
$(A,g)$, a new subgoal $(A,M)$ is created and $tac$ is applied to it.
If the goal is proved, the resulting theorem is broken down and added
to the assumptions of the original goal; thus the proof proceeds with
the goal $((M::A), g)$. (Note however, that case-splitting will happen
if the breaking-down of $\ \vdash M$ exposes disjunctions.) Thus
\texttt{by} allows a useful style of `assertional' or `Mizar-like'
reasoning to be mixed with ordinary tactic proof.\footnote{Proofs in
  the Mizar system are readable documents, unlike almost all
  tactic-based proofs.}


\texttt{SPOSE\_NOT\_THEN} initiates a proof by
contradiction by assuming the negation of the goal and driving the
negation inwards through quantifiers. It provides the resulting theorem
as an argument to the supplied function, which will use the theorem to
build and apply a tactic.

\section{The \texttt{meson} library}
\label{sec:mesonLib}

\index{decision procedures!first-order logic, meson@first-order logic, \ml{meson}}
The \texttt{meson} library is an implementation of the
model-elimination method for finding proofs of goals in first-order
logic.  There are three main entry-points:

\begin{verbatim}
   MESON_TAC     : thm list -> tactic
   ASM_MESON_TAC : thm list -> tactic
   GEN_MESON_TAC : int -> int -> int -> thm list -> tactic
\end{verbatim}

Each of these tactics attempts to prove the goal.  They will either
succeed in doing so, or fail with a ``depth exceeded'' exception.  If
the branching factor in the search-space is high, the \texttt{meson}
tactics may also take a very long time to reach the maximum depth.

All of the \texttt{meson} tactics take a list of theorems.  These
extra facts are used by the decision procedure to help prove the goal.
\texttt{MESON\_TAC} ignores the goal's assumptions; the other two
entry-points include the assumptions as part of the sequent to be
proved.

The extra parameters to \ml{GEN\_MESON\_TAC} provide extra control of
the behaviour of the iterative deepening that is at the heart of the
search for a proof.  In any given iteration, the algorithm searches
for a proof of depth no more than a parameter $d$.  The default
behaviour for \ml{MESON\_TAC} and \ml{ASM\_MESON\_TAC} is to start $d$
at 0, to increment it by one each time a search fails, and to fail if
$d$ exceeds the value stored in the reference value
\ml{mesonLib.max\_depth}.  By way of contrast,
\ml{GEN\_MESON\_TAC~min~max~step} starts $d$ at \ml{min}, increments
it by \ml{step}, and gives up when $d$ exceeds \ml{max}.

\section{The \texttt{simp} library}
\label{sec:simpLib}



\section{The {\tt num} library}
\label{sec:numLib}
\index{decision procedures!Presburger arithmetic over natural numbers}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "description"
%%% End:
