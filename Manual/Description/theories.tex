\chapter{Theories}\label{HOLtheories}

\newcommand{\konst}[1]{\ensuremath{\mbox{\small{\textbf{\sf{#1}}}}}}
\newcommand{\nil}{\mathbf{[} \;\mathbf{]}}
\newcommand{\cons}[2]{{#1}\mathbf{:}\mathbf{:}{#2}}

\index{theories, in HOL logic@theories, in \HOL{} logic!hierarchies
of} The \HOL{} system provides a collection of theories to base
verification tools or further theory development on.  In the rest of
this section, these theories are briefly described.  It is,
unfortunately, not possible to provide a complete list of all the
definitions and theorems in each theory. Therefore, the sections that
follow provide only an overview of the contents of each theory.  For a
complete list of all the axioms, definitions and theorems in \HOL, see
\REFERENCE.


\section{The theory {\tt min}}\label{minTheory}

The starting theory of \HOL{} is the theory \ml{min}.
\index{min, the HOL theory@\ml{min}, the \HOL\ theory|(} 
In this theory, the type constant {\small\verb+bool+} of booleans,
the binary type operator $(\alpha,\beta)${\small\verb+fun+} of functions, and the type
constant {\small\verb+ind+} of individuals are declared. Building on
these types, three primitive constants
\index{constants, in HOL logic@constants, in \HOL\ logic!primitive logical}
\index{primitive constants, of HOL logic@primitive constants, of \HOL\ logic}
are declared: equality, implication, and a choice operator:
\index{ equality, in HOL logic@\ml{=} (equality, in \HOL\ logic)}
\index{equality, in HOL logic@equality, in \HOL\ logic}
\begin{description}
\item [Equality] Equality ({\small\verb+= : 'a -> 'a -> bool+}) is an
  infix operator.
\index{equality, in HOL logic@equality, in \HOL\ logic}
\item [Implication] Implication
  ({\small\verb+==> : bool -> bool -> bool+}) is the 
  \emph{material implication} and is an infix operator that is
  right-associative, \ie, \verb+x ==> y ==> z+ parses to the same term
  as \verb+x ==> (y ==> z)+.
\index{implication, in HOL logic@implication, in \HOL\ logic}
\item [Choice] Equality
and implication are standard predicate calculus notions, but choice is
more exotic: if $t$ is a term having type $\sigma${\small\verb+->bool+},
then {\small\verb+@x.+}$t${\small\verb+ x+} (or, equivalently,
{\small\verb+$@+}$t$) denotes {\it some\/} member of the set whose
characteristic\index{characteristic predicate, of type definitions}
 function is $t$. If the set is empty, then
{\small\verb+@x.+}$t${\small\verb+ x+} denotes an arbitrary member of the
set denoted by $\sigma$. The constant {\small\verb+@+} is a higher order
version of Hilbert's
\index{Hilbert, D.}
\index{epsilon operator}
 $\hilbert$-operator; it is related to the constant
$\iota$ in Church's formulation of higher order logic. For more details,
see Church's
\index{Church, A.}
original paper \cite{Church}, Leisenring's
\index{Leisenring, A.}
book on Hilbert's $\hilbert$-symbol \cite{Leisenring}, or Andrews'
textbook on type theory \cite{Andrews}.
\end{description}

\medskip

\noindent No theorems or axioms are placed in theory \theoryimp{min}.
The primitive rules of inference of \HOL{} depend on the presence of 
\theoryimp{min}.


\section{Basic Theories}

The most basic theories in HOL provide support for a standard
collection of types. The theory \theoryimp{bool} defines the basis of
the \HOL{} logic, including the boolean operations and
quantifiers. On this platform, quite a bit of theorem-proving
infrastructure can already be built. Further basic types are developed
in the theory of pairs (\theoryimp{prod}), disjoint sums
(\theoryimp{sum}), the one-element type (\theoryimp{one}), and the
(\theoryimp{option}) type.


\subsection{The theory \theoryimp{bool}}\label{boolfull}

\index{axioms!primitive, of HOL logic@primitive, of \HOL\ logic|(} At
start-up, the initial theory for users of the \HOL\ system is called
\ml{bool}\index{HOL@\ml{HOL}}, which is constructed when the \HOL\
system is built. The theory \theoryimp{bool} is an extension of the
combination of the ``conceptual'' theories \theory{LOG} and
\theory{INIT}, described in Chapter~\ref{semantics}.  Thus it contains
the four axioms\index{axioms!in bool theory@in \ml{bool} theory} for
higher order logic. These axioms, together with the rules of inference
described in Section~\ref{rules}, constitute the core of the \HOL\
logic.  Because of the way the \HOL\ system evolved from
\LCF,\index{LCF@\LCF}\footnote{To simplify the porting of the LCF
  theorem-proving tools to the HOL system, the HOL logic was made as
  like PP$\lambda$ (the logic built-in to LCF) as possible.} the
particular axiomatization\index{axioms!non-primitive, of HOL
  logic@non-primitive, of \HOL\ logic} of higher order logic it uses
differs from the classical axiomatization due to Church\index{Church,
  A.} \cite{Church}.  The biggest difference is that in Church's
formulation type variables\index{type variables, in HOL logic@type
  variables, in \HOL\ logic!differences from classical} are in the
meta-language, whereas in the \HOL\ logic they are part of the object
language.

The logical constants\index{logical constants, in HOL logic@logical
  constants, in \HOL\ logic} {\small\verb+T+}\index{truth values, in
  HOL logic@truth values, in \HOL\ logic!constants
  for}\index{T@\ml{T}!defined in terms of primitives} (truth),
{\small\verb+F+}\index{F@\ml{F}!defined in terms of primitives}
(falsity), {\small\verb+~+} (negation)\index{ negation, in HOL
  logic@{\small\verb+~+} (negation, in \HOL\ logic)},
{\small\verb+/\+} (conjunction)\index{ conjunction, in HOL
  logic@{\small\verb+/\+} (conjunction, in \HOL\
  logic)}\index{conjunction, in HOL logic@conjunction, in \HOL\
  logic!defined in terms of primitives},
{\small\verb+\/+} (disjunction)\index{ disjunction, in HOL logic@{\small\verb+\/+} (disjunction, in \HOL\ logic)}\index{disjunction, in HOL logic@disjunction, in \HOL\ logic!defined in terms of primitives}, {\small\verb+!+} (universal
  quantification)\index{ universal quantifier, in HOL
    logic@{\small\verb+"!+} (universal quantifier, in \HOL\
    logic)}\index{universal quantifier, in HOL logic@universal
    quantifier, in \HOL\ logic!defined in terms of primitives},
  {\small\verb+?+} (existential quantification)\index{ existential
    quantifier, in HOL logic@{\small\verb+?+} (existential quantifier,
    in \HOL\ logic)}\index{existential quantifier, in HOL
    logic@existential quantifier, in \HOL\ logic!defined in terms of
    primitives} and {\small\verb+?!+} (unique existence
  quantifier)\index{ exists unique, in HOL logic@{\small\verb+?"!+}
    (exists unique, in \HOL\ logic)}\index{exists unique, in HOL
    logic@exists unique, in \HOL\ logic!defined in terms of
    primitives} can all be defined in terms of
  equality\index{equality, in HOL logic@equality, in \HOL\ logic},
  implication and choice.  The definitions listed below are fairly
  standard; each one is preceded by its \ML\ name.  Later definitions
  sometimes build on earlier ones.


\begin{hol}
\index{truth values, in HOL logic@truth values, in \HOL\ logic!definition of}
\index{T_DEF@\ml{T\_DEF}}
\index{T@\ml{T}!definitional axiom for}
\index{disjunction, in HOL logic@disjunction, in \HOL\ logic!definitional axiom for}
\index{conjunction, in HOL logic@conjunction, in \HOL\ logic!definitional axiom for}
\index{iff, in HOL logic@iff, in \HOL\ logic!definitional axiom for}
\index{negation, in HOL logic@negation, in \HOL\ logic!definitional axiom for}
\index{exists unique, in HOL logic@exists unique, in \HOL\ logic}
\index{F@\ml{F}!axiom for}
\index{F@\ml{F}!definitional axiom for}
\index{ exists unique, in HOL logic@{\small\verb+?"!+} (exists unique, in \HOL\ logic)}
\index{T_DEF@\ml{T\_DEF}}
\index{FORALL_DEF@\ml{FORALL\_DEF}}
\index{EXISTS_DEF@\ml{EXISTS\_DEF}}
\index{AND_DEF@\ml{AND\_DEF}}
\index{OR_DEF@\ml{OR\_DEF}}
\index{F_DEF@\ml{F\_DEF}}
\index{NOT_DEF@\ml{NOT\_DEF}}
\index{EXISTS_UNIQUE_DEF@\ml{EXISTS\_UNIQUE\_DEF}}
\index{conjunction, in HOL logic@conjunction, in \HOL\ logic!definitional axiom for}
\index{disjunction, in HOL logic@disjunction, in \HOL\ logic!definitional axiom for}
\index{equality, in HOL logic@equality, in \HOL\ logic!primitive axiom for}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL\ logic!definitional axiom for}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL\ logic!definitional axiom for}
\index{exists unique, in HOL logic@exists unique, in \HOL\ logic!definitional axiom for}
\begin{verbatim}
   T_DEF              |- T  = ((\x:bool. x) = (\x. x))

   FORALL_DEF         |- !  = \P:'a->bool. P = (\x. T)

   EXISTS_DEF         |- ?  = \P:'a->bool. P($@ P)

   AND_DEF            |- /\ = \t1 t2. !t. (t1 ==> t2 ==> t) ==> t

   OR_DEF             |- \/ = \t1 t2. !t. (t1 ==> t) ==> (t2 ==> t) ==> t

   F_DEF              |- F  = !t. t

   NOT_DEF            |- ~  = (\t. t ==> F)

   EXISTS_UNIQUE_DEF  |- ?! = (\P. $? P /\ (!x y. P x /\ P y ==> (x = y)))
\end{verbatim}
\end{hol}


There are four
\index{universal quantifier, in HOL logic@universalquantifier,
       in \HOL\ logic!in four primitive axioms}
axioms in the theory {\small\verb+bool+}\index{bool, the HOL
theory@\ml{bool}, the \HOL\ theory}; the first three are the following:

\begin{hol}
\index{BOOL_CASES_AX@\ml{BOOL\_CASES\_AX}}
\index{ETA_AX@\ml{ETA\_AX}}
\index{SELECT_AX@\ml{SELECT\_AX}}
\index{implication, in HOL logic@implication, in \HOL\ logic!primitive axiom for}
\index{ choice function, in HOL logic@{\small\verb+"@+} (choice function, in \HOL\ logic)}
\index{choice axiom}
\index{choice operator, in HOL logic@choice operator, in \HOL\ logic!primitive axiom for}
\begin{verbatim}
   BOOL_CASES_AX   |- !t. (t = T) \/ (t = F)

   ETA_AX          |- !t. (\x. t x) = t

   SELECT_AX       |- !P:'a->bool x. P x ==> P($@ P)
\end{verbatim}\end{hol}

\noindent
The fourth and last axiom of the \HOL\ logic is the Axiom of
Infinity\index{axiom of infinity}. Its statement is phrased in terms of
the function properties {\small\verb+ONE_ONE+} and {\small\verb+ONTO+}. The
definitions are:

\begin{hol}
\index{ONE_ONE_DEF@\ml{ONE\_ONE\_DEF}}
\index{ONTO_DEF@\ml{ONTO\_DEF}}
\index{one-to-one predicate, in HOL logic@one-to-one predicate, in \HOL\ logic!definitional axiom for}
\index{onto predicate, in HOL logic@onto predicate, in \HOL\ logic!definitional axiom for}
\begin{verbatim}
   ONE_ONE_DEF |- ONE_ONE f = (!x1 x2. (f x1 = f x2) ==> (x1 = x2))

   ONTO_DEF    |- ONTO f    = (!y. ?x. y = f x)
\end{verbatim}\end{hol}

\noindent The Axiom of Infinity\index{axioms!in bool theory@in \ml{bool} theory} is
%
{\begin{hol}
\index{INFINITY_AX@\ml{INFINITY\_AX}}
\index{axiom of infinity}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL\ logic!in infinity axiom}
\begin{verbatim}
  INFINITY_AX  |- ?f:ind->ind. ONE_ONE f /\ ~(ONTO f)
\end{verbatim}\end{hol}}
%
\noindent
This asserts that there exists a one-to-one map from {\small\verb+ind+} to
itself that is not onto. This implies that the type {\small\verb+ind+}
denotes an infinite set.\index{axioms!primitive, of HOL logic@primitive, of \HOL\ logic|)}

The three other axioms of the theory {\small\verb+bool+}, the rules of
inference in Section~\ref{rules} and the Axiom of Infinity are,
together, sufficient for developing all of standard mathematics. Thus,
in principle, the user of the \HOL\ system should never need to make a
non-definitional\index{axioms!dispensibility of
adding}\index{definitional theories} theory. In practice, it is often
very tempting to take the risk of introducing new axioms because
deriving them from definitions can be tedious---proving that `axioms'
follow from definitions amounts to proving their consistency.

\paragraph {Further definitions}

The theory {\small\verb+bool+} also supplies the definitions of a number of
useful constants.
\begin{hol}
\index{LET_DEF@\ml{LET\_DEF}}
\index{COND_DEF@\ml{COND\_DEF}}
\index{COND@\ml{COND}}
\index{LET@\ml{LET}}
\index{conditional predicate, in HOL logic@conditional predicate, in \HOL\ logic!definitional axiom for}
\index{conditionals, in HOL logic@conditionals, in \HOL\ logic}
\begin{verbatim}
   LET_DEF  |- LET  = \f x. f x
   COND_DEF |- COND = \t t1 t2.@x.((t=T)==>(x=t1))/\((t=F)==>(x=t2))
   IN_DEF   |- IN   = \x (f:'a -> bool). f x
\end{verbatim}
\end{hol}

The constant {\small\verb+LET+}\index{let-terms, in HOL logic@\ml{let}-terms, in \HOL\ logic!constant for} is used in representing terms
containing local variable bindings (\ie\
{\small\verb+let+}-terms)
\index{let-terms, in HOL logic@\ml{let}-terms,in \HOL\ logic!definitional axiom for}. 
For example, the concrete syntax
{\small\verb+let v = M in N+} is translated by the parser to the term
{\small\verb+LET (\v.N) M+}. For the full description of how
{\small\verb+let+} expressions are translated, see Section \ref{prod}.

The constant {\small\verb+COND+} is used in representing conditional
expressions. The concrete syntax \index{terms, in HOL logic@terms, in
  \HOL\ logic!conditional}\index{conditional predicate, in HOL
  logic@conditional predicate, in \HOL\ logic}\index{conditionals, in
  HOL logic@conditionals, in \HOL\ logic} \ml{`if $t_1\ $then$\ t_2\
  $else$\ t_3$`} abbreviates the application \ml{COND\ $t_1\ t_2\
  t_3$}. The syntax \ml{$t_1\; $=>$\;t_2\;$|$\;t_3$} is also
permitted. The system prints out conditionals in the "if $t_1$ then
$t_2$ else $t_3$" form.

The constant {\small\verb+IN+} (written as an infix) is the basis of
the modelling of sets by their characteristic functions.  The term
$x\texttt{ IN }P$ can be read as ``$x$ is an element of the set
$P$'', or (more in line with its definition) as ``the predicate $P$ is
true of $x$''.

Finally, the polymorphic constant {\small\verb+ARB+}$:\alpha$ denotes 
a fixed but arbitrary element. {\small\verb+ARB+} is occasionally 
useful when attempting to deal with the issue of partiality.

\subsubsection{Restricted quantifiers}\label{res-quant}

\index{restricted quantification}
%
The theory \theoryimp{bool} also defines constants that implement
\emph{restricted quantification}. This provides a means of simulating
subtypes and dependent types with predicates. The most heavily used
are restrictions of the existential and universal quantifiers:
%
\begin{verbatim}
  RES_FORALL_DEF |- RES_FORALL = \P m. !x. x IN P ==> m x

  RES_EXISTS_DEF |- RES_EXISTS = \P m. ?x. x IN P /\ m x

  RES_ABSTRACT_DEF |- (!P m x. x IN P ==> (RES_ABSTRACT P m x = m x) /\
                      (!P m1 m2.
                          (!x. x IN P ==> (m1 x = m2 x)) ==>
                           (RES_ABSTRACT P m1 = RES_ABSTRACT P m2)
\end{verbatim}
%
The definition of \ml{RES\_ABSTRACT} is a characterising formula, rather
than a direct equation.  There are two important properties
\begin{itemize}
\item if $y$ is an element of $P$ then $(\bs{}x :: P.\; M)
  y = M[y/x]$
\item If two restricted abstractions agree on all values over their
  (common) restricting set, then they are equal.
\end{itemize}

For completeness, restricted versions of unique existence and
indefinite description are provided, although hardly used.
\begin{verbatim}
  RES_EXISTS_UNIQUE_DEF
    |- RES_EXISTS_UNIQUE = \P m. (?x :: P. m x) /\
                                 (!x y :: P. m x /\ m y ==> (x = y))

   RES_SELECT_DEF
     |- RES_SELECT = \P m. @x. x IN P /\ m x
\end{verbatim}

The definition of \ml{RES\_EXISTS\_UNIQUE} uses the restricted
quantification syntax with the {\small\verb+::+} symbol, referring to
the earlier definitions \ml{RES\_EXISTS} and \ml{RES\_FORALL}.
The \texttt{::} syntax is used with restricted quantifiers to allow
arbitrary predicates to restrict binding variables. The \HOL{} parser
allows restricted quantification of all of a sequence of binding
variables by putting the restriction at the end of the sequence, thus
with a universal quantification: 
%
\[
\forall x \, y \, z \, {\tt ::} \; P \, . \; Q(x,y,z)
\]
%
Here the predicate $P$ restricts all of $x$, $y$ and $z$.

\subsubsection{Derived syntactic forms}\label{derived-terms}

\index{type checking, in HOL logic@type checking, in \HOL\
  logic!special forms in|(} \index{quotation, in HOL logic@quotation,
  in \HOL\ logic!of non-primitive terms|(} The \HOL{} quotation
parser\index{quotation, in HOL logic@quotation, in \HOL\ logic!parser
  for} can translate various standard logical notations\index{parsing,
  of HOL logic@parsing, of \HOL\ logic!of standard notations} into
primitive terms. For example, if \ml{+} has been declared an
infix\index{infixes, in HOL logic@infixes, in \HOL\ logic} (as
explained in Section~\ref{theoryfns}) (as it is when
\ml{arithmeticTheory} has been loaded), then \ml{``x+1``} is
translated to \ml{``\$+~x~1``}. The escape character \ml{\$}\index{
  escape, in HOL logic parser@\ml{\$} (escape, in \HOL\ logic
  parser)}\index{declared constants, in HOL logic@declared constants,
  in \HOL\ logic}\index{infixes, in HOL logic@infixes, in \HOL\ logic}
suppresses the infix behaviour of \ml{+} and prevents the quotation
parser getting confused.  In general, \ml{\$} can be used to suppress
any special syntactic behaviour a token (such as \texttt{if},
\texttt{+} or \texttt{let}) \index{tokens@tokens!supressing parsing
  behaviour of} might have. This is illustrated in the table below, in
which the terms in the column headed \textit{`\ML{} quotation'} are
translated by the quotation parser to the corresponding terms in the
column headed \textit{`Primitive term'}.  Conversely, the terms in the
latter column are always printed in the form shown in the former one.
The \ML{} constructor expressions in the rightmost column evaluate to
the same values (of type \ml{term}) as the other quotations in the
same row.

\bigskip

\begin{center}
\index{choice operator, in HOL logic@choice operator, in \HOL\ logic!syntax of}
\index{ negation, in HOL logic@{\small\verb+~+} (negation, in \HOL\ logic)}
\index{ disjunction, in HOL logic@{\small\verb+\/+} (disjunction, in \HOL\ logic)}
\index{ conjunction, in HOL logic@\texttt{\small/\bs} (conjunction, in \HOL\ logic)}
\index{ implication, in HOL logic@{\small\verb+==>+} (implication, in \HOL\ logic)}
\index{ equality, in HOL logic@\ml{=} (equality, in \HOL\ logic)}
\index{ universal quantifier, in HOL logic@{\small\verb+"!+} (universal quantifier, in \HOL\ logic)}
\index{ existential quantifier, in HOL logic@{\small\verb+?+} (existential quantifier, in \HOL\ logic)}
\index{ choice function, in HOL logic@{\small\verb+"@+} (choice function, in \HOL\ logic)}
\index{terms, in HOL logic@terms, in \HOL\ logic!non-primitive}
\index{terms, in HOL logic@terms, in \HOL\ logic!constructors for}
\index{conditional predicate, in HOL logic@conditional predicate, in \HOL\ logic}
\index{conditionals, in HOL logic@conditionals, in \HOL\ logic}
\index{conjunction, in HOL logic@conjunction, in \HOL\ logic!constructor for}
\index{disjunction, in HOL logic@disjunction, in \HOL\ logic!constructor for}
\index{equality, in HOL logic@equality, in \HOL\ logic!syntax of}
\index{negation, in HOL logic@negation, in \HOL\ logic!syntax of}
\index{negation, in HOL logic@negation, in \HOL\ logic!constructor for}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL\ logic!syntax of}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL\ logic!syntax of}
\index{implication, in HOL logic@implication, in \HOL\ logic!syntax of}
\index{mk_neg@\ml{mk\_neg}}
\index{mk_disj@\ml{mk\_disj}}
\index{mk_conj@\ml{mk\_conj}}
\index{mk_imp@\ml{mk\_imp}}
\index{mk_eq@\ml{mk\_eq}}
\index{mk_forall@\ml{mk\_forall}}
\index{mk_exists@\ml{mk\_exists}}
\index{mk_select@\ml{mk\_select}}
\index{mk_cond@\ml{mk\_cond}}
\index{mk_let@\ml{mk\_let}}
\index{conjunction, in HOL logic@conjunction, in \HOL\ logic!syntax of}
\begin{tabular}{|l|l|l|l|} \hline
\multicolumn{4}{|c|}{ } \\
\multicolumn{4}{|c|}{\bf Non-primitive terms} \\
\multicolumn{4}{|c|}{ } \\
{\it Kind of term} & {\it \ML\ quotation} &
{\it Primitive term} &
{\it Constructor expression} \\ \hline
 & & & \\
 & {\small\verb+~+}$t$ & {\small\verb+$~ +}$t$ & {\small\verb+mk_neg(+}$t${\small\verb+)+} \\ \hline
Disjunction & $t_1${\small\verb+\/+}$t_2$ & {\small\verb+$\/ +}$t_1\ t_2$ &
{\small\verb+mk_disj(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
Conjunction & $t_1${\small\verb+/\+}$t_2$ & {\small\verb+$/\ +}$t_1\ t_2$ &
{\small\verb+mk_conj(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\
\hline
%
Implication & $t_1${\small\verb+==>+}$t_2$ & {\small\verb+$==> +}$t_1\ t_2$ &
{\small\verb+mk_imp(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
Equality & $t_1${\small\verb+=+}$t_2$ & {\small\verb+$= +}$t_1\ t_2$ &
{\small\verb+mk_eq(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
$\forall$-quantification & {\small\verb+!+}$x${\small\verb+.+}$t$ &
{\small\verb+$!(\+}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_forall(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
$\exists$-quantification & {\small\verb+?+}$x${\small\verb+.+}$t$ &
{\small\verb+$?(\+}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_exists(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
$\hilbert$-term & {\small\verb+@+}$x${\small\verb+.+}$t$ &
{\small\verb+$@(\+}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_select(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
Conditional\index{COND@\ml{COND}} & {\small\verb+if +}$t\ ${\small\verb+then +}$t_1${\small\verb+ else +}$t_2$ &
{\small\verb+COND +}$t\ t_1\ t_2$ & {\small\verb+mk_cond(+}$t${\small\verb+,+}$t_1${\small\verb+,+}$t_2${\small\verb+)+}
 \\ \hline
%
{\small\verb+let+}-expression & {\small\verb+let +}$x${\small\verb+=+}$t_1${\small\verb+ in +}$t_2$ &
{\small\verb+LET(\+}$x${\small\verb+.+}$t_2${\small\verb+)+}$t_1$ &
{\small\verb+mk_let(\+}$x${\small\verb+.+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
\end{tabular}
\end{center}

\bigskip

There are constructors, destructors and indicators for all the obvious
constructs. (Indicators, \eg\ \ml{is\_neg}, return truth values
indicating whether or not a term belongs to the syntax class in
question.) In addition to the constructors listed in the table there
are constructors, destructors, and indicators for pairs and lists,
namely \ml{mk\_pair}\index{mk_pair@\ml{mk\_pair}},
\ml{mk\_cons}\index{mk_cons@\ml{mk\_cons}} and
\ml{mk\_list}\index{mk_list@\ml{mk\_list}} (see \REFERENCE).  The
constants {\small\verb+COND+}\index{COND@\ml{COND}} and
{\small\verb+LET+} are explained in Section~\ref{boolfull}.  The
constants {\small\verb+\/+}\index{disjunction, in HOL
  logic@disjunction, in \HOL\ logic!syntax of}, {\small\verb+/\+},
{\small\verb+==>+} and {\small\verb+=+} are examples of {\it
  infixes\/} and represent $\vee$, $\wedge$, $\imp$ and equality,
respectively. If $c$ is declared to be an infix, then the \HOL\ parser
will translate $t_1\ c\ t_2$ to {\small\verb+$+}$c\ t_1\ t_2$.

The constants {\small\verb+!+}, {\small\verb+?+} and {\small\verb+@+}
are examples of \label{binder} \textit{binders}\index{binders, in HOL
logic@binders, in \HOL\ logic} and represent $\forall$, $\exists$ and
$\hilbert$, respectively.  If $c$ is declared to be a binder, then the
\HOL\ parser will translate $c\ x${\small\verb+.+}$t$ to the
combination
{\small\verb+$+}$c${\small\verb+(\+}$x${\small\verb+.+}$t${\small\verb+)+}
(\ie\ the application of the constant $c$ to the representation of the
abstraction $\lquant{x}t$)\index{ function abstraction binder, in HOL
logic@{\small\verb+\+} (function abstraction binder, in \HOL\ logic)}.


\begin{center}

\index{variables, in HOL logic@variables, in \HOL\ logic!multiple bound}
\index{list_mk_comb@\ml{list\_mk\_comb}|pin}
\index{list_mk_abs@\ml{list\_mk\_abs}|pin}
\index{list_mk_forall@\ml{list\_mk\_forall}|pin}
\index{list_mk_exists@\ml{list\_mk\_exists}|pin}
\index{combinations, in HOL logic@combinations, in \HOL\ logic!abbreviation for multiple}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL\ logic!abbreviation for multiple}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL\ logic!abbreviation for multiple}
\begin{tabular}{|l|l|l|} \hline
\multicolumn{3}{|c|}{ } \\
\multicolumn{3}{|c|}{\bf Syntactic abbreviations} \\
\multicolumn{3}{|c|}{ } \\
{\it Abbreviated term} & {\it Meaning} &
{\it Constructor expression} \\ \hline
 & &  \\
$t\ t_1 \cdots t_n$ &
{\small\verb+(+}$\cdots${\small\verb+(+}$t\ t_1${\small\verb+)+}$\cdots t_n${\small\verb+)+} &
{\small\verb+list_mk_comb(+}$t${\small\verb+,[+}$t_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$t_n${\small\verb+])+} \\ \hline
{\small\verb+\+}$x_1\cdots x_n${\small\verb+.+}$t$ &
{\small\verb+\+}$x_1${\small\verb+. +}$\cdots${\small\verb+ \+}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_abs([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+}
\\ \hline
{\small\verb+!+}$x_1\cdots x_n${\small\verb+.+}$t$ &
{\small\verb+!+}$x_1${\small\verb+. +}$\cdots${\small\verb+ !+}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_forall([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+}
\\ \hline
{\small\verb+?+}$x_1\cdots x_n${\small\verb+.+}$t$ &
{\small\verb+?+}$x_1${\small\verb+. +}$\cdots${\small\verb+ ?+}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_exists([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+} \\
\hline
\end{tabular}
\end{center}

\noindent There are also constructors
\ml{list\_mk\_conj}\index{list_mk_conj@\ml{list\_mk\_conj}},
\ml{list\_mk\_disj}\index{list_mk_disj@\ml{list\_mk\_disj}},
\ml{list\_mk\_imp}\index{list_mk_imp@\ml{list\_mk\_imp}} and
for conjunctions, disjunctions, and implications respectively.
The corresponding destructor functions are called \ml{strip\_comb}, \etc,
\index{term constructors, in HOL logic@term constructors, in \HOL\ logic|)}
\index{terms, in HOL logic@terms, in \HOL\ logic!constructors for|)}

\subsubsection{Theorems}

A large number of theorems involving the logical constants are
pre-proved in the theory \theoryimp{bool}. The following theorems
illustrate how higher order logic allows concise expression of
theorems supporting quantifier movement.

\begin{boxed}
\begin{verbatim}
 LEFT_AND_FORALL_THM  |- !P Q. (!x. P x) /\ Q = !x. P x /\ Q
 RIGHT_AND_FORALL_THM |- !P Q. P /\ (!x. Q x) = !x. P /\ Q x

 LEFT_EXISTS_AND_THM  |- !P Q. (?x. P x /\ Q) = (?x. P x) /\ Q
 RIGHT_EXISTS_AND_THM |- !P Q. (?x. P /\ Q x) = P /\ ?x. Q x

 LEFT_FORALL_IMP_THM  |- !P Q. (!x. P x ==> Q) = (?x. P x) ==> Q
 RIGHT_FORALL_IMP_THM |- !P Q. (!x. P ==> Q x) = P ==> !x. Q x

 LEFT_EXISTS_IMP_THM  |- !P Q. (?x. P x ==> Q) = (!x. P x) ==> Q
 RIGHT_EXISTS_IMP_THM |- !P Q. (?x. P ==> Q x) = P ==> ?x. Q x

 LEFT_FORALL_OR_THM   |- !Q P. (!x. P x \/ Q) = (!x. P x) \/ Q
 RIGHT_FORALL_OR_THM  |- !P Q. (!x. P \/ Q x) = P \/ !x. Q x

 LEFT_OR_EXISTS_THM   |- !P Q. (?x. P x) \/ Q = ?x. P x \/ Q
 RIGHT_OR_EXISTS_THM  |- !P Q. P \/ (?x. Q x) = ?x. P \/ Q x

 EXISTS_OR_THM        |- !P Q. (?x. P x \/ Q x) = (?x. P x) \/ ?x. Q x
 FORALL_AND_THM       |- !P Q. (!x. P x /\ Q x) = (!x. P x) /\ !x. Q x

 NOT_EXISTS_THM       |- !P. ~(?x. P x) = !x. ~P x
 NOT_FORALL_THM       |- !P. ~(!x. P x) = ?x. ~P x

 SKOLEM_THM           |- !P. (!x. ?y. P x y) = ?f. !x. P x (f x)
\end{verbatim}
\end{boxed}

Also, a theorem justifying Skolemization ({\small\verb+SKOLEM_THM+}) is 
proved. Many other theorems may be found in \theoryimp{bool} theory.

\subsection{Combinators}

\index{function composition, in HOL logic@function composition, in \HOL\
logic|(}

The theory \theoryimp{combin}
\index{combin@\theoryimp{combin}}
\index{combinators, in HOL logic@combinators, in \HOL{} logic}
contains the definitions of function composition (infixed \ml{o})
\index{function composition operator, in HOL logic@\ml{o} (function composition operator), in \HOL{} logic|(}
and the combinators
\ml{S},
\index{S, constant in HOL logic@\ml{S}, constant in \HOL{} logic}
\ml{K},
\index{K, constant in HOL logic@\ml{K}, constant in \HOL{} logic}
\ml{I},
\index{I, constant in HOL logic@\ml{I}, constant in \HOL{} logic}
\ml{W},
\index{W, constant in HOL logic@\ml{W}, constant in \HOL{} logic}
and \ml{C},
\index{C, constant in HOL logic@\ml{C}, constant in \HOL{} logic}

\begin{hol}
\index{K_DEF@\ml{K\_DEF}}
\index{S_DEF@\ml{S\_DEF}}
\index{I_DEF@\ml{I\_DEF}}
\index{W_DEF@\ml{W\_DEF}}
\index{C_DEF@\ml{C\_DEF}}
{\small
\begin{verbatim}
   o_DEF |- f o g = (\x. f(g x))

   K_DEF |- K = (\x y. x)

   S_DEF |- S = (\f g x. f x(g x))

   I_DEF |- I = S K K

   W_DEF |- W = (\f x. f x x)

   C_DEF |- C = (\f x y. f y x)
\end{verbatim}}
\end{hol}

\noindent The following elementary properties are proved in the theory
\ml{combin}:

\begin{hol}
\index{K_THM@\ml{K\_THM}}
\index{S_THM@\ml{S\_THM}}
\index{I_THM@\ml{I\_THM}}
\index{I_o_ID@\ml{I\_o\_ID}} %
\begin{verbatim}
  o_THM   |- !f g x. (f o g) x = f(g x)
  o_ASSOC |- !f g h. f o (g o h) = (f o g) o h

  K_THM   |- !x y. K x y = x
  S_THM   |- !f g x. S f g x = f x (g x)
  I_THM   |- !x. I x = x
  W_THM   |- !f x. W f x = f x x
  C_THM   |- !f x y. C f x y = f y x

  I_o_ID  |- !f. (I o f = f) /\ (f o I = f)

  K_o_THM |- (!f v. K v o f = K v) /\ (!f v. f o K v = K (f v))
\end{verbatim}
\end{hol}

Having the symbols \ml{o}, \ml{S}, \ml{K}, \ml{I}, \ml{W}, and \ml{C}
as built-in constants
\index{variables, in HOL logic@variables, in \HOL{} logic!with constant names}
is sometimes inconvenient because they are often wanted
as mnemonic names for variables (\eg\ \ml{S} to range over sets and
\ml{o} to range over outputs).  Variables (though not constants) with
these names can be used in the current system if \ml{o}, \ml{S}, \ml{K},
\ml{I}, \ml{W}, and \ml{C} are first hidden (see Section~\ref{hidden}).
\index{function composition operator, in HOL logic@\ml{o} (function composition operator), in \HOL{} logic|)}
\index{function composition, in HOL logic@function composition, in \HOL{} logic|)}


\subsection{Pairs}\label{prod}

\index{representing types, in HOL logic@representing types, in \HOL{} logic!pair example of|(}
\index{pairs, in HOL logic@pairs, in \HOL{} logic|(}
\index{product types!in HOL logic@in \HOL{} logic|(}
The Cartesian  product  type  operator
\index{type operators, in HOL logic@type operators, in \HOL{} logic!for pairs}
\ml{prod}
\index{prod@\ml{prod}}
is  defined  in  the  theory \ml{pair}. Values of type
{\small\verb%(%}$\sigma_1${\small\verb%,%}$\sigma_2${\small\verb%)prod%} are
ordered pairs  whose  first  component  has  type  $\sigma_1$  and whose second
component has type $\sigma_2$.  The \HOL{} parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of pairs}
converts type expressions of the
form \ml{`:}$\sigma_1${\small\verb%#%}$\sigma_2$\ml{`}
\index{ product type operator, in HOL logic@{\small\verb+#+} (product type operator, in \HOL{} logic)}
 into\ml{(}$\sigma_1$\ml{,}$\sigma_2$\ml{)prod}
\index{ pair constructor, in HOL logic@\ml{,} (pair constructor, in \HOL{} logic)},
and the printer inverts this transformation. Pairs
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL{} logic}
are constructed with an infixed comma symbol

\begin{hol}
\begin{verbatim}
   $, : 'a -> 'b -> 'a # 'b
\end{verbatim}
\end{hol}

\noindent so, for example, if $t_1$ and $t_2$ have types $\sigma_1$ and
$\sigma_2$
respectively, then $t_1$\ml{,}$t_2$ is a term with type
$\sigma_1${\small\verb%#%}$\sigma_2$. Usually, pairs are written
within brackets:
\ml{(}$t_1$\ml{,}$t_2$\ml{)}. The comma symbol associates
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL\ logic!associativity of}
 to the right, so  that
\ml{(}$t_1$\ml{,}$t_2$\ml{,}$\ldots$\ml{,}$t_n$\ml{)}
means
\ml{(}$t_1$\ml{,(}$t_2$\ml{,}$\ldots$\ml{,}$t_n$\ml{))}.

\paragraph {Defining the product type}

The type of Cartesian products is defined by representing a pair
{\small\verb%(%}$t_1${\small\verb%,%}$t_2${\small\verb%)%}
by the function
%
\begin{hol}
\begin{alltt}
   \bs{}a b. (a=\m{t\sb{1}}) /\bs (b=\m{t\sb{2}})
\end{alltt}
\end{hol}
%
\noindent The representing type of
$\sigma_1${\small\verb%#%}$\sigma_2$ is thus
$\sigma_1${\small\verb%->%}$\sigma_2${\small\verb%->bool%}.
It is easy to prove the following theorem.\footnote{This theorem has
an un-reduced $\beta$-redex in order to meet the interface
required by the type definition principle.}
%
\begin{hol}
{\small
\begin{verbatim}
  |- ?p:'a->'b->bool. (\p. ?x y. p = \a b. (a = x) /\ (b = y)) p
\end{verbatim}}
\end{hol}
%
The type operator {\small\verb%prod%} is defined
by invoking \verb+new_type_definition+ with this theorem
 which results in the definitional axiom
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL\ logic}
\index{axioms!in bool theory@in \ml{bool} theory}
\ml{prod\_TY\_DEF} shown below being asserted in the theory \ml{pair}.
%
\begin{hol}
{\small
\begin{verbatim}
  prod_TY_DEF
    |- ?rep. TYPE_DEFINITION (\p. ?x y. p = (\a b. (a = x) /\ (b = y))) rep
\end{verbatim}}
\end{hol}
%
Next, the representation and abstraction functions {\small\verb%REP_prod%} and
{\small\verb%ABS_prod%} for the new type are introduced, along with
the following characterizing theorem, by use of the function
\verb+define_new_type_bijections+.
%
\begin{hol}
\index{REP_prod@\ml{REP\_prod}}
\index{ABS_prod@\ml{ABS\_prod}}
{\small
\begin{verbatim}
  |- (!a. ABS_prod (REP_prod a) = a) /\
     (!r. (\p. ?x y. p = (\a b. (a=x) /\ (b=y)) r = (REP_prod(ABS_prod r) = r)
\end{verbatim}}
\end{hol}

\paragraph {Pairs and projections}

The infix constructor `{\small\verb%,%}' is then defined
to be an application of the abstraction function. Subsequently, two
crucial theorems are proved: {\small\verb+PAIR_EQ+} asserts that equal
pairs have equal components and {\small\verb+ABS_PAIR_THM+} shows that
every term having a product type can be decomposed into a pair of terms.
\begin{hol}\index{COMMA_DEF@\ml{COMMA\_DEF}}
\index{COMMA_DEF@\ml{COMMA\_DEF}}
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL{} logic!definition of}
\index{PAIR_EQ@\ml{PAIR\_EQ}}
\index{ABS_PAIR_THM@\ml{ABS\_PAIR\_THM}}
{\small
\begin{verbatim}
  COMMA_DEF    |- !x y. $, x y = ABS_prod (\a b. (a = x) /\(b = y))

  PAIR_EQ      |- ((x,y) = (a,b)) = (x=a) /\ (y=b)

  ABS_PAIR_THM |- !x. ?q r. x = (q,r)
\end{verbatim}}
\end{hol}
%
By Skolemizing {\small\verb+ABS_PAIR_THM+} and making constant specifications
for {\small\verb+FST+} and {\small\verb+SND+}, the following theorems
are proved.
%
\begin{hol}
\index{PAIR@\ml{PAIR}}
\index{FST_DEF@\ml{FST\_DEF}}
\index{SND_DEF@\ml{SND\_DEF}}
\index{FST, the constant in HOL logic@\ml{FST}, the constant in \HOL{} logic!definition of}
\index{SND, the constant in HOL logic@\ml{SND}, the constant in \HOL{} logic!definition of}
\index{selectors, in HOL logic@selectors, in \HOL{} logic}
\begin{verbatim}
   PAIR     |- !x. (FST x,SND x) = x
   FST      |- !x y. FST(x,y) = x
   SND      |- !x y. SND(x,y) = y
\end{verbatim}
\end{hol}
\index{pairs, in HOL logic@pairs, in \HOL{} logic|)}
\index{product types!in HOL logic@in \HOL{} logic|)}
\index{representing types, in HOL logic@representing types, in \HOL{} logic!pair example of|)}

\paragraph{Pairs and functions}

In \HOL{}, a function of type $\alpha \# \beta\to\gamma$ always has a
counterpart of type $\alpha\to\beta\to\gamma$, and \emph{vice versa}.
This conversion is accomplished by the functions {\small\verb+CURRY+}
and {\small\verb+UNCURRY+}. These functions are inverses.
%
\begin{hol}
\index{CURRY@\ml{CURRY}}
\index{CURRY_DEF@\ml{CURRY\_DEF}}
\index{UNCURRY_DEF@\ml{UNCURRY\_DEF}}
{\small
\begin{verbatim}
  CURRY_DEF    |- !f x y. CURRY f x y = f (x,y)
  UNCURRY_DEF  |- !f x y. UNCURRY f (x,y) = f x y

  CURRY_UNCURRY_THM |- !f. CURRY (UNCURRY f) = f
  UNCURRY_CURRY_THM |- !f. UNCURRY (CURRY f) = f
\end{verbatim}}
\end{hol}


\paragraph {Mapping functions over a pair}

Functions $f : \alpha \to \gamma_1$ and $g : \beta\to\gamma_2$ can be
applied component-wise ({\small\verb+##+}, infix) over a pair of type
$\alpha \# \beta$ to obtain a pair of type $\gamma_1 \# \gamma_2$.
%
\begin{hol}
\index{PAIR_MAP_THM@\ml{PAIR\_MAP\_THM}}
{\small
\begin{verbatim}
  PAIR_MAP_THM  |- !f g x y. (f ## g) (x,y) = (f x,g y)
\end{verbatim}}
\end{hol}

\paragraph {Binders and pairs}

When doing proofs, statements involving tuples may take the form of a
binding (quantification or $\lambda$-abstraction) of a variable with a
product type. It may be convenient in subsequent reasoning steps to
replace the variables with tuples of variables. The following theorems
support this.
%
 \begin{hol}
{\small
\begin{verbatim}
  FORALL_PROD  |- (!p. P p) = !p_1 p_2. P (p_1,p_2)
  EXISTS_PROD  |- (?p. P p) = ?p_1 p_2. P (p_1,p_2)
  LAMBDA_PROD  |- !P. (\p. P p) = \(p1,p2). P (p1,p2)
\end{verbatim}}
\end{hol}
%
The theorem {\small\verb+LAMBDA_PROD+} involves a \emph{paired
 abstraction}, discussed in Section \ref{HOL-varstruct}.


\paragraph {Wellfounded relations on pairs}

Wellfoundedness, defined in Section \ref{prim-rec-conseq},
is a useful notion, especially for proving termination of
recursive functions. For pairs, the lexicographic combination
of relations ({\small\verb+LEX+}, infix) may be defined by using
paired abstractions. Then the theorem that lexicographic combination
of wellfounded relations delivers a wellfounded relation is easy to
prove.
%
\begin{hol}
{\small
\begin{verbatim}
 LEX_DEF =
    |- !R1 R2. R1 LEX R2 = (\(s,t) (u,v). R1 s u \/ (s = u) /\ R2 t v)
 WF_LEX
    |- !R Q. WF R /\ WF Q ==> WF (R LEX Q)
\end{verbatim}}
\end{hol}

\subsubsection{Paired abstractions}
\label{HOL-varstruct}
\index{pairs, in HOL logic@pairs, in \HOL{} logic!in abstractions|(}
\index{terms, in HOL logic@terms, in \HOL{} logic!pair|(}
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of quotation syntax|(}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!paired|(}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!uncurrying, in paired|(}

It is notationally convenient to include pairing in the lambda
notation, as a simple pattern-matching mechanism. The quotation parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of function abstractions}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!abbreviation for multiple}
\index{terms, in HOL logic@terms, in \HOL{} logic!function abstraction}
will convert the term
{\small\bs\texttt{(}}$x_1${\small\verb%,%}$x_2${\small\verb%).%}$t$
to {\small\verb%UNCURRY(%\bs}$x_1\ x_2${\small\verb%.%}$t${\small\verb%)%}.
The transformation is done recursively so that, for example,
%
\begin{hol}
\begin{alltt}
   \bs(\m{x\sb{1}},\m{x\sb{2}},\m{x\sb{3}}).\m{t}
\end{alltt}
\end{hol}
%
\noindent is converted to
%
\begin{hol}
{\small
\begin{alltt}
  UNCURRY \bs\m{x\sb{1}}. UNCURRY(\bs\m{x\sb{2}} \m{x\sb{3}}.\m{t}))
\end{alltt}}
\end{hol}
%
\noindent More generally, the quotation parser repeatedly applies the
transformation:
%
\begin{hol}
{\small
\begin{alltt}
   \bs(\m{v\sb{1}},\m{v\sb{2}}).\m{t}\m{\quad \leadsto\quad}UNCURRY(\bs\m{v\sb{1}}.\bs\m{v\sb{2}}.\m{t})
\end{alltt}}
\end{hol}
%
\noindent until no more variable structures remain. For example:

\vspace{1ex}
\begin{tabular}{ll}
\texttt{\bs($x$,$y$).$t$} &
  $\leadsto$ \texttt{UNCURRY(\bs$x\,y$.$t$)}\\
%
\texttt{\bs($x_1$,$x_2$,$\ldots$,$x_n$).$t$} &
  $\leadsto$ \texttt{UNCURRY(\bs$x_1$.\bs($x_2$,$\ldots$,$x_n$).$t$)}\\
%
\texttt{\bs(($x_1$,$\ldots$,$x_n$),$y_1$,$\ldots$,$y_m$).$t$} &
  $\leadsto$
  \texttt{UNCURRY(\bs($x_1$,$\ldots$,$x_n$).\bs($y_1$,$\ldots$,$y_m$).$t$)}\\
\end{tabular}

\vspace{1ex}

As a result of this parser translation, a variable structure, such as \ml{(x,y)} in
\ml{\bs(x,y).x+y}, is not a subterm of the abstraction
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!subterms of}
in which it occurs; it disappears on parsing.
\index{binders, in HOL logic@binders, in \HOL{} logic!parsing of}
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of binders}
This can lead to unexpected errors (accompanied by obscure error
messages).  For example, antiquoting a pair into the bound variable
position of a lambda abstraction fails:

\begin{session}
\begin{verbatim}
  - ``\(x,y).x+y``;
  > val it = `\(x,y). x + y` : term

  - val p = Term `(x:num,y:num)`;
  > val p = `(x,y)` : term

  - Lib.try Term `\^p.x+y`;

  Exception raised at Term.dest_var:
  not a var
  ! Uncaught exception:
\end{verbatim}
\end{session}

If $b$ is a binder, then \ml{$b$($x_1$,$x_2$).$t$} is parsed as
\ml{$b$(\bs($x_1$,$x_2$).$t$)}, and hence transformed as above.  For
example,
\ml{!(x,y). x > y}
parses to
\ml{ \$!(UNCURRY(\bs{}x.\bs{}y.\ x > y))}.
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!paired|)}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!uncurrying, in paired|)}
\index{pairs, in HOL logic@pairs, in \HOL{} logic!in abstractions|)}
\index{terms, in HOL logic@terms, in \HOL{} logic!pair|)}\index{UNCURRY@\ml{UNCURRY}|)}


\subsubsection{{\tt let}-terms}
\label{let-exp}

The quotation parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of let-terms@of \ml{let}-terms}
 accepts \ml{let}-terms
\index{terms, in HOL logic@terms, in \HOL{}
  logic!let-@\ml{let}-}
\index{let-terms, in HOL logic@\ml{let}-terms,
  in \HOL{} logic!as abbreviations}
similar to those in \ML. For example, the following terms are allowed:

\begin{hol}
\begin{verbatim}
   let x = 1 and y = 2 in x+y

   let f(x,y) = (x*x)+(y*y) and a = 20*20 and b = 50*49 in f(a,b)
\end{verbatim}
\end{hol}

\ml{let}-terms are actually abbreviations for ordinary terms which are
specially supported by the parser and pretty printer.
The constant \ml{LET}
\index{LET@\ml{LET}} is defined (in the theory \ml{bool}) by:

\begin{hol}\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!relation to let-terms@relation to \ml{let}-terms}
{\small
\begin{verbatim}
   LET = (\f x. f x)
\end{verbatim}}
\end{hol}

\noindent and is used to encode \ml{let}-terms in the logic. The parser
repeatedly applies the transformations:

\bigskip

{\small\begin{tabular}{ll}
\texttt{let~$f\,v_1\,\ldots\,v_n$~=~$t_1$~in~$t_2$} &
$\leadsto$~~\texttt{LET(\bs$f$.$t_2$)(\bs$v_1\,\ldots\,v_n$.$t_1$)}\\
%
\texttt{let~($v_1$,$\ldots$,$v_n$)~=~$t_1$~in~$t_2$} &
$\leadsto$~~\texttt{LET(\bs($v_1$,$\ldots$,$v_n$).$t_2$)$t_1$}\\
%
\texttt{let~$v_1$=$t_1$~and~$\ldots$~and~$v_n$=$t_n$~in~$t$} &
$\leadsto$~~\texttt{LET($\ldots$(LET(LET(\bs$v_1\ldots v_n$.$t$)$t_1$)$t_2$)$\ldots$)$t_n$}\\
\end{tabular}}

\bigskip


\noindent The underlying structure of the term can be seen by applying
destructor operations.  For example:

\setcounter{sessioncount}{1}
\begin{session}
\begin{verbatim}
- Term `let x = 1 and y = 2 in x+y`;
> val it = `let x = 1 and y = 2 in x + y` : term

- dest_comb it;
> val it = (`LET (LET (\x y. x + y) 1)`, `2`) : term * term

- Term `let (x,y) = (1,2) in x+y`;
> val it = `let (x,y) = (1,2) in x + y` : Term.term

- dest_comb it;
> val it = (`LET (\(x,y). x + y)`, `(1,2)`) : Term.term * Term.term
\end{verbatim}
\end{session}

The reader is recommended to convince himself or herself that the
translations of \ml{let}-terms represent the intuitive meaning suggested by
the surface syntax.
\index{quotation, in HOL logic@quotation, in \HOL{} logic|)}
\index{quotation, in HOL logic@quotation, in \HOL{} logic!of non-primitive terms|)}
\index{terms, in HOL logic@terms, in \HOL{} logic!syntax of|)}
\index{type checking, in HOL logic@type checking, in \HOL{} logic!special forms in|)}

\subsection{Disjoint sums}\label{sum}

The theory \ml{sum}\index{sum@\ml{sum}} defines the binary  disjoint
union\index{disjoint union theory, in HOL
logic@disjoint union theory, in \HOL{} logic|(}  type operator \ml{sum}.
A type  {\small\verb%(%}$\sigma_1${\small\verb%,%}$\sigma_2${\small\verb%)sum%}
denotes the  disjoint  union  of  types  $\sigma_1$  and $\sigma_2$.   The type
operator {\small\verb%sum%} can be defined, just as {\small\verb%prod%} was, but
the details are omitted here.\footnote{The definition of disjoint  unions in
the HOL system is due to Tom Melham. The technical details of this definition can
be found in~\cite{Melham-banff}.}  The \HOL{} parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of sum types}
converts
\ml{":}$\sigma_1${\small\verb%+%}$\sigma_2$\ml{"}\index{ disjoint union
type operator, in HOL logic@\ml{+} (disjoint union
type operator, in HOL logic)} into
\ml{(}$\sigma_1$\ml{,}$\sigma_2$\ml{)sum}, and the printer inverts this.

The standard operations on sums are:

\begin{hol}
\index{disjoint union theory, in HOL logic@disjoint union theory, in \HOL{} logic|)}
\index{INL, the constant in HOL logic@\ml{INL}, the constant in \HOL{} logic}
\index{INR, the constant in HOL logic@\ml{INR}, the constant in \HOL{} logic}
\index{ISL, the constant in HOL logic@\ml{ISL}, the constant in \HOL{} logic}
\index{ISR, the constant in HOL logic@\ml{ISR}, the constant in \HOL{} logic}
\index{OUTL, the constant in HOL logic@\ml{OUTL}, the constant in \HOL{} logic}
\index{OUTR, the constant in HOL logic@\ml{OUTR}, the constant in \HOL{} logic}
{\small
\begin{verbatim}
   INL  : 'a -> 'a + 'b
   INR  : 'b -> 'a + 'b
   ISL  : 'a + 'b -> bool
   ISR  : 'a + 'b -> bool
   OUTL : 'a + 'b -> 'a
   OUTR : 'a + 'b -> 'b
\end{verbatim}}
\end{hol}

\noindent These are all defined as constants in the theory \ml{sum}.  The
constants \ml{INL} and \ml{INR} inject into the left and right summands,
respectively. The constants \ml{ISL} and \ml{ISR} test for membership of the
left and right summands, respectively. The constants \ml{OUTL} and \ml{OUTR}
project from a sum to the left and right summands, respectively.

The following theorem is proved in the theory \ml{sum}. It provides a
complete and abstract characterization of the disjoint sum type.

\begin{hol}
\index{sum_Axiom@\ml{sum\_Axiom}}
\index{sum_axiom@\ml{sum\_axiom}}
\begin{verbatim}
  sum_Axiom  |- !f g. ?! h. (!x. h(INL x) = f x) /\ (!x. h(INR x) = g x)
\end{verbatim}
\end{hol}

\noindent Also provided are the following theorems having to
do with the discriminator functions \ml{ISL} and \ml{ISR}:

\begin{hol}
\index{ISL, the theorem in HOL logic@\ml{ISL}, the theorem in \HOL{} logic}
\index{ISR, the theorem in HOL logic@\ml{ISR}, the theorem in \HOL{} logic}
\index{ISL_OR_ISR@\ml{ISL\_OR\_ISR}}
\begin{verbatim}
   ISL         |- (!x. ISL(INL x)) /\ (!y. ~ISL(INR y))
   ISR         |- (!x. ISR(INR x)) /\ (!y. ~ISR(INL y))

   ISL_OR_ISR  |- !x. ISL x \/ ISR x
\end{verbatim}
\end{hol}

\noindent The \ml{sum} theory also provides the following theorems
relating the projection functions and the discriminators.

\begin{hol}
\index{OUTL, the theorem in HOL logic@\ml{OUTL}, the theorem in \HOL{} logic}
\index{OUTR, the theorem in HOL logic@\ml{OUTR}, the theorem in \HOL{} logic}
\index{INL, the theorem in HOL logic@\ml{INL}, the theorem in \HOL{} logic}
\index{INR, the theorem in HOL logic@\ml{INR}, the theorem in \HOL{} logic}
{\small
\begin{verbatim}
   OUTL        |- !x. OUTL(INL x) = x
   OUTR        |- !x. OUTR(INR x) = x

   INL         |- !x. ISL x ==> (INL(OUTL x) = x)
   INR         |- !x. ISR x ==> (INR(OUTR x) = x)
\end{verbatim}}
\end{hol}

\subsection{The one-element type}%
\index{one, the HOL theory@\ml{one}, the \HOL{} theory}%
\index{one, the HOL type@\ml{one}, the \HOL{} type}%

The theory \ml{one} defines  the type  \ml{one} which  contains one element.
The constant  \ml{one}  is specified  to denote  this element.   The pre-proved
theorems in the theory \ml{one} are:

\begin{hol}
\index{one_axiom@\ml{one\_axiom}}
\index{one, the HOL theorem@\ml{one}, the \HOL{} theorem}
\index{one_Axiom@\ml{one\_Axiom}}
\begin{verbatim}
   one_axiom   |- !(f:'a->one) (g:'a -> one). f = g
   one         |- !(v:one). v = one
   one_Axiom   |- !(e:'a). ?!(fn:one->'a). fn one = e
\end{verbatim}
\end{hol}

\noindent These three theorems are equivalent characterizations of the type
with only one value. The theory \ml{one} is typically used in
constructing more elaborate types.  The one value of the type
\ml{one}, can also be written as \ml{()} by analogy with the unit
value in \ML.  This is also the default way in which this value is
printed by the system pretty-printer.

\subsection{The option type}
\index{option, the HOL theory@\ml{option}, the \HOL{} theory}

The theory \theoryimp{option} defines a type operator \verb+option+
that `lifts' its argument type, creating a type with all of the
values of the argument and one other, specially distinguished value.
The constructors of this type are
\begin{verbatim}
   NONE : 'a option
   SOME : 'a -> 'a option
\end{verbatim}
Options can be used to model partial functions.  If a function of type
$\alpha\rightarrow\beta$ does not have useful $\beta$ values for all
$\alpha$ inputs, then this distinction can be marked by making the
range of the function $\beta\konst{option}$, and mapping the
undefined $\alpha$ values to {\small\verb+NONE+}.

An inductive type, options have a recursion theorem supporting the
definition of primitive recursive functions over option values.
%
{\small
\begin{verbatim}
  option_Axiom
    |- !e f.
        ?h:'a option -> 'b.
          (!x. h (SOME x) = f x) /\
          (h NONE = e)
\end{verbatim}
}
The \theoryimp{option} theory also defines a case constant that allows
one to inspect option values in a ``pattern-matching'' style.
{\small
\begin{verbatim}
       case e of
          NONE -> u
       || SOME x -> f x
\end{verbatim}
}
The constant underlying this syntactic sugar is \verb+option_case+
with definition
{\small
\begin{verbatim}
   option_case_def |- (option_case u f NONE = u) /\
                      (option_case u f (SOME x) = f x)
\end{verbatim}}

Another useful function maps a function over an option:
{\small
\begin{verbatim}
  OPTION_MAP_DEF  |- (OPTION_MAP f NONE = NONE) /\
                     (OPTION_MAP f (SOME x) = SOME (f x))
\end{verbatim}
}
Finally, the {\small\verb+THE+} function takes a {\small\verb+SOME+}
value to that constructor's argument, and is unspecified on
{\small\verb+NONE+}:
{\small
\begin{verbatim}
   THE_DEF   |- THE (SOME x) = x
\end{verbatim}
}

\section{Numbers}

The natural numbers, integers, and real numbers are provided in a
series of theories. Also available are theories of floating point and
fixed point numbers.

\subsection{Natural numbers}

The natural numbers are developed in a series of theories:
\theoryimp{num},\theoryimp{prim\_rec},\theoryimp{arithmetic}, and
\theoryimp{numeral}. In \theoryimp{num}, the type of numbers is
defined from the Axiom of Infinity, and Peano's axioms are derived. In
\theoryimp{prim\_rec} the Primitive Recursion theorem is proved. Based
on that, a large theory treating the standard arithmetic operations is
developed in \theoryimp{arithmetic}. Lastly, a theory of numerals is developed.

\subsubsection{The theory \theoryimp{num}}

The theory \theoryimp{num}
\index{num, the theory in HOL logic@\ml{num}, the theory in \HOL{} logic}
defines the type \ml{num} of natural numbers to be
isomorphic to a countable subset of the primitive type \ml{ind}.  In this
theory, the constants \ml{0}
\index{ zero, in HOL logic@\ml{0} (zero, in \HOL{} logic)}
and \ml{SUC} (the successor function) are defined
and Peano's axioms
\index{axioms!in num theory@in \ml{num} theory}
\index{Peano's axioms}
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
pre-proved in the form:

\begin{hol}
\index{NOT_SUC@\ml{NOT\_SUC}}
\index{INV_SUC@\ml{INV\_SUC}}
\index{INDUCTION@\ml{INDUCTION}}
\begin{verbatim}
   NOT_SUC    |- !n. ~(SUC n = 0)
   INV_SUC    |- !m n. (SUC m = SUC n) ==> (m = n)
   INDUCTION  |- !P. P 0 /\ (!n. P n ==> P(SUC n)) ==> (!n. P n)
\end{verbatim}
\end{hol}

In higher order logic, Peano's axioms are sufficient for developing number
theory because addition and multiplication can be defined. In first order
logic these must be taken as primitive.  Note also that
{\small\verb%INDUCTION%}
\index{induction rule!for numbers, in HOL logic@for numbers, in \HOL{} logic}
could not be stated as a single axiom in first order logic because
predicates (\eg\ {\small\verb%P%}) cannot be quantified.

\subsubsection{The theory \theoryimp{prim\_rec}}\label{prim_rec}

\index{primitive recursive definitions, in HOL logic@primitive recursive definitions, in \HOL{} logic!automated|(}
\index{primitive recursion theorem!for numbers|(}
\index{prim_rec@\ml{prim\_rec}|(}
In classical logic, unlike domain theory logics such as \PPL\index{PPlambda (same as PPLAMBDA), of LCF system@\ml{PP}$\lambda$ (same as \ml{PPLAMBDA}), of \ml{LCF} system},
arbitrary recursive definitions\index{recursive definitions, in classical logics} are not allowed. For example, there is no
function $f$ (of type \ml{num->num}) such that

\begin{hol}
{\small\verb%   !%}$x${\small\verb%. %}$f$ $x${\small\verb%  =  (%}$f$ $x${\small\verb%) + 1%}
\end{hol}

\noindent Certain restricted forms of recursive\index{primitive recursive
functions} definition do, however, uniquely
define functions. An important example are the {\it primitive recursive\/}
functions.\footnote{In higher order logic, primitive recursion
is much more powerful than in first order logic;
for example, Ackermann's function can be defined
by primitive recursion in higher order logic.} For
any $x$ and $f$ the {\it primitive
recursion theorem\/} tells us that there is a unique function
{\small\verb%fn%} such that:

\begin{hol}
{\small\verb%   (%}\ml{fn}{\small\verb% 0 = %}$x${\small\verb%) /\ (!%}$n${\small\verb%.%}\ml{fn}{\small\verb%(%}\ml{SUC} $n${\small\verb%) = %}$f${\small\verb% (%}\ml{fn} $n${\small\verb%)%} $n${\small\verb%)%}
\end{hol}

The primitive recursion theorem, named  {\small\verb+num_Axiom+} in
\HOL, follows from Peano's
%
\index{Peano's axioms}
%
axioms.

\begin{hol}\index{num_Axiom@\ml{num\_Axiom}}
\index{characterizing theorem!for numbers}
\begin{verbatim}
  num_Axiom  |- !x f. ?fn. (fn 0 = x) /\ (!n. fn(SUC n) = f n (fn n))
\end{verbatim}
\end{hol}

\noindent The theorem states the validity of primitive recursive
definitions on the natural numbers: for any \ml{x} and \ml{f} there exists a
corresponding total function \ml{fn} which satisfies
the primitive recursive definition whose form is determined by \ml{x} and
\ml{f}.

\paragraph{The less-than relation}

The less-than relation `{\small{\tt\verb+<+}}'
\index{less than, in HOL logic@\ml{<} (less than, in \HOL{} logic)}
is most naturally defined by primitive recursion. However, in our
development it is needed for the proof of the
  primitive recursion theorem, so it must be defined before definition
  by primitive recursion is available. The theory \theoryimp{prim\_rec}
  therefore contains the following non-recursive definition\index{less
  than, in HOL logic@less than, in \HOL{} logic} of \ml{<}:

\begin{hol}
\index{LESS@\ml{LESS}}
\begin{verbatim}
   LESS  |- !m n. m < n = ?P. (!n. P(SUC n) ==> P n) /\ P m /\ ~P n
\end{verbatim}
\end{hol}

\noindent
This definition says that {\small\verb%m < n%} if there exists a set (with
characteristic function {\small\verb%P%}) that is downward
closed\footnote{A set of numbers is \textit{downward closed} if whenever it
contains the successor of a number, it also contains the number.} and
contains {\small\verb%m%} but not {\small\verb%n%}.

\subsubsection{Mechanizing primitive recursive definitions}
\label{num-prim-rec}

\index{type definitions, in HOL logic@type definitions, in \HOL{} logic!primitive recursive|(}
\index{recursive definitions, in HOL logic@recursive definitions, in \HOL{} logic!automated, for numbers|(}
\index{primitive recursion theorem!automated use of, in HOL system@automated use of, in \HOL{} system|(}
The primitive
\index{primitive recursive definitions, in HOL logic@primitive recursive definitions, in \HOL{} logic!justification of}
recursion theorem can be used to justify any definition of a function
on the natural numbers by primitive recursion.  For example, a
primitive recursive definition in higher order logic of the form

\begin{hol}
\begin{alltt}
   fun 0       x\(\sb{1}\) \m{\dots} x\(\sb{i}\) = \m{f\sb{1}[}x\(\sb{1}\)\m{,\ldots,\,} x\(\sb{i}]\)
   fun (SUC n) x\(\sb{1}\) \m{\dots} x\(\sb{i}\) = \m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\m{,} x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
\end{alltt}
\end{hol}

\noindent where all the free variables in the  terms $t_1$,
\dots, $t_i$ are contained in $\{$\ml{n}, $\ml{x}_1$, \dots, $\ml{x}_i\}$,
is logically equivalent to:

\begin{hol}
\begin{alltt}
   fun 0       = \bs{}x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
   fun (SUC n) = \bs{}x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\m{,}x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
               = (\bs{}f n x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\m{,} x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)) (fun n) n
\end{alltt}
\end{hol}

The existence  of  a  recursive  function  \ml{fun} which  satisfies these two
equations follows directly from the primitive recursion theorem
\ml{num\_Axiom} shown above.   Specializing the  quantified variables \verb!x!
and \verb!f!  in  a suitably  type-instantiated version  of \ml{num\_Axiom} so
that

\begin{hol}
\begin{alltt}
   x\m{=}\bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)  {\rm and}  f\(=\)\bs{}f n x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\))
\end{alltt}
\end{hol}

\noindent yields the existence theorem shown below:

\begin{hol}
\begin{alltt}
   |- ?fn. fn 0       = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\) /\bs{}
           fn (SUC n) = (\bs{}f n x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)) (fn n) n
\end{alltt}
\end{hol}

\noindent This theorem allows a constant \ml{fun} to be introduced (via the
definitional mechanism of constant specifications---see Section~\ref{conspec})
to denote the recursive function that satisfies the two equations in the body
of the theorem. Introducing a constant \ml{fun} to name the function asserted
to exist by the theorem shown above, and simplifying using $\beta$-reduction,
yields the following theorem:

\begin{hol}
\begin{alltt}
   |- fun 0       = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\) /\bs{}
      fun (SUC n) = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
\end{alltt}
\end{hol}

\noindent It follows immediately from this theorem that the constant \ml{fun}
satisfies the primitive recursive defining equations given by the theorem shown
below:

\begin{hol}
\begin{alltt}
   |- fun 0 x\(\sb{1}\) \(\dots\) x\(\sb{i}\) = \m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
      fun (SUC n) x\(\sb{1}\) \(\dots\) x\(\sb{i}\) = \m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
\end{alltt}
\end{hol}

To automate the use of the primitive recursion theorem in deriving
recursive definitions of this kind, the \HOL{} system provides a function
which automatically proves the existence of primitive recursive
functions and then makes a constant specification to introduce the constant
that denotes such a function:

\begin{boxed}
\index{new_recursive_definition@\ml{new\_recursive\_definition}|pin}
\begin{verbatim}
   new_recursive_definition : thm -> string -> term -> thm
\end{verbatim}
\end{boxed}

\noindent In fact, {\verb+new_recursive_definition+} handles
primitive recursive definitions over a range of types, not just the
natural numbers. For details, see the \REFERENCE\ documentation.

More conveniently still, the \verb+Define+ function (see
Section~\ref{sec:high-level-proof-steps}) supports primitive
recursion, along with other styles of recursion, and does not require the
user to quote the primitive recursion axiom. It does, however, require
termination proofs to be performed; fortunately, these need not be
done for primitive recursions.

\subsubsection{Dependent Choice and wellfoundedness}
\label{prim-rec-conseq}

The primitive recursion theorem is useful beyond its main purpose of
justifying recursive definitions. For example, the theory
\theoryimp{prim\_rec} proves the Axiom of Dependent Choice ({\small\verb+DC+}).

\begin{hol}
\index{Axiom of Dependent Choice@\ml{DC}}
{\small
\begin{verbatim}
   DC  |- !P R a.
            P a /\ (!x. P x ==> ?y. P y /\ R x y)
             ==>
           ?f. (f 0 = a) /\ !n. P (f n) /\ R (f n) (f (SUC n))
\end{verbatim}}
\end{hol}

The proof uses {\small\verb+SELECT_AX+}. The theorem {\small\verb+DC+}
is useful when one wishes to build a function having a certain
property from a relation. For example, one way to define the
wellfoundedness of a relation $R$ is to say that it has no infinite
decreasing $R$ chains.
%
\begin{hol}
\index{wellfounded@\ml{wellfounded}}
\begin{verbatim}
  wellfounded_def
    |- wellfounded (R:'a->'a->bool) = ~?f. !n. R (f (SUC n)) (f n)

  WF_IFF_WELLFOUNDED
    |- !R. WF R = wellfounded R
\end{verbatim}
\end{hol}
By use of {\small\verb+DC+}, this statement can be proved
to be equal to the notion of wellfoundedness {\small\verb+WF+}
(namely, that every set has an $R$-minimal element) defined in the theory
\theoryimp{relation}.

Theorems asserting the wellfoundedness of the predecessor relation and
the less-than relation, as well as the wellfoundedness of measure
functions are also proved in \theoryimp{prim\_rec}.

\begin{hol}
\index{WF_PRED@\ml{WF\_PRED}}
\index{WF_LESS@\ml{WF\_LESS}}
\index{measure_def@\ml{measure\_def}}
\index{WF_measure@\ml{WF\_measure}}
\begin{verbatim}
   WF_PRED     |- WF (\x y. y = SUC x)
   WF_LESS     |- WF $<

   measure_def |- measure = inv_image $<
   measure_thm |- !f x y. measure f x y = f x < f y
   WF_measure  |- !m. WF (measure m)
\end{verbatim}
\end{hol}


\subsection{Arithmetic}

The built-in theory {\small\verb%arithmetic%}
\index{number theory, in HOL logic@number theory, in \HOL{} logic}
\index{arithmetic@\ml{arithmetic}}
contains primitive recursive definitions of the following standard
arithmetic operators.

\begin{hol}
\index{ADD@\ml{ADD}}
\index{SUB@\ml{SUB}}
\index{MULT@\ml{MULT}}
\index{EXP@\ml{EXP}}
\index{ subtraction, in HOL logic@\ml{-} (subtraction, in \HOL{} logic)}
\index{ multiplication, in HOL logic@\ml{*} (multiplication, in \HOL{} logic)}
{\small
\begin{verbatim}
   ADD    |- (!n. 0 + n = n) /\
             (!m n. (SUC m) + n = SUC(m + n))

   SUB    |- (!m. 0 - m = 0) /\
             (!m n. (SUC m) - n = if m < n then 0 else SUC(m - n))

   MULT   |- (!n. 0 * n = 0) /\
             (!m n. (SUC m) * n = (m * n) + n)

   EXP    |- (!m. m EXP 0 = 1) /\
             (!m n. m EXP (SUC n) = m * (m EXP n))
\end{verbatim}}
\end{hol}
%
Note that {\small\verb+EXP+} is an infix. The infix notation
{\verb+**+} may be used in place of {\small\verb+EXP+}. Thus 
({\small\verb+x EXP y+}) means $x^y$, and so does ({\verb+x ** y+}).

\paragraph{Comparison operators}

A full set of comparison operators is defined in terms of \verb+<+.

\begin{hol}
\index{arithmetic, in HOL logic@arithmetic, in \HOL{} logic}
\index{ greater than, in HOL logic@\ml{>} (greater than, in \HOL{} logic)}
\index{ less or equal, in HOL logic@\ml{<=} (less or equal, in \HOL{} logic)}
\index{ greater or equal, in HOL logic@\ml{>=} (greater or equal, in \HOL{} logic)}
{\small
\begin{verbatim}
   GREATER        |- !m n. m > n = (n < m)
   LESS_OR_EQ     |- !m n. m <= n = (m < n \/ (m = n))
   GREATER_OR_EQ  |- !m n. m >= n = (m > n \/ (m = n))
\end{verbatim}}
\end{hol}

\paragraph{Division and modulus}

A constant specification is used to introduce division ({\small\verb+DIV+}, infix) and
modulus ({\small\verb+MOD+}, infix) operators, together with their
characterizing property.  
\begin{hol}
\index{MOD@\ml{MOD}}
\index{DIV@\ml{DIV}}
{\small
\begin{verbatim}
   DIVISION
     |- !n. 0 < n ==> !k. (k = ((k DIV n) * n) + (k MOD n)) /\ (k MOD n) < n
\end{verbatim}}
\end{hol}

\paragraph{Even and odd}

The properties of a number being even or odd are defined recursively.
%
\begin{hol}
\index{EVEN@\ml{EVEN}}
\index{ODD@\ml{ODD}}
{\small
\begin{verbatim}
   EVEN |- (EVEN 0 = T) /\ !n. EVEN (SUC n) = ~EVEN n

   ODD  |- (ODD 0 = F) /\ !n. ODD (SUC n) = ~ODD n
\end{verbatim}}
\end{hol}

\paragraph{Maximum and minimum}

The minumum and maximum of two numbers are defined in the usual way.
%
\begin{hol}
\index{MIN@\ml{MIN}}
\index{MAX@\ml{MAX}}
{\small
\begin{verbatim}
   MAX_DEF |- !m n. MAX m n = (if m < n then n else m)
   MIN_DEF |- !m n. MIN m n = (if m < n then m else n)
\end{verbatim}}
\end{hol}

\paragraph{Factorial}
\index{FACT@\ml{FACT}}

The factorial of a number is a primitive recursive definition.
%
\begin{hol}
\index{FACT@\ml{FACT}}
{\small
\begin{verbatim}
   FACT |- (FACT 0 = 1) /\ !n. FACT (SUC n) = SUC n * FACT n
\end{verbatim}}
\end{hol}

\paragraph{Function iteration}
\index{FUNPOW@\ml{FUNPOW}}

The iterated application $f^n x$ of a function $f : \konst{num} \to
\konst{num}$ is defined by primitive recursion. The definition
({\small\verb+FUNPOW+}) is tail-recursive. An alternative presentation
of the recursion ({\small\verb+FUNPOW_SUC+}) may be simpler to reason
about in some cases.
%
\begin{hol}
{\small
\begin{verbatim}
   FUNPOW
     |- (!f x. FUNPOW f 0 x = x) /\
        (!f n x. FUNPOW f (SUC n) x = FUNPOW f n (f x))
   FUNPOW_SUC
     |- !f n x. FUNPOW f (SUC n) x = f (FUNPOW f n x)
\end{verbatim}}
\end{hol}

\medskip

On this basis, an \adhoc\ but useful collection of over two hundred
and fifty elementary theorems of arithmetic are proved when \HOL{} is
built and stored in the theory {\small\verb%arithmetic%}.  For a
complete list of the available theorems, see \REFERENCE.

\subsubsection{Grammar information}

The following table gives the parsing status of the arithmetic
constants.

\begin{center}
{\small
\begin{tabular}{@{}ccc}
Operator & Strength & Associativity \\ \hline
{\small\verb+>=+} & 450 & right \\
{\small\verb+<=+} & 450 & right \\
{\small\verb+>+} & 450 & right \\
{\small\verb+<+} & 450 & right \\
{\small\verb%+%} & 500 & left \\
{\small\verb%-%} & 500 & left \\
{\small\verb%*%} & 600& left \\
{\small\verb%DIV%} & 600 & left \\
{\small\verb%MOD%} & 650 & left \\
{\small\verb%EXP%} & 700 & right \\
\end{tabular}}
\end{center}

\subsection{Numerals}\label{numeral}\index{numeral,
the construction of in HOL logic@\ml{numeral}, the construction of in \HOL{} logic}

The type \ml{num}
\index{num, the type in \HOL\ logic@\ml{num}, the type in \HOL{} logic}
is usually thought of as being supplied with an infinite collection of
numerals: \ml{1}, \ml{2}, \ml{3}, \etc.  However, the \HOL{} logic has
no way to define such infinite families of constants; instead, all
numerals other than $0$ are actually built up from the constants
introduced by the following definitions:
\begin{verbatim}
   NUMERAL_DEF |- !x. NUMERAL x = x

   BIT1        |- !x. BIT1 n = n + (n + SUC 0)
   BIT2        |- !x. BIT2 n = n + (n + SUC(SUC 0))

   ALT_ZERO    |- ALT_ZERO = 0
\end{verbatim}

\noindent For example, the numeral $5$ is represented by the term
\[
   \ml{NUMERAL}(\ml{BIT1}(\ml{BIT2}(\ml{ALT\_ZERO})))
\]
and the \HOL{} parser and pretty-printer make such terms appear as
numerals. This binary representation for numerals allows for
asymptotically efficient calculation. Theorems supporting arithmetic
calculations on numerals can be found in the \theoryimp{numeral}
theory; these are mechanized by the \verb+reduce+ library. Thus,
arithmetic calculations are performed by deductive steps in \HOL.
For example the following calculation of $2 ^{(1023 + 14)/9}$ takes 
approximately 70,000 primitive inference steps and returns in two
seconds. 
%
\begin{boxed}
{\small
\begin{verbatim}
 - reduceLib.REDUCE_CONV ``2 EXP ((1023 + 14) DIV 9)``;

 > val it = |- 2 ** ((1023 + 14) DIV 9) = 41538374868278621028243970633760768
\end{verbatim}}
\end{boxed}

\paragraph {Construction of numerals}

Numerals may of course be built using \ml{mk\_comb}, and taken apart with
\ml{dest\_comb}; however, a more convenient interface to this
functionality is provided by the functions \ml{mk\_numeral},
\ml{dest\_numeral}, and \ml{is\_numeral} (found in the structure
\ml{numSyntax}). These entrypoints make use of an \ML{} structure
\ml{Arbnum} which implements arbitrary precision numbers {\verb+num+}. The
following session shows how \HOL{} numerals are constructed from elements of
type \verb+num+ and how numerals are destructed. The structure
{\small\verb+Arbnum+} provides a full collection of arithmetic
operations, using the usual names for the operations, \eg \verb|+|,
\verb|*|, \verb|-|, \etc.

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
  - numSyntax.mk_numeral 
       (Arbnum.fromString "3432432423423423234");
  > val it = ``3432432423423423234`` : term

  - numSyntax.dest_numeral it;
  > val it = 3432432423423423234 : num

  - Arbnum.+(it,it);
  > val it = 6864864846846846468 : num
\end{verbatim}
\end{session}

\paragraph{Numerals and Peano numbers}

Numerals are related to numbers built from {\small\verb+0+} and
{\small\verb+SUC+} via the derived inference rule
\ml{num\_CONV}, found in the \ml{numLib} library.

\begin{boxed}
\index{num_CONV@\ml{num\_CONV}|pin}
\begin{verbatim}
   num_CONV : term -> thm
\end{verbatim}
\end{boxed}

\noindent \ml{num\_CONV} can be used to generate the `\ml{SUC}'
equation for any non-zero numeral.  For example:

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
- load "numLib"; open numLib;

- num_CONV ``2``;
> val it = |- 2 = SUC 1 : thm

- num_CONV ``3141592653``;
> val it = |- 3141592653 = SUC 3141592652 : thm
\end{verbatim}
\end{session}

\noindent The \ml{num\_CONV} function works purely by inference.

\subsubsection{Overloading of arithmetic operators}
\label{arith-overloading}

When other numeric theories are loaded (such as those for the reals or
integers), numerals are overloaded so that the numeral {\small\verb+1+} can
actually stand for a natural number, an integer or a real value. The
parser has a pass of overloading resolution in which it attempts to 
determine the actual type to give to a numeral. For example, in the
following session, the theory of integers is loaded, whereupon the 
numeral \verb+2+ is taken to be an integer.
%
\begin{session}
{\small
\begin{verbatim}
  - load "integerTheory";
  > val it = () : unit

  - ``2``;
  <<HOL message: more than one resolution of overloading was possible.>>
  > val it = `2` : term

  - type_of it;
  > val it = `:int` : hol_type
\end{verbatim}}
\end{session}

 In order to precisely specify the desired type, the user can use single
character suffixes (`\ml{n}' for the natural numbers, and `\ml{i}' for
the integers):
\begin{session}
{\small
\begin{verbatim}
- type_of ``2n``;
> val it = `:num` : hol_type

- type_of ``42i``;
> val it = `:int` : hol_type
\end{verbatim}}
\end{session}

A numeric literal for a \HOL{} type other than \verb+num+, such as
\verb+42i+,  is represented by the application of an
\emph{injection} function of type {\small\verb+num -> ty+} to a
numeral. The injection function is different for each type
{\small\verb+ty+}. See Section \ref{integers} for further discussion.

The functions {\verb+mk_numeral+}, {\verb+dest_numeral+}, and
{\verb+is_numeral+} only work for numerals, and not for numeric
literals with character suffixes other than {\small\verb+n+}. For
information on how to install new character suffixes, consult the
{\small\verb+add_numeral_info+} entry in \REFERENCE.

\subsection{Integers}\label{integers}

There is an extensive theory of integers in \HOL. The type of integers
is constructed as a quotient on pairs of natural numbers. A standard
collection of operators are defined. These are overloaded with
similar operations on the natural numbers, and on the real numbers.
The constants defined in the integer theory include those found in the
following table.

\begin{center}
{\small
\begin{tabular}{@{}cccc}
Constant & Overloaded symbol & Strength & Associativity \\ \hline
{\small\verb+int_ge+} &{\small\verb+>=+} & 450 & right \\
{\small\verb+int_le+} &{\small\verb+<=+} & 450 & right \\
{\small\verb+int_gt+} &{\small\verb+>+}  & 450 & right \\
{\small\verb+int_lt+} &{\small\verb+<+}  & 450 & right \\
{\small\verb+int_add+} &{\small\verb%+%} & 500 & left \\
{\small\verb+int_sub+} &{\small\verb%-%} & 500 & left \\
{\small\verb+int_neg+} &{\small\verb%~%} & 900 & trueprefix \\
{\small\verb+int_mul+} &{\small\verb%*%} & 600 & left \\
{\small\verb%/%} & & 600 & left \\
{\small\verb+%+} & & 650 & left \\
{\small\verb+int_exp+} &{\small\verb%**%} & 700 & right \\
{\small\verb+int_of_num+} &{\small\verb%&%} & & prefix \\
\end{tabular}}
\end{center}

The overloaded symbol {\small\verb+& : num -> int+} denotes the
injection function from natural numbers to integers. The following
session illustrates how overloading and integers literals are treated.

\begin{session}
\begin{verbatim}
Term `1i = &(1n + 0n)`;
> val it = `1 = & (1 + 0)` : term

- show_numeral_types := true;
> val it = () : unit

- Term `&1 = &(1n + 0n)`;
<<HOL message: more than one resolution of overloading was possible.>>
> val it = `1i = & (1n + 0n)` : Term.term
\end{verbatim}
\end{session}


\subsection{Real numbers}

There is an extensive collection of theories that make up the
development of real numbers and analysis in HOL, due to John Harrison
\cite{jrh:thesis}. We will only give a sketchy overview of the
development; the interested reader should consult \REFERENCE\ and
Harrison's thesis.

The axioms for the real numbers are derived from the `half reals' which
are constructed from the `half rationals'. This part of the development
is recorded in {\small\verb+hratTheory+} and
{\small\verb+hrealTheory+}, but is not used once the reals have been
constructed. The real axioms are derived in the theory
{\small\verb+realaxTheory+}. A standard collection of operators on the
reals, and theorems about them, is found in {\small\verb+realaxTheory+}
and {\small\verb+realTheory+}. The operators and their parse status are
listed in the following table.

\begin{center}
{\small
\begin{tabular}{@{}cccc}
Constant & Overloaded symbol & Strength & Associativity \\ \hline
{\small\verb+real_ge+} &{\small\verb+>=+} & 450 & right \\
{\small\verb+real_lte+} &{\small\verb+<=+} & 450 & right \\
{\small\verb+real_gt+} &{\small\verb+>+}  & 450 & right \\
{\small\verb+real_lt+} &{\small\verb+<+}  & 450 & right \\
{\small\verb+real_add+} &{\small\verb%+%} & 500 & left \\
{\small\verb+real_sub+} &{\small\verb%-%} & 500 & left \\
{\small\verb+real_neg+} &{\small\verb%~%} & 900 & trueprefix \\
{\small\verb+real_mul+} &{\small\verb%*%} & 600 & left \\
{\small\verb+real_div+} & {\small\verb%/%} & 600 & left \\
{\small\verb+pow+} & &700 & right \\
{\small\verb+real_of_num+} &{\small\verb%&%} & & prefix \\
\end{tabular}}
\end{center}

On the basis of {\small\verb+realTheory+}, the following  sequence of
theories is constructed:

\begin{description}
\item [topology] Topologies and metric spaces, including metric on
the real line.
\item [nets] Moore-Smith covergence nets, and special cases like
sequences.
\item [seq] Sequences and series of real numbers.
\item [lim] Limits, continuity and differentiation.
\item [powser] Power series.
\item [transc] Transcendental functions, \emph{e.g.}, exp, sin,
cos, ln, root, sqrt, pi, tan, asn, acs, atn. Also the Kurzweil-Henstock
gauge integral the fundamental theorem of calculus, and McLaurin's
theorem.

\end{description}

\section{Sequences}

\HOL{} provides theories for various kinds of sequences: finite lists, lazy lists,
paths, finite strings, and $n$-bit words.

\subsection{Lists}\label{avra_list}
\index{list, the type operator in HOL logic@\ml{list}, the type operator in \HOL{} logic}
\index{recursive definitions, in HOL logic@recursive definitions, in \HOL{} logic!automated for lists|(}
\index{types, in HOL logic@types, in \HOL{} logic!tools for construction of}
\index{lists, in HOL logic@lists, in \HOL{} logic|(}
\index{list theory, in HOL logic@\ml{list} theory, in \HOL{} logic|(}
\index{lists, in HOL logic@\ml{[} $\cdots$ \ml{;} $\cdots$ \ml{]} (lists, in \HOL{} logic)|(}

\HOL{} lists are inductively defined finite sequences where each
element in a list has the same type. The theory \ml{list} introduces
the unary type operator $\alpha \; \konst{list}$ by a type definition
and a standard collection of list processing functions are
defined. The primitive constructors {\small\verb+NIL+} and {\small\verb+CONS+}
%
\begin{hol}
\index{NIL@\ml{NIL}}
\index{CONS@\ml{CONS}}
{\small
\begin{verbatim}
   NIL  : 'a list
   CONS : 'a -> 'a list -> 'a list
\end{verbatim}
}\end{hol}
%
are used to build lists and have been defined from the representing type for
lists. The \HOL{} parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of list expressions}
has been specially  modified to  parse the expression
{\small\verb%[]%} into {\small\verb%NIL%}, to parse the expression
{\small\verb%h :: t%} into {\small\verb%CONS h t%}, and to parse the expression
{\small\verb%[%}$t_1${\small\verb%;%}$t_2${\small\verb%;%}$\ldots${\small\verb%;%}$t_n${\small\verb%]%}
into {\small\verb%CONS %}$t_1${\small\verb% (CONS %}$t_2 \cdots\
${\small\verb%(CONS %}$t_n${\small\verb%  NIL)%}$\  \cdots\ ${\small\verb%)%}.
The \HOL{} printer
\index{printing, in HOL logic@printing, in \HOL{} logic!of list expressions}
reverses these transformations.

Based on the inductive characterization of the type, the following
fundamental theorems about lists
\index{list theorems, in HOL logic@list theorems, in \HOL{} logic|(}
are proved and stored in the theory \ml{list}.

\begin{hol}
\index{list_Axiom@\ml{list\_Axiom}}
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
\index{axioms!in list theory@in \ml{list} theory}
\index{list_INDUCT@\ml{list\_INDUCT}}
\index{list_CASES@\ml{list\_CASES}}
\index{CONS_11@\ml{CONS\_{11}}}
\index{NOT_NIL_CONS@\ml{NOT\_NIL\_CONS}}
\index{NOT_CONS_NIL@\ml{NOT\_CONS\_NIL}}
\index{characterizing theorem!for lists}
{\small
\begin{verbatim}
  list_Axiom   |- !x f. ?fn. (fn [] = x) /\ (!h t. fn (h::t) = f(fn t)h t)

  list_INDUCT  |- !P. P [] /\ (!t. P t ==> (!h. P(h::t))) ==> (!l. P l)

  list_CASES   |- !l. (l = []) \/ (?t h. l = h::t)

  CONS_11      |- !h t h' t'. (h::t = h'::t') = (h = h') /\ (t = t')

  NOT_NIL_CONS |- !h t. ~([] = h::t)

  NOT_CONS_NIL |- !h t. ~(h::t = [])
\end{verbatim}}
\end{hol}

The theorem \ml{list\_Axiom} shown above is analogous to the primitive
recursion theorem\index{primitive recursion theorem!for lists} on the
natural numbers discussed above in Section~\ref{num-prim-rec}.  It
states the validity of primitive recursive definitions on lists, and
can be used to justify any such definition.  The \ML\ function
{\small\verb+new_recursive_definition+} uses this theorem to do
automatic \index{primitive recursion theorem!automated use of, in HOL
system@automated use of, in \HOL{} system|)} proofs of the existence
of primitive recursive functions on lists and then make constant
specifications to introduce constants that denote such functions.

The induction theorem for lists, \ml{list\_INDUCT}, provides the main
proof tool used to reason about operations that manipulate lists. The
theorem \ml{list\_CASES} is used to perform case analysis on whether a
list is empty or not.

The theorem {\small\verb+CONS_11+} shows that {\small\verb+CONS+} is injective;
the theorems {\small\verb+NOT_NIL_CONS+} and {\small\verb+NOT_CONS_NIL+} show that
{\small\verb+NIL+} and {\small\verb+CONS+} are distinct, \ie,
cannot give rise to the same structure. Together, these three theorems
are used for equational reasoning about lists.

The predicate \ml{NULL} and the selectors \ml{HD} and \ml{TL} are
defined
\index{list definitions, in HOL logic@list definitions, in \HOL{} logic}
in the theory \ml{list} by
%
\begin{hol}
\index{NULL, the definition in HOL logic@\ml{NULL}, the definition in \HOL{} logic}
\index{HD, the definition in HOL logic@\ml{HD}, the definition in \HOL{} logic}
\index{TL, the definition in HOL logic@\ml{TL}, the definition in \HOL{} logic}
{\small
\begin{verbatim}
   NULL |- NULL [] /\ (!h t. ~NULL(h::t))
   HD   |- !h t. HD(h::t) = h
   TL   |- !h t. TL(h::t) = t
\end{verbatim}}
\end{hol}

\noindent The following functions on lists are also defined in the theory \ml{list}.
%
\index{SUM, the theorem in HOL logic@\ml{SUM}, the theorem in \HOL{} logic}
\index{APPEND, the theorem in HOL logic@\ml{APPEND}, the theorem in \HOL{} logic}
\index{concatenation, of lists!in HOL logic@in \HOL{} logic}
\index{FLAT, the theorem in HOL logic@\ml{FLAT}, the theorem in \HOL{} logic}
\index{LENGTH, the theorem in HOL logic@\ml{LENGTH}, the theorem in \HOL{} logic}
\index{MAP, the theorem in HOL logic@\ml{MAP}, the theorem in \HOL{} logic}
\index{EL, the theorem in HOL logic@\ml{EL}, the theorem in \HOL{} logic}
\index{SUM, the constant in HOL logic@\ml{SUM}, the constant in \HOL{} logic}
\index{APPEND, the constant in HOL logic@\ml{APPEND}, the constant in \HOL{} logic}
\index{FLAT, the constant in HOL logic@\ml{FLAT}, the constant in \HOL{} logic}
\index{LENGTH, the constant in HOL logic@\ml{LENGTH}, the constant in \HOL{} logic}
\index{MAP, the constant in HOL logic@\ml{MAP}, the constant in \HOL{} logic}
\index{EL, the constant in HOL logic@\ml{EL}, the constant in \HOL{} logic}
\index{EVERY, the HOL constant@\ml{EVERY}, the \HOL{} constant}
\index{EVERY_DEF@\ml{EVERY\_DEF}}
\index{EVERY, the HOL constant@\ml{EVERY}, the \HOL{} constant}
\index{EXISTS_DEF@\ml{EXISTS\_DEF}}
\index{EXISTS, the HOL constant@\ml{EXISTS}, the \HOL{} constant}
\index{FILTER@\ml{FILTER}}
\index{FILTER, the HOL constant@\ml{FILTER}, the \HOL{} constant}
\index{FOLDL@\ml{FOLDL}}
\index{FOLDL, the HOL constant@\ml{FOLDL}, the \HOL{} constant}
\index{FOLDR@\ml{FOLDR}}
\index{FOLDR, the HOL constant@\ml{FOLDR}, the \HOL{} constant}
\index{MEM@\ml{MEM}}
\index{MEM, the HOL constant@\ml{MEM}, the \HOL{} constant}
%
\paragraph{Case expressions}

Compound \HOL{} expressions that branch based on
whether a term is an empty or non-empty list have the
surface syntax (borrowed from ML)
\[
\begin{array}{l}
\konst{case}\ e_1 \ \konst{of} \\
{~~~~~~~}  \nil \longrightarrow e_2 \\
{~~~}  \mid\mid \cons{h}{t} \longrightarrow e_3
\end{array}
\]
%
Such an expression is translated to
$\konst{list\_case}\ e_2\ (\lambda h\; t.\ e_3)\ e_1$ where the constant
{\small\verb+list_case+} is defined as follows:
{\small
\begin{verbatim}
  list_case_def
    |- (!v f. list_case v f [] = v) /\
       (!v f a0 a1. list_case v f (a0::a1) = f a0 a1)
\end{verbatim}}

\paragraph{List membership}

Membership in a list {\small\verb+MEM+} is defined as follows:
%
{\small
\begin{verbatim}
  MEM |- (!x. MEM x [] = F) /\
         (!x h t. MEM x (h::t) = (x = h) \/ MEM x t)
\end{verbatim}}

\paragraph {Concatenation of lists}

Binary list concatenation ({\small\verb+APPEND+}) may also be denoted by
the infix operator {\small\verb|++|}; thus the expression
{\small\verb|L1 ++ L2|} is translated into {\small\verb+APPEND L1 L2+}.
The concatenation of a list of lists into a list is achieved by
{\small\verb+FLAT+}.
%
{\small
\begin{verbatim}
  APPEND
    |- (!l. APPEND [] l = l) /\
       (!l1 l2 h. APPEND (h::l1) l2 = h::APPEND l1 l2)
  FLAT
    |- (FLAT [] = []) /\ (!h t. FLAT(h::t) = h ++ FLAT t)
\end{verbatim}}

\paragraph {Numbers and lists}

The length ({\small\verb+LENGTH+}) and size ({\small\verb+list_size+})
of a list are suported notions. The size of a list takes account of
the size of each element of the list (given by parameter
$f:\alpha\to\konst{num}$), while the length of the list ignores the
size of each list element. The alternate length definition
({\small\verb+LEN+}) is tail-recursive.
%
{\small
\begin{verbatim}
  LENGTH
    |- (LENGTH [] = 0) /\ (!h t. LENGTH (h::t) = SUC(LENGTH t))
  LEN_DEF
    |- (!n. LEN [] n = n) /\ !h t n. LEN (h::t) n = LEN t (n + 1)
  list_size_def
    |- (!f. list_size f [] = 0) /\
       !f a0 a1. list_size f (a0::a1) = 1 + (f a0 + list_size f a1))
  EL
    |- (!l. EL 0 l = HD l) /\ (!l n. EL (SUC n) l = EL n (TL l))
\end{verbatim}}

\noindent
Note that the extraction of the $n$th element ({\small\verb+EL+}) of a
list starts its indexing from 0.

\paragraph {Mapping functions over lists}

There are functions for mapping a function $f : \alpha \to \beta$ over
a single list ({\small\verb+MAP+}) or a function $f : \alpha \to \beta \to \gamma$
over two lists ({\small\verb+MAP2+}).
%
{\small
\begin{verbatim}
  MAP
    |- (!f. MAP f [] = []) /\
       (!f h t. MAP f (h::t) = f h::MAP f t)
  MAP2
    |- (!f. MAP2 f [] [] = []) /\
       !f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2
\end{verbatim}}
%
The behaviour of {\small\verb+MAP2+} in the two cases when it is given
one empty list and one non-empty list is unspecified.

\paragraph {Predicates over lists}

Predicates can be applied to lists in a universal sense (the predicate
must hold of every element in the list) or an existential sense (the
predicate must hold of some element in the list). This functionality
is supported by {\small\verb+EVERY+} and {\small\verb+EXISTS+},
respectively. The elimination of all elements in list not satisfying
a given predicate is performed by {\small\verb+FILTER+}.
%
{\small
\begin{verbatim}
  EVERY_DEF
    |- (!P. EVERY P [] = T) /\
       (!P h t. EVERY P (h::t) = P h /\ EVERY P t)
  EXISTS_DEF
    |- (!P. EXISTS P [] = F) /\
       (!P h t. EXISTS P (h::t) = P h \/ EXISTS P t)
  FILTER
    |- (!P. FILTER P [] = []) /\
       (!P h t. FILTER P (h::t) = if P h then h::FILTER P t else FILTER P t)
  ALL_DISTINCT
    |- (ALL_DISTINCT [] = T) /\
       (!h t. ALL_DISTINCT (h::t) = ~MEM h t /\ ALL_DISTINCT t)
\end{verbatim}}
%
The predicate {\small\verb+ALL_DISTINCT+} holds on a list  just
in case no element in the list is equal to any other.

\paragraph {Folding}

Applying a binary function $f : \alpha\to\beta\to\beta$ pairwise
through a list and accumulating the result is known as
\emph{folding}. At times, it is necessary to do this operation
from left-to-right ({\small\verb+FOLDL+}), and at others the
right-to-left direction ({\small\verb+FOLDR+}) is required.
%
{\small
\begin{verbatim}
  FOLDL
    |- (!f e. FOLDL f e [] = e) /\
       (!f e x l. FOLDL f e (x::l) = FOLDL f (f e x) l)
  FOLDR
    |- (!f e. FOLDR f e [] = e) /\
       (!f e x l. FOLDR f e (x::l) = f x (FOLDR f e l))
\end{verbatim}}

\paragraph {List reversal}

The reversal of a list ({\small\verb+REVERSE+}) and its tail recursive counterpart
{\small\verb+REV+} are defined in {\small\verb+list+}.
{\small
\begin{verbatim}
  REVERSE_DEF
    |- (REVERSE [] = []) /\
       (!h t. REVERSE (h::t) = REVERSE t ++ [h])
  REV_DEF
    |- (!acc. REV [] acc = acc) /\
       (!h t acc. REV (h::t) acc = REV t (h::acc))
\end{verbatim}}

\paragraph {Conversion to sets}

Lists can be converted to sets ({\small\verb+LIST_TO_SET+}) by
partial application of {\small\verb+MEM+}. The somewhat
terse definition is used to derive the theorem
{\small\verb+IN_LIST_TO_SET+}.
%
{\small
\begin{verbatim}
  LIST_TO_SET
    |- LIST_TO_SET = combin$C MEM
  IN_LIST_TO_SET
    |- x IN LIST_TO_SET l = MEM x l
\end{verbatim}}
%
Further support for translating between different kinds of
collections may be found in the {\small\verb+container+} theory.

\paragraph {Pairs and lists}

Two lists of equal length may be component-wise paired by
the {\small\verb+ZIP+} operation. The result is unspecified
when the lists are not the same length. The inverse operation,
{\small\verb+UNZIP+}, translates a list of pairs into a pair of
lists.
%
{\small
\begin{verbatim}
  ZIP
    |- (ZIP ([],[]) = []) /\
       (!x1 l1 x2 l2. ZIP (x1::l1,x2::l2) = (x1,x2)::ZIP (l1,l2))
  UNZIP_THM
    |- (UNZIP [] = ([],[])) /\
       (UNZIP ((x,y)::t) = let (L1,L2) = UNZIP t in (x::L1,y::L2))
\end{verbatim}}

\paragraph {Alternate access}

Lists are essentially treated in a stack-like manner. However, at
times it is convenient to access the last element
({\small\verb+LAST+}) of a non-empty list directly. The last element
of a non-empty list is dropped by {\small\verb+FRONT+}.
%
{\small
\begin{verbatim}
  LAST_DEF
    |- !h t. LAST (h::t) = if t = [] then h else LAST t
  FRONT_DEF
    |- !h t. FRONT (h::t) = if t = [] then [] else h::FRONT t
  APPEND_FRONT_LAST
    |- !l. ~(l = []) ==> (FRONT l ++ [LAST l] = l)
\end{verbatim}}
%
Joining the front part and the last element of a non-empty list yields
the original list.  Both {\small\verb+LAST+} and {\small\verb+FRONT+}
are unspecified on empty lists. 


\noindent For a complete list of available theorems in
{\small\verb+list+}, see \REFERENCE.  Further development of list
theory can be found in {\small\verb+rich_list+}.

\index{list theorems, in HOL logic@list theorems, in \HOL{} logic|)}
\index{lists, in HOL logic@\ml{[} $\cdots$ \ml{;} $\cdots$ \ml{]} (lists, in \HOL{} logic)|)}
\index{list theory, in HOL logic@\ml{list} theory, in \HOL{} logic|)}
\index{lists, in HOL logic@lists, in \HOL{} logic|)}
\index{recursive definitions, in HOL logic@recursive definitions, in \HOL{} logic!automated for lists|)}

\subsection{Possibly infinite sequences (\theoryimp{llist})}

\index{lazy lists@``lazy'' lists!\HOL{} theory of|(}
The theory \theoryimp{llist} contains the definition of a type of
possibly infinite sequences.  This type is similar to the ``lazy
lists'' of programming languages like Haskell, hence the name of the
theory.  The \theoryimp{llist} theory has a number of constants that
are analogous to constants in the theory of (necessarily finite)
lists.  The \theoryimp{llist} versions of these constants have the
same names, but with a capital `L\/' prepended.  Thus, some of the core
constants in this theory are:

{\small \begin{verbatim}
   LNIL  : 'a llist
   LCONS : 'a -> 'a llist -> 'a llist
   LHD   : 'a llist -> 'a option
   LTL   : 'a llist -> 'a llist option
\end{verbatim}}

The \ml{LHD} and \ml{LTL} constants return \ml{NONE} when applied to
the empty sequence, \ml{LNIL}.  This use of an option type is another
way of modelling the essential partiality of these constants.  (In the
theory of lists, the analogous \ml{HD} and \ml{TL} functions are
simply have unspecified values when applied to empty lists.)

The type \ml{llist} is not inductive, and there is no primitive
recursion theorem supporting the definition of functions that have
domains of type \ml{llist}.  Rather, \ml{llist} is a coinductive type,
and has an axiom that justifies the definition of (co-)recursive
functions that map into the \ml{llist} type.  This axiom has the name
\ml{llist\_Axiom}, and states
{\small \begin{verbatim}
   !f : 'a -> ('a # 'b) option.
      ?g : 'a -> 'b llist.
         (!x. LHD (g x) = OPTION_MAP SND (f x)) /\
         (!x. LTL (g x) = OPTION_MAP (g o FST) (f x))
\end{verbatim}}
\noindent An equivalent form of the above is
{\small
\begin{verbatim}
   !f. ?g.
      !x. g x = case f x of
                   NONE -> LNIL
                || SOME (x',y) -> LCONS y (g x')
\end{verbatim}
}

Other constants in the theory \theoryimp{llist} include \texttt{LTAKE},
\texttt{LDROP}, \texttt{LMAP}, \texttt{LFINITE} and
\texttt{LFILTER}. Their types are
{\small \begin{verbatim}
   LTAKE   : num -> 'a llist -> 'a list
   LDROP   : num -> 'a llist -> 'a llist
   LMAP    : ('a -> 'b) -> 'a llist -> 'b llist
   LFINITE : 'a llist -> bool
   LFILTER : ('a -> bool) -> 'a llist -> 'a llist
\end{verbatim}}
\noindent They are characterised by the following theorems
{\small
\begin{verbatim}
   LTAKE_THM
      |- (LTAKE 0 l = SOME []) /\
         (LTAKE (SUC n) LNIL = NONE) /\
         (LTAKE (SUC n) (LCONS h t) = OPTION_MAP (CONS h) (LTAKE n t)

   LDROP_THM
      |- (LDROP 0 ll = SOME ll) /\
         (LDROP (SUC n) ll = NONE) /\
         (LDROP (SUC n) (LCONS h t) = LDROP n t)

   LMAP
      |- (LMAP f LNIL = LNIL) /\
         (LMAP f (LCONS h t) = LCONS (f h) (LMAP f t))

   LFINITE_THM
      |- (LFINITE LNIL = T) /\
         (LFINITE (LCONS h t) = LFINITE t)

   LFILTER_THM
      |- (LFILTER P LNIL = LNIL) /\
         (LFILTER P (LCONS h t) = if P h then LCONS h (LFILTER P t)
                                  else LFILTER P t)
\end{verbatim}
}

\paragraph{Proof principles}

Finally, there are two very important proof principles for proving
that two \texttt{llist} values are equal.  The first states that two
sequences are equal if they return the same prefixes of length $n$ for
all possible values of $n$:
{\small
\begin{verbatim}
   LTAKE_EQ |- (ll1 = ll2) = (!n. LTAKE n ll1 = LTAKE n ll2)
\end{verbatim}
}
\noindent This theorem is subsequently used to derive the bisimulation
principle:
{
\small
\begin{verbatim}
   LLIST_BISIMULATION
            |- (ll1 = ll2) =
               ?R. R ll1 ll2 /\
                   !ll3 ll4. R ll3 ll4 ==>
                             (ll3 = LNIL) /\ (ll4 = LNIL) \/
                             (LHD ll3 = LHD ll4) /\
                             R (THE (LTL ll3)) (THE (LTL ll4))
\end{verbatim}
}
The principle of bisimulation states that two \ml{llist} values $l_1$
and $l_2$ are equal if (and only if) it is possible to find a
relation $R$ such that
\begin{itemize}
\item $R$ relates the two values, i.e., $R\;l_1\;l_2$; and
\item if $R$ holds of any two values $l_3$ and $l_4$, then either
  \begin{itemize}
  \item both $l_3$ and $l_4$ are empty; or
  \item the head elements of $l_3$ and $l_4$ are the same, and the
    tails of those two values are again related by $R$
  \end{itemize}
\end{itemize}
Of course, a possible $R$ would be equality itself, but the strength
of this theorem is that other, more convenient relations can also be
used.
\index{lazy lists@``lazy'' lists!\HOL{} theory of|)}

\subsection{Labelled paths (\theoryimp{path})}

The theory \theoryimp{path}
\index{labelled paths!\HOL{} theory of|(}
\index{reduction sequences!\HOL{} theory of|(}
defines a binary type operator $(\alpha,\beta)\texttt{path}$, which
stands for possibly infinite paths of the following form
\[
  \alpha_1 \stackrel{\beta_1}{\longrightarrow}
  \alpha_2 \stackrel{\beta_2}{\longrightarrow}
  \alpha_3 \stackrel{\beta_3}{\longrightarrow} \cdots
  \alpha_n \stackrel{\beta_n}{\longrightarrow}
  \alpha_{n+1} \stackrel{\beta_{n+1}}{\longrightarrow}  \cdots
  \]
The \texttt{path} type is thus an appropriate model for reduction
sequences, where the $\alpha$ parameter corresponds to ``states'', and
the $\beta$ parameter corresponds to the labels on the arrows.

The model of $(\alpha,\beta)\texttt{path}$ is $\alpha \times
((\alpha\times\beta)\texttt{llist})$.  The type of paths has two
constructors:
{\small
\begin{verbatim}
   stopped_at : 'a -> ('a,'b) path
   pcons      : 'a -> 'b -> ('a,'b) path -> ('a,'b) path
\end{verbatim}
}
The \ml{stopped\_at} constructor returns a path containing just one
state, and no transitions.  (Thus, the reduction sequence has
``stopped at'' this state.)  The \ml{pcons} constructor takes a state,
a label, and a path, and returns a path which is now headed by the
state argument, and which moves from that state via the label argument
to the path.  Graphically, $\texttt{pcons}\;x\;l\;p$ is equal to
\[
x \stackrel{l}{\longrightarrow}
\underbrace{p_1 \stackrel{l_1}{\longrightarrow} p_2
  \stackrel{l_2}{\longrightarrow} \cdots\quad}_p
\]
Other constants defined in theory \theoryimp{path} include
{\small
\begin{verbatim}
   finite  : ('a,'b) path -> bool
   first   : ('a,'b) path -> 'a
   labels  : ('a,'b) path -> 'b llist
   last    : ('a,'b) path -> 'a
   length  : ('a,'b) path -> num option
   okpath  : ('a -> 'b -> 'a -> bool) -> ('a,'b) path -> bool
   pconcat : ('a,'b) path -> 'b -> ('a,'b) path -> ('a,'b) path
   pmap    : ('a -> 'c) -> ('b -> 'd) -> ('a,'b)path -> ('c,'d)path
\end{verbatim}
}

The \texttt{first} function returns the first element of a path.
There always is such an element, and the defining equations are
{\small
\begin{verbatim}
   first_thm  |- (first (stopped_at x) = x) /\
                 (first (pcons x l p) = x)
\end{verbatim}
}

On the other hand, the \texttt{last} function does not always have a
well-specified value, though it still has nice characterising
equations:
{\small
\begin{verbatim}
   last_thm   |- (last (stopped_at x) = x) /\
                 (last (pcons x l p) = last p)
\end{verbatim}
}

The theorem for \texttt{finite} has a similar feel, but has a definite
value (\texttt{F}, or \emph{false}) on infinite paths), whereas the
value of \texttt{last} on such paths is unspecified:
{\small
\begin{verbatim}
   finite_thm |- (finite (stopped_at x) = T) /\
                 (finite (pcons x l p) = finite p)
\end{verbatim}
}

The function \texttt{pconcat} concatenates two paths, linking them
with a provided label.  If the first path is infinite, then the result
is equal to that first path.  The defining equation is
{\small
\begin{verbatim}
  pconcat_thm |- (pconcat (stopped_at x) lab p2 = pcons x lab p2) /\
                 (pconcat (pcons x r p) lab p2 =
                      pcons x r (pconcat p lab p2)
\end{verbatim}
}
\noindent
These equations are true even when the first argument to
\texttt{pconcat} is an infinite path.

The \texttt{okpath} predicate tests whether or not a path is a valid
transition given a ternary transition relation.  Its characterising
theorem is
{\small
\begin{verbatim}
  okpath_thm |-
     (okpath R (stopped_at x)) /\
     (okpath R (pcons x r p) = R x r (first p) /\ okpath R p)
\end{verbatim}
}

There is also an induction principle that simplifies reasoning about
finite $R$-paths:
{\small
\begin{verbatim}
  finite_okpath_ind |-
      (!x. P (stopped_at x)) /\
      (!x r p. okpath R p /\ finite p /\ R x r (first p) /\ P p ==>
               P (pcons x r p)) ==>
      !p. okpath R p /\ finite p ==> P p
\end{verbatim}
}
\index{labelled paths!\HOL{} theory of|)}
\index{reduction sequences!\HOL{} theory of|)}


\subsection{Character strings (\theoryimp{string})}

The theory \theoryimp{string} defines a type of characters and a type
of finite strings built from those characters, along with a useful suite of 
definitions for operating on strings. 

\paragraph {Characters}

The type \verb+char+ is represented by the numbers less than 256. Two
constants are defined: {\small\verb+CHR +}$: \konst{num}\to\konst{char}$ and
{\small\verb+ORD +}$: \konst{char}\to\konst{num}$. The following theorems
hold:
{\small
\begin{verbatim}
  CHR_ORD  |- !a. CHR (ORD a) = a
  ORD_CHR  |- !r. r < 256 = (ORD (CHR r) = r)
\end{verbatim}
}

\paragraph {Strings}

The type \verb+string+ is inductively characterized by the
constructors 
%
{\small
\begin{verbatim}
  EMPTYSTRING : string
  STRING      : char -> string -> string
\end{verbatim}
}
%
The \HOL{} parser maps the syntax \verb+""+ to 
{\small\verb+EMPTYSTRING+}, and the \HOL{} printer inverts this.
The parser expands string literals of the form \verb+"+$c_1 c_2
\ldots c_n$\verb+"+ to the compound term

\smallskip

\qquad {\small\verb+STRING+} $c_1$ ({\small\verb+STRING+} $c_2$ \
$\ldots$ ({\small\verb+STRING+} $c_{n-1}$ \ ({\small\verb+STRING+}
$c_n$ \ {\small\verb+EMPTYSTRING+})) $\ldots$ )

\smallskip

\noindent As a result of the characterization, the following basic theorems
hold:
%
{\small
\begin{verbatim}
  STRING_11
    |- !c1 c2 s1 s2. (STRING c1 s1 = STRING c2 s2) = (c1=c2) /\ (s1=s2)
  STRING_DISTINCT
    |- !c s. ~("" = STRING c s)) /\ (!c s. ~(STRING c s = ""))
  string_Axiom
    |- !b g. ?f.  (f "" = b) /\
                  (!c t. f (STRING c t) = g c t (f t))
  STRING_INDUCT_THM
    |- !P. P "" /\ (!s. P s ==> !c. P (STRING c s)) ==> !s. P s
  STRING_CASES
    |- !s. (s = "") \/ (?c str. s = STRING c str)
\end{verbatim}
}
%
There is also a destructor function {\small\verb+DEST_STRING+} for
strings which returns an option type.
{\small
\begin{verbatim}
  DEST_STRING
    |- (DEST_STRING "" = NONE) /\
       (DEST_STRING (STRING c rst) = SOME(c,rst))
\end{verbatim}
}


\paragraph{Case expressions}

Compound \HOL{} expressions that branch based on
whether a term is an empty or non-empty string have the
surface syntax
%
{\small
\begin{verbatim}
   case s 
    of "" -> e1
    || STRING c rst -> e2
\end{verbatim}}
%
Such an expression is translated to
$\konst{string\_case}\ e_1 \ (\lambda c\; rst.\ e_2)\ s$ where the constant
{\small\verb+string_case+} is defined as follows:
%
{\small
\begin{verbatim}
  STRING_CASE_DEF
    |- (string_case b f ""  = b) /\
       (string_case b f (STRING c s) = f c s)
\end{verbatim}}

\paragraph {Length and concatenation}

The length of a string ({\small\verb+STRLEN+}) is defined by primitive
recursion. The concatenation of strings ({\small\verb+STRCAT+}) may be
expressed recursively ({\small\verb+STRCAT_EQNS+})or as a fold 
({\small\verb+STRCAT_EXPLODE+}):
%
{\small
\begin{verbatim}
  STRLEN_DEF
    |- (STRLEN "" = 0) /\ 
       (STRLEN (STRING c s) = 1 + STRLEN s)

  STRCAT_EQNS = Q.store_thm
    |- (STRCAT "" s = s) /\
       (STRCAT s "" = s) /\
       (STRCAT (STRING c s1) s2 = STRING c (STRCAT s1 s2))
  STRCAT_EXPLODE
    |- !s1 s2. STRCAT s1 s2 = FOLDR STRING s2 (EXPLODE s1)
\end{verbatim}}


\paragraph {Strings and lists}

Strings are converted to lists of characters by
{\small\verb+EXPLODE+}. This is inverted by {\small\verb+IMPLODE+}.
%
{\small
\begin{verbatim}
  EXPLODE_EQNS
    |- (EXPLODE "" = []) /\
       (!c s. EXPLODE (STRING c s) = c::EXPLODE s)

  IMPLODE_EQNS
    |- (IMPLODE [] = "") /\
       (!c s. IMPLODE (c::t) = STRING c (IMPLODE t))
\end{verbatim}}

\paragraph {Prefix checking}

That string $s_1$ is a prefix of $s_2$ ({\small\verb+isPREFIX+}) can be
defined by recursion ({\small\verb+isPREFIX_DEF+}). From this, the 
statement {\small\verb+isPREFIX_STRCAT+} can be easily derived.
%
{\small
\begin{verbatim}
  isPREFIX_DEF 
    |- isPREFIX s1 s2 = 
         case (DEST_STRING s1, DEST_STRING s2)
          of (NONE, _) -> T
          || (SOME __, NONE) -> F
          || (SOME(c1,t1),SOME(c2,t2)) -> (c1=c2) /\ isPREFIX t1 t2

  isPREFIX_STRCAT
    |- !s1 s2. isPREFIX s1 s2 = ?s3. s2 = STRCAT s1 s3
\end{verbatim}
}

\subsection{Theories of $n$-bit words}

Anthony's package.

\section{Collections}

Several different notions of a collection of elements are available in
\HOL: sets, multisets, relations, and finite maps.

\subsection{Sets (\theoryimp{pred\_set})}

An extensive development of set theory is available in the theory
{\small\verb+pred_set+}. Sets are represented by functions of the type
$\alpha \to \konst{bool}$, \ie, they are so-called characteristic
functions. One can use the type abbreviation $\alpha\; \konst{set}$
instead of $\alpha \to \konst{bool}$. Sets may be finite or
infinite. All of the elements in a set must have the same type.

\emph{Set membership} is the basic notion that formalized set theory
is based on. In HOL, membership is represented by a the infix constant
{\small\verb+IN+}, defined in theory {\small\verb+bool+} for
convenience.
%
{\small
\begin{verbatim}
    IN_DEF  |- IN = \x f. f x
\end{verbatim}}
%
The {\small\verb+IN+} operator is merely a way of applying the
characteristic function to an item, as the following
trivial consequence of the definition shows:
%
{\small
\begin{verbatim}
  SPECIFICATION  |- !P x. x IN P = P x
\end{verbatim}}
% 
\noindent Two sets are equal if they have the same elements.
%
{\small
\begin{verbatim}
  EXTENSION
    |- !s t. (s = t) = (!x. (x IN s) = (x IN t))
\end{verbatim}}

\paragraph{Empty and universal sets}

The empty set is the characteristic function that is constantly
false. The constant {\small\verb+EMPTY+} denotes the empty set; it may
be written as {\small\verb+{}+}. The universal set {\small\verb+UNIV+}
on a type is the characteristic function that is always true for
elements of that type.
%
{\small
\begin{verbatim}
  EMPTY_DEF   |- {} = (\x. F)
  UNIV_DEF    |- UNIV = (\x. T)
\end{verbatim}}
%
\paragraph{Insertion, union, and intersection}

The insertion ({\small\verb+INSERT+}, written infix) of an element
into a set is defined with a set comprehension. Set comprehension is
discussed in the next subsection. Set union ({\small\verb+UNION+},
written infix) and intersection ({\small\verb+INTER+}, also infix)
are given their usual definitions by set comprehension.
%
{\small
\begin{verbatim}
  INSERT_DEF  |- !x s. x INSERT s = {y | (y = x) \/ y IN s}
  UNION_DEF   |- !s t. s UNION t = {x | x IN s \/ x IN t}
  INTER_DEF   |- !s t. s INTER t = {x | x IN s /\ x IN t}
\end{verbatim}}
%
{\small\verb+UNION+} and {\small\verb+INTER+} are binary
operations. Indexed union and intersection operations, \ie,
$\bigcup_{i \in P}$ and $\bigcap_{i \in P}$ are provided by the
definitions of  {\small\verb+BIGUNION+} and {\small\verb+BIGINTER+}.
{\small
\begin{verbatim}
  BIGUNION    |- !P. BIGUNION P = {x | ?s. s IN P /\ x IN s}
  BIGINTER    |- !P. BIGINTER P = {x | !s. s IN P ==> x IN s}
\end{verbatim}}
%
Both {\small\verb+BIGUNION+} and {\small\verb+BIGINTER+} reduce
a set of sets to a set and thus have the type
$((\alpha\to\konst{bool})\to\konst{bool})\to (\alpha\to\konst{bool})$.

\paragraph{Subsets}

Set inclusion ({\small\verb+SUBSET+}, infix) and proper set inclusion
({\small\verb+PSUBSET+}, infix) are defined as follows:
%
{\small
\begin{verbatim}
  SUBSET_DEF  |- !s t. s SUBSET t = !x. x IN s ==> x IN t
  PSUBSET_DEF |- !s t. s PSUBSET t = s SUBSET t /\ ~(s = t)
\end{verbatim}}

\paragraph{Set difference and complement}

The difference between two sets ({\small\verb+DIFF+}, infix) is
defined by a set comprehension. Based on that, the deletion of a
single element ({\small\verb+DELETE+}, infix) from a set is
straightforward. Since the universe of a type is always available via
{\small\verb+UNIV+}, the complement ({\small\verb+COMPL+}) of a set
may be taken.
{\small
\begin{verbatim}
  DIFF_DEF    |- !s t. s DIFF t = {x | x IN s /\ ~(x IN t)}
  DELETE_DEF  |- !s x. s DELETE x = s DIFF {x}
  COMPL_DEF   |- !P. COMPL P = UNIV DIFF P
\end{verbatim}}
%
\paragraph{Functions on sets}
The image of a function $f :\alpha \to \beta$ on
a set ({\small\verb+IMAGE+}) is defined with a set comprehension.
{\small
\begin{verbatim}
  IMAGE_DEF   |- !f s. IMAGE f s = {f x | x IN s}
\end{verbatim}}
%
Injections, surjections, and bijections between sets are defined
as follows:
%
{\small
\begin{verbatim}
 INJ_DEF
      |- !f s t.
           INJ f s t =
           (!x. x IN s ==> f x IN t) /\
           !x y. x IN s /\ y IN s ==> (f x = f y) ==> (x = y)
 SURJ_DEF
      |- !f s t.
           SURJ f s t =
           (!x. x IN s ==> f x IN t) /\ !x. x IN t ==> ?y. y IN s /\ (f y = x)

 BIJ_DEF |- !f s t. BIJ f s t = INJ f s t /\ SURJ f s t
\end{verbatim}}
%
\paragraph{Finite sets}
The finite sets ({\small\verb+FINITE+}) are defined inductively as those
built from the empty set by a finite number of insertions.
%
{\small
\begin{verbatim}
 FINITE_DEF
      |- !s. FINITE s = !P. P {} /\ (!s. P s ==> !e. P (e INSERT s)) ==> P s
 INFINITE_DEF
      |- !s. INFINITE s = ~FINITE s
\end{verbatim}}
%
A set is infinite iff it is not finite. The finite sets have an
induction theorem :
%
{\small
\begin{verbatim}
 FINITE_INDUCT
   |- !P. P {} /\
         (!s. FINITE s /\ P s ==> !e. ~(e IN s) ==> P (e INSERT s))
         ==>  !s. FINITE s ==> P s
\end{verbatim}}
%
As mentioned, set operations apply to both finite and infinite
sets. However, some operations, such as cardinality
({\small\verb+CARD+}), are only defined for finite sets.  The
cardinality of an infinite set is not specified.
%
{\small
\begin{verbatim}
 CARD_DEF
    |- (CARD {} = 0) /\
       !s. FINITE s ==>
           !x. CARD (x INSERT s) = if x IN s then CARD s else SUC (CARD s)
\end{verbatim}}
%
Since the finite and infinite sets are dealt with uniformly in
 {\small\verb+pred_set+}, properties of operations on finite sets must
explicitly include constraints about finiteness. For example the
following theorem relating cardinality and subsets is only true
for finite sets.
%
{\small
\begin{verbatim}
 CARD_PSUBSET
   |- !s. FINITE s ==> !t. t PSUBSET s ==> CARD t < CARD s
\end{verbatim}}
%
An extensive suite of theorems dealing with finiteness and cardinality
is available in {\small\verb+pred_set+}.

\paragraph{Cross product}
The product of two sets ({\small\verb+CROSS+}, infix) is defined
with a set comprehension.
%
{\small
\begin{verbatim}
  CROSS_DEF   |- !P Q. P CROSS Q = {p | FST p IN P /\ SND p IN Q}
\end{verbatim}}
%
\noindent Cardinality and cross product are related by the following theorem:
{\small
\begin{verbatim}
 CARD_CROSS
   |- !P Q. FINITE P /\ FINITE Q ==> (CARD (P CROSS Q) = CARD P * CARD Q)
\end{verbatim}}
%
\paragraph{Recursive functions on sets}

Recursive functions on sets may be defined by wellfounded
recursion. Usually, the totality of such a function is established by
measuring the cardinality of the (finite) set. However, another
theorem may be used to justify a fold ({\small\verb+ITSET+}) for finite sets.
Provided a function $f:\alpha\to\beta\to\beta$ obeys a condition
known as \emph{left-commutativity}, namely, $f\;x\;(f\;y\;z) =
f\;y\;(f\;x\;z)$, then $f$ can be applied by folding it on the set
in a tail-recursive fashion.
%
{\small
\begin{verbatim}
 ITSET_EMPTY
   |- !f b. ITSET f {} b = b
 COMMUTING_ITSET_INSERT
   |- !f s. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE s ==>
            !x b. ITSET f (x INSERT s) b = ITSET f (s DELETE x) (f x b)
\end{verbatim}}
%
\noindent A recursive version is also available:
{\small
\begin{verbatim}
 COMMUTING_ITSET_RECURSES
   |- !f e s b.
        (!x y z. f x (f y z) = f y (f x z)) /\ FINITE s ==>
        (ITSET f (e INSERT s) b = f e (ITSET f (s DELETE e) b))
\end{verbatim}}
%
For the full derivation, see the sources of {\small\verb+pred_set+}.
The definition of {\small\verb+ITSET+} allows, for example, the
definition of summing the results of a function on a finite set of elements,
from which a recursive characterization and other useful theorems are derived.
%
{\small
\begin{verbatim}
 SUM_IMAGE_DEF
   |- !f s. SIGMA f s = ITSET (\e acc. f e + acc) s 0
 SUM_IMAGE_THM
   |- !f. (SIGMA f {} = 0) /\
          !e s. FINITE s ==> (SIGMA f (e INSERT s) = f e + SIGMA f (s DELETE e))
\end{verbatim}}

\paragraph{Other definitions and theorems}

There are more definitions in {\small\verb+pred_set+}, but they
are not as heavily used as the ones presented here. Similarly, most
theorems in {\small\verb+pred_set+} relate the various common set operations
to each other, but do not express any deep theorems of set theory.

However, one notable theorem is Koenig's Lemma, which states that every
finitely branching infinite tree has an infinite path. There are many
ways to formulate this theorem, depending on how the notion of tree is
formalized. In {\small\verb+pred_set+}, finite branching is defined as
a predicate on a relation.
%
{\small
\begin{verbatim}
 finite_branching_def
  |- !R. finitely_branching R = !x. FINITE {y | R x y}
\end{verbatim}}
%
\noindent From this, the following version of Koenig's Lemma is stated and
proved:
{\small
\begin{verbatim}
 KoenigsLemma
  |- finitely_branching R ==>
       !x. ~FINITE {y | RTC R x y} ==> ?f. (f 0 = x) /\ !n. R (f n) (f (SUC n))
\end{verbatim}}


\subsubsection{Syntax for sets}\index{set theory notation}

The special purpose set-theoretic notations
{\small\verb%{%}$t_1 ;t_2 ; \ldots ; t_n${\small\verb%}%} and
{\small\verb%{%}$t${\small\verb% | %}$p${\small\verb%}%} are recognized 
by the \HOL{} parser and printer when the theory \theoryimp{pred\_set} 
is loaded.

The normal interpretation of 
{\small\verb%{%}$t_1 ;t_2 ; \ldots ; t_n${\small\verb%}%} is the finite set containing just
$t_1,t_2,\ldots, t_n$. This can be modelled by starting with the empty
  set and performing a sequence of insertions. For example, \verb+{1;2;3;4}+ parses to

\begin{hol}{\small
\begin{verbatim}
   1 INSERT (2 INSERT (3 INSERT (4 INSERT EMPTY)))
\end{verbatim}}\end{hol}

\paragraph {Set comprehensions}

The normal interpretation of 
{\small\verb%{%}$t${\small\verb% | %}$p${\small\verb%}%} is
the set of all $t$s such that $p$. In \HOL, such syntax parses to:
%
\texttt{GSPEC(\bs($x_1$,$\ldots$,$x_n$).($t$,$p$))}
%
\noindent where $x_1, \ldots, x_n$ are those free variables that 
occur in both $t$ and $p$.  If there are no such free variables 
then an error results. The order in which the variables are listed in 
the variable structure of the paired abstraction is an unspecified
function of the structure of $t$ (it is approximately left to
right). For example, 
%
\begin{hol}{\small\begin{verbatim}
   {p+q | p < q /\ q < r}
\end{verbatim}}\end{hol}
%
\noindent parses to:
%
\begin{hol}{\small\begin{verbatim}
   GSPEC(\(p,q). ((p+q), (p < q /\ q < r)))
\end{verbatim}}\end{hol}
%
where \ml{GSPEC} is characterized by:
%
\begin{hol}{\small\begin{verbatim}
   GSPECIFICATION  |- !f v. (v IN GSPEC f) = (?x. (v,T) = f x)
\end{verbatim}}\end{hol}

This somewhat cryptic specification can be understood by exercising an
example. The syntax 
%
{\small
\begin{verbatim}
   3 IN {p+q | p < q /\ q < r}
\end{verbatim}}
%
is mapped by the \HOL{} parser to 
{\small
\begin{verbatim}
   3 IN GSPEC(\(p,q). ((p+q), (p < q /\ q < r)))
\end{verbatim}}
%
which, by {\small\verb+GSPECIFICATION+}, is equal to 
{\small
\begin{verbatim}
   ?x. (3,T) = (\(p,q). ((p+q), (p < q /\ q < r))) x
\end{verbatim}}
%
The existentially quantified variable \verb+x+ has a pair type,
so it can be replaced by a pair \verb+(p,q)+ and a
paired-$\beta$-reduction can be performed, yielding
%
{\small
\begin{verbatim}
   ?(p,q). (3,T) = ((p+q), (p < q /\ q < r))
\end{verbatim}}
%
which is equal to the intended meaning of the original
syntax:
%
{\small
\begin{verbatim}
   ?(p,q). (p+q = 3) /\ (p < q /\ q < r)
\end{verbatim}}

\subsection{Multisets (\theoryimp{bag})}\label{multiset}

Multisets, also known as \emph{bags}, are similar to sets, except that
they allow repeat occurrences of an element. Whereas sets are
represented by functions of type $\alpha\to\konst{bool}$, which signal
the presence, or absence, of an element, multisets are represented
by functions of type $\alpha\to\konst{num}$, which give the
multiplicity of each element in the multiset. Multisets may be finite
or infinite.

The type abbreviations $\alpha\;\konst{multiset}$ and
$\alpha\;\konst{bag}$ can be used instead of $\alpha\to\konst{num}$.

\paragraph {Empty multiset}

The empty bag has no elements. Thus, the function implementing it
returns $0$ for every input.
%
{\small
\begin{verbatim}
  EMPTY_BAG  |- EMPTY_BAG = K 0
\end{verbatim}}

\noindent The special syntax {\verb+{||}+} can be used to represent the empty
bag.

\paragraph {Membership}

Much of the theory can be based on the notion of membership in a
bag. There are two notions: does an element occur at least $n$ times
in a bag ({\small\verb+BAG_INN+}); and does an element occur in a bag
at all ({\small\verb+BAG_IN+}).
%
{\small
\begin{verbatim}
  BAG_INN  |- BAG_INN e n b = (b e >= n)
  BAG_IN   |- BAG_IN e b = BAG_INN e 1 b
\end{verbatim}}
%
\noindent Two bags are equal if all elements have the same tally.
%
{\small
\begin{verbatim}
  BAG_EXTENSION
    |- !b1 b2. (b1 = b2) = (!n e. BAG_INN e n b1 = BAG_INN e n b2)
\end{verbatim}}

\paragraph{Sub-multiset}

A sub-bag relationship ({\small\verb+SUB_BAG+}) holds between $b_1$ and
$b_2$ provided that every element in $b_1$ occurs at least as often in
$b_2$. The notion of a proper sub-bag ({\small\verb+PSUB_BAG+}) is
easily defined. 
%
{\small
\begin{verbatim}
  SUB_BAG
    |- SUB_BAG b1 b2 = !x n. BAG_INN x n b1 ==> BAG_INN x n b2
  PSUB_BAG
    |- PSUB_BAG b1 b2 = SUB_BAG b1 b2 /\ ~(b1 = b2)
\end{verbatim}}

\paragraph{Insertion}

Inserting an element into a bag ({\small\verb+BAG_INSERT+}) updates
the tally for that element and leaves the others unchanged.
%
{\small
\begin{verbatim}
  BAG_INSERT
    |- BAG_INSERT e b = (\x. if (x = e) then b e + 1 else b x)
\end{verbatim}}

Explicitly-given multisets are supported by the syntax
{\small\verb%{|%}$t_1 ;t_2 ; \ldots ; t_n${\small\verb%|}%}, where
there may, of course, be repetitions. This is modelled by starting with the empty
multiset and performing a sequence of insertions. For example,
\verb+{|1; 2; 3; 2; 1|}+ parses to

\begin{hol}{\small
\begin{verbatim}
  BAG_INSERT 1 (BAG_INSERT 2 (BAG_INSERT 3 (BAG_INSERT 2 (BAG_INSERT 1 {||}))))
\end{verbatim}}\end{hol}


\paragraph{Union and difference}

The union ({\small\verb+BAG_UNION+}) and difference
({\small\verb+BAG_DIFF+}) operations on bags both reduce to an arithmetic
calculation on their elements. Deleting a single element from a bag
may be expressed by taking the multiset difference with a single-element
multiset; however, there is also a relational presentation
({\small\verb+BAG_DELETE+}). 
%
{\small
\begin{verbatim}
  BAG_UNION
    |- BAG_UNION b c = \x. b x + c x
  BAG_DIFF
    |- BAG_DIFF b1 b2 = \x. b1 x - b2 x
  BAG_DELETE
    |- BAG_DELETE b0 e b = (b0 = BAG_INSERT e b)
\end{verbatim}}

\paragraph {Intersection, merge, and filter}

The intersection of two bags ({\small\verb+BAG_INTER+}) takes the
pointwise minimum. The dual operation, merging
({\small\verb+BAG_MERGE+}), takes the pointwise maximum. A bag can be
`filtered' by a set to return the bag where all the elements not in
the set have been dropped ({\small\verb+BAG_FILTER+}).
%
{\small
\begin{verbatim}
  BAG_INTER
    |- BAG_INTER b1 b2 = (\x. if (b1 x < b2 x) then b1 x else b2 x)
  BAG_MERGE
    |- BAG_MERGE b1 b2 = (\x. if (b1 x < b2 x) then b2 x else b1 x)
  BAG_FILTER_DEF
    |- BAG_FILTER P b = (\e. if P e then b e else 0)
\end{verbatim}}

\paragraph {Sets and Multisets}

Moving between bags and sets is accomplished by the following two
definitions.
%
{\small
\begin{verbatim}
  SET_OF_BAG
    |- SET_OF_BAG b = \x. BAG_IN x b
  BAG_OF_SET
    |- BAG_OF_SET P = \x. if x IN P then 1 else 0
\end{verbatim}}

\paragraph {Image}

Taking the image of a function on a multiset
to get a new multiset seems to be simply a
matter of applying the function to each element of the multiset. However, there
is a problem if $f$ is non-injective and the multiset is infinite. For
example, take the multiset consisting of all the natural numbers and
apply $\lambda x.\; 1$ to each element. The resulting multiset would hold an
infinite number of $1$s. To avoid this requires some constraints: for
example, stipulating that the function be only finitely non-injective,
or that the input multiset be finite. Such conditions would be onerous
in proof; the compromise is to map the multipicity of problematic
elements to $0$.
%
{\small
\begin{verbatim}
  BAG_IMAGE_DEF
    |- BAG_IMAGE f b = 
         \e. let sb = BAG_FILTER (\e0. f e0 = e) b
             in
               if FINITE_BAG sb then BAG_CARD sb else 0
\end{verbatim}}


\paragraph {Finite multisets}

The finite multisets ({\small\verb+FINITE_BAG+}) are defined inductively as those
built from the empty bag by a finite number of insertions.
%
{\small
\begin{verbatim}
  FINITE_BAG
    |- FINITE_BAG b =
         !P. P EMPTY_BAG /\ 
             (!b. P b ==> (!e. P (BAG_INSERT e b))) ==> P b
\end{verbatim}}
%
\noindent The finite multisets have an induction theorem, and also a strong
induction theorem.
%
{\small
\begin{verbatim}
  FINITE_BAG_INDUCT
    |- !P. P {||} /\
           (!b. P b ==> (!e. P (BAG_INSERT e b))) 
           ==> (!b. FINITE_BAG b ==> P b)

  STRONG_FINITE_BAG_INDUCT
    |- !P. P {||} /\ 
           (!b. FINITE_BAG b /\ P b ==> !e. P (BAG_INSERT e b)) 
           ==> (!b. FINITE_BAG b ==> P b)
\end{verbatim}}
%
The cardinality ({\small\verb+BAG_CARD+}) of a multiset counts the
total number of occurrences. It is only specified for finite multisets.
%
{\small
\begin{verbatim}
 BAG_CARD_THM 
   |- (BAG_CARD {||} = 0) /\
      (!b. FINITE_BAG b ==> !e. BAG_CARD (BAG_INSERT e b) = BAG_CARD b + 1)
\end{verbatim}}

\paragraph{Recursive functions on multisets}

Recursive functions on multiset may be defined by wellfounded
recursion. Usually, the totality of such a function is established by
measuring the cardinality of the (finite) multiset. However, 
a fold ({\small\verb+ITBAG+}) for finite sets is provided.
Provided a function $f:\alpha\to\beta\to\beta$ obeys a condition
known as \emph{left-commutativity}, namely, $f\;x\;(f\;y\;z) =
f\;y\;(f\;x\;z)$, then $f$ can be applied by folding it on the multiset
in a tail-recursive fashion.
%
{\small
\begin{verbatim}
 ITBAG_EMPTY
   |- !f acc. ITSET f {||} acc = acc
 COMMUTING_ITBAG_INSERT
   |- !f b. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE_BAG b ==>
            !x a. ITBAG f (BAG_INSERT x b) a = ITBAG f b (f x a)
\end{verbatim}}
%
\noindent A recursive version is also available:
{\small
\begin{verbatim}
 COMMUTING_ITBAG_RECURSES
   |- !f e b a. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE_BAG b ==>
                (ITBAG f (BAG_INSERT e b) a = f e (ITBAG f b a))
\end{verbatim}}

\subsection{Relations (\theoryimp{relation})}\label{relation}

Mathematical relations can be represented in \HOL{} by the type
$\alpha \to\beta\to\konst{bool}$. (In most applications, the type of a
relation is an instance of $\alpha \to\alpha\to\konst{bool}$, but the
extra generality doesn't hurt.) The theory \theoryimp{relation}
provides definitions of basic properties and operations on relations,
defines various kinds of orders and closures, defines wellfoundedness
and proves the wellfounded recursion theorem, and develops some
basic results used in Term Rewriting.

\paragraph {Basic properties}

The following basic properties of relations are defined.
%
\begin{hol}
{\small
\begin{verbatim}
  transitive_def
    |- transitive R = !x y z. R x y /\ R y z ==> R x z
  reflexive_def
    |- reflexive R = (!x. R x x)
  irreflexive_def
    |- irreflexive R = (!x. ~R x x)
  symmetric_def
    |- symmetric R = (!x y. R x y = R y x)
  antisymmetric_def
    |- antisymmetric R = (!x y. R x y /\ R y x ==> (x = y))
  equivalence_def
    |- equivalence R = reflexive R /\ symmetric R /\ transitive R
  trichotomous
    |- trichotomous R = !a b. R a b \/ R b a \/ (a = b)
  total_def
    |- total R = (!x y. R x y \/ R y x)
\end{verbatim}}
\end{hol}

\paragraph{Basic operations}

The following basic operations on relations are defined: the empty
relation ({\small\verb+EMPTY_REL+}), relation composition
({\small\verb+O+, infix}), inversion ({\small\verb+inv+}), 
domain ({\small\verb+RDOM+}), and range ({\small\verb+RRANGE+}).
%
\begin{hol}
{\small
\begin{verbatim}
  EMPTY_REL_DEF  
    |- !x y. EMPTY_REL x y = F
  O_DEF
    |- $O R1 R2 x z = ?y. R1 x y /\ R2 y z
  inv_DEF
    |- inv R x y = R y x
  RDOM_DEF
    |- RDOM R x = ?y. R x y
  RRANGE
    |- RRANGE R y = ?x. R x y
\end{verbatim}}
\end{hol}

Set  operations lifted to work on relations include subset
({\small\verb+RSUBSET+}, infix), 
union ({\small\verb+RUNION+}, infix),
intersection ({\small\verb+RINTER+}, infix), 
complement ({\small\verb+RCOMPL+}), and universe ({\small\verb+RUNIV+}).
%
\begin{hol}
{\small
\begin{verbatim}
  RSUBSET
    |- $RSUBSET R1 R2 = !x y. R1 x y ==> R2 x y
  RUNION
    |- $RUNION R1 R2 x y = R1 x y \/ R2 x y
  RINTER
    |- $RINTER R1 R2 x y = R1 x y /\ R2 x y
  RCOMPL
    |- RCOMPL R x y = ~R x y
  RUNIV
    |- RUNIV x y = T
\end{verbatim}}
\end{hol}

\paragraph {Orders}

A sequence of definitions capturing various notions of order are made
in \theoryimp{relation}.
%
\begin{hol}
{\small
\begin{verbatim}
  PreOrder
    |- PreOrder R = reflexive R /\ transitive R
  Order
    |- Order Z = antisymmetric Z /\ transitive Z
  WeakOrder
    |- WeakOrder Z = reflexive Z /\ antisymmetric Z /\ transitive Z
  StrongOrder
    |- StrongOrder Z = irreflexive Z /\ antisymmetric Z /\ transitive Z
  LinearOrder
    |- LinearOrder R = Order R /\ trichotomous R
  WeakLinearOrder
    |- WeakLinearOrder R = WeakOrder R /\ trichotomous R
  StrongLinearOrder
    |- StrongLinearOrder R = StrongOrder R /\ trichotomous R
\end{verbatim}}
\end{hol}

\paragraph {Closures}

The transitive closure ({\small\verb+TC+}) of a relation $R : \alpha
\to\alpha\to\konst{bool}$ is defined inductively, as the least
relation including $R$ and closed under transitivity. Similarly, the
reflexive-transitive closure ({\small\verb+RTC+}) is defined to be the least
relation closed under transitivity and reflexivity.
%
\begin{hol}
{\small
\begin{verbatim}
  TC_DEF 
    |- TC R a b =
         !P. (!x y. R x y ==> P x y) /\
             (!x y z. P x y /\ P y z ==> P x z) ==> P a b
  RTC_DEF 
    |- RTC R a b =
         !P. (!x. P x x) /\
             (!x y z. R x y /\ P y z ==> P x z) ==> P a b
\end{verbatim}}
\end{hol}

From these definitions, one can recover the initial rules.
%
\begin{hol}
{\small
\begin{verbatim}
  TC_RULES
    |- !R. (!x y. R x y ==> TC R x y) /\
           (!x y z. TC R x y /\ TC R y z ==> TC R x z)
  RTC_RULES
    |- !R. (!x. RTC R x x) /\ 
           (!x y z. R x y /\ RTC R y z ==> RTC R x z)
  RTC_RULES_RIGHT1
    |- !R. (!x. RTC R x x) /\ 
           (!x y z. RTC R x y /\ R y z ==> RTC R x z)
\end{verbatim}}
\end{hol}
%
Notice that {\small\verb+RTC_RULES+}, in keeping with the definition
of {\small\verb+RTC+}, extends a sequence of \verb+R+-steps leading
from \verb+y+ to \verb+z+ on the left with a single \verb+R+-step from
\verb+x+ to \verb+y+ to construct \verb+RTC x z+. The theorem
{\small\verb+RTC_RULES_RIGHT1+} makes the extension on the right.
Similar alternative theorems are proved for case analysis and induction.

For example, {\small\verb+TC_CASES1+} and {\small\verb+TC_CASES2+} in the
following decompose {\small\verb+RTC R x z+} to either 
{\small\verb+R x y+} followed by {\small\verb+RTC R y z+}
({\small\verb+TC_CASES1+})
or 
{\small\verb+RTC R x y+} followed by {\small\verb+R y z+}
({\small\verb+TC_CASES2+}).

%
\begin{hol}
{\small
\begin{verbatim}
  TC_CASES1
    |- !R x z. TC R x z ==> R x z \/ ?y. R x y /\ TC R y z
  TC_CASES2
    |- !R x z. TC R x z ==> R x z \/ ?y. TC R x y /\ R y z

  RTC_CASES1
    |- !R x y. RTC R x y = (x = y) \/ ?u. R x u /\ RTC R u y
  RTC_CASES2
    |- !R x y. RTC R x y = (x = y) \/ ?u. RTC R x u /\ R u y
  RTC_CASES_RTC_TWICE
    |- !R x y. RTC R x y = ?u. RTC R x u /\ RTC R u y
\end{verbatim}}
\end{hol}

As well as the basic induction theorems for {\small\verb+TC+} and 
{\small\verb+RTC+}, there are so-called \emph{strong} induction
theorems, which have stronger induction hypotheses.
%
\begin{hol}
{\small
\begin{verbatim}
  TC_INDUCT
    |- !R P. (!x y. R x y ==> P x y) /\
             (!x y z. P x y /\ P y z ==> P x z) 
             ==> !u v. TC R u v ==> P u v
  RTC_INDUCT
    |- ! R P. (!x. P x x) /\ 
              (!x y z. R x y /\ P y z ==> P x z) ==>
              (!x y. RTC R x y ==> P x y)
  TC_STRONG_INDUCT
    |- !R P. (!x y. R x y ==> P x y) /\
             (!x y z. P x y /\ P y z /\ TC R x y /\ TC R y z ==> P x z) ==>
             (!u v. TC R u v ==> P u v)
  RTC_STRONG_INDUCT
    |- !R P. (!x. P x x) /\ 
             (!x y z. R x y /\ RTC R y z /\ P y z ==> P x z) ==>
             (!x y. RTC R x y ==> P x y)
\end{verbatim}}
\end{hol}
Variants of these induction theorems are also available which break
apart the closure from the left or right, as for the case analysis theorems.

\medskip

The reflexive ({\small\verb+RC+}) and symmetric closures
({\small\verb+RC+}) are straightforward to define. The equivalence
closure ({\small\verb+EQC+}) is the symmetric then transitive then
reflexive closure of $R$.
%
\begin{hol}
{\small
\begin{verbatim}
  RC_DEF   |- RC R x y = (x = y) \/ R x y
  SC_DEF   |- SC R x y = R x y \/ R y x
  EQC_DEF  |- EQC R = RC (TC (SC R))
\end{verbatim}}
\end{hol}

\paragraph {Wellfounded relations}

A relation $R$ is wellfounded ({\small\verb+WF+}) if every non-empty set
has an $R$-minimal element. Wellfoundedness is used to justify the
principle of wellfounded induction ({\small\verb+WF_INDUCTION_THM+}).
%
\begin{hol}
{\small
\begin{verbatim}
  WF_DEF 
    |- !R. WF R = !B. (?w. B w) ==> ?min. B min /\ !b. R b min ==> ~B b
  WF_INDUCTION_THM
    |- !R WF R ==> !P. (!x. (!y. R y x ==> P y) ==> P x) ==> !x. P x
\end{verbatim}}
\end{hol}

The \emph{wellfounded part} ({\small\verb+WFP+}) of a relation can be
inductively defined, from which its rules, case-analysis theorem and
induction theorems may be derived.
%
\begin{hol}
{\small
\begin{verbatim}
  WFP_DEF
    |- WFP R a = !P. (!x. (!y. R y x ==> P y) ==> P x) ==> P a
  WFP_RULES
    |- !R x. (!y. R y x ==> WFP R y) ==> WFP R x
  WFP_CASES
    |- !R x. WFP R x = !y. R y x ==> WFP R y
  WFP_INDUCT
    |- !R P. (!x. (!y. R y x ==> P y) ==> P x) 
             ==> !x. WFP R x ==> P x
  WFP_STRONG_INDUCT
    |- !R. (!x. WFP R x /\ (!y. R y x ==> P y) ==> P x) 
           ==> !x. WFP R x ==> P x
\end{verbatim}}
\end{hol}

Wellfoundedness can also be used to justify a general recursion
theorem. Intuitively, a collection of recursion equations can be
admitted into the \HOL{} logic with no loss of consistency provided
that every possible sequence of recursive calls is finite. Wellfounded
relations are used to capture this notion: if there is a wellfounded
relation $R$ on the domain of the desired function such that every
sequence of recursive calls is $R$-decreasing, then the recursion
equations specify a unique total function and the equations can be
admitted into the logic.

The recursion theorems {\small\verb+WFREC_COROLLARY+} and
{\small\verb+WF_RECURSION_THM+} use the notion of a function
restriction ({\small\verb+RESTRICT+}) in order to force the recursive
function to be applied to $R$-smaller arguments in recursive calls..
%
\begin{hol}
{\small
\begin{verbatim}
  RESTRICT_DEF 
    |- !f R x. RESTRICT f R x = \y. if R y x then f y else ARB

  WFREC_COROLLARY
    |- !M R f. (f = WFREC R M) ==> WF R ==> !x. f x = M (RESTRICT f R x) x

  WF_RECURSION_THM 
    |- !R. WF R ==> !M. ?!f. !x. f x = M (RESTRICT f R x) x
\end{verbatim}}
\end{hol}

\noindent The theorems {\small\verb+WF_INDUCTION_THM+} and
{\small\verb+WFREC_COROLLARY+} are used to automate recursive
definitions; see Section \ref{TFL}. A few basic operators for
wellfounded relations are also defined, along with theorems stating
that they propagate wellfoundedness.

\begin{hol}
\begin{verbatim}
   inv_image_def  |- !R f. inv_image R f = \x y. R (f x) (f y)

   WF_inv_image   |- !R f. WF R ==> WF (inv_image R f)
   WF_SUBSET      |- !R P. WF R /\ (!x y. P x y ==> R x y) ==> WF P
   WF_TC          |- !R. WF R ==> WF (TC R)
   WF_Empty       |- WF EMPTY_REL
\end{verbatim}
\end{hol}

\paragraph {Term Rewriting}

A few basic definitions from Term Rewriting theory 
(the diamond property (\verb+diamond+), the Church-Rosser
property ({\small\verb+CR+} and {\small\verb+WCR+}), and Strong
Normalization ({\small\verb+SN+})) appear
in \theoryimp{relation}. 
%
\begin{hol}
{\small
\begin{verbatim}
  diamond_def
    |- diamond R = !x y z. R x y /\ R x z ==> ?u. R y u /\ R z u
  CR_def
    |- CR R = diamond (RTC R)
  WCR_def
    |- WCR R = !x y z. R x y /\ R x z ==> ?u. RTC R y u /\ RTC R z u
  SN_def
    |- SN R = WF (inv R)
\end{verbatim}}
\end{hol}
%
\noindent From those, Newman's Lemma is proved.
%
\begin{hol}
{\small
\begin{verbatim}
  Newmans_lemma  |- !R. WCR R /\ SN R ==> CR R
\end{verbatim}}
\end{hol}

\subsection{Finite maps (\theoryimp{finite\_map})}\label{finite_map}

The theory \theoryimp{finite\_map} formalizes a type
$(\alpha,\beta)$\verb+fmap+ of finite functions. These notionally have
type $\alpha\to\beta$, but additionally have only finitely many
elements in their domain. The representing type is $\alpha\to\beta +
\konst{one}$, where only a finite number of the $\alpha$ map to a
$\beta$ and the rest map to \verb+one+. The syntax
$\alpha$\verb+|->+$\beta$ is recognized by the parser as an
alternative to $(\alpha,\beta)$\verb+fmap+.

\paragraph {Basic notions}

The empty map ({\small\verb+FEMPTY+}), the domain of a map
({\small\verb+FDOM+}), the updating of a map
({\small\verb+FUPDATE+}), and the application of a map to an argument
({\small\verb+FAPPLY+}) are the main notions in the theory. 
%
{\small
\begin{verbatim}
  FEMPTY  : 'a |-> 'b
  FDOM    : ('a |-> 'b) -> 'a set
  FUPDATE : ('a |-> 'b) -> 'a # 'b -> ('a |-> 'b)
  FAPPLY  : ('a |-> 'b) -> 'a -> 'b
\end{verbatim}}

The \HOL{} parser and printer will treat the syntax \verb+f ' x+ as
the application of finite map \verb+f+ to argument \verb+x+, ie, as 
{\small\verb+FAPPLY f x+}. Also, the notation \verb#f |+ (x,y)#
represents the updating of finite map \verb+f+ by the pair
\verb+(x,y)+, \ie, as {\small\verb+FUPDATE f (x,y)+}.

The basic constants have obscure definitions from which the following
are a few of the more perspicious properties that are derived:
%
{\small
\begin{verbatim}
  FDOM_FUPDATE
    |- !f a b. FDOM (f |+ (a,b)) = (a INSERT (FDOM f))
  FDOM_FINITE
    |- !fm. FINITE (FDOM fm)

  FAPPLY_FUPDATE_THM
    |- !f a b x. (f |+ (a,b)) ' x = if x=a then b else f'x

  lookup_DEF
    |- FLOOKUP f x = (if x IN FDOM f then SOME (f'x) else NONE)
  FRANGE_DEF
    |- FRANGE f = {y | ?x. x IN FDOM f /\ (f'x = y)}
  fmap_EQ_THM
    |- !f g. (FDOM f = FDOM g) /\ 
             (!x. x IN FDOM f ==> (FAPPLY f x = FAPPLY g x)) = (f = g)
\end{verbatim}}

There is support for iterated updates ({\small\verb+FUPDATE_LIST+},
infix) to a map:
%
{\small
\begin{verbatim}
  FUPDATE_LIST  |- $FUPDATE_LIST = FOLDL FUPDATE
  FUPDATE_LIST_THM
    |- !f. (f FUPDATE_LIST [] = f) /\
           (!h t. f FUPDATE_LIST (h::t) = (FUPDATE f h) FUPDATE_LIST t)
\end{verbatim}}
%
\noindent Thus {\small\verb+fm FUPDATE_LIST (k1,v1) (k2,v2)+} is equal
to {\small\verb+(fm |- (k1,v1)) |- (k2,v2)+}.

\paragraph {Induction}

There is an induction theorem for finite maps.
%
{\small
\begin{verbatim}
  fmap_INDUCT
    |- !P. P FEMPTY /\
           (!f. P f ==> !x y. ~(x IN FDOM f) ==> P (FUPDATE f (x,y))) 
          ==> !f. P f
\end{verbatim}}

\paragraph{Cardinality}

The cardinality of a finite map is the cardinality of its domain.
%
{\small
\begin{verbatim}
  FCARD_DEF  |- FCARD fm = CARD (FDOM fm)
  FCARD_FUPDATE
    |- !fm a b. FCARD (FUPDATE fm (a, b)) = 
                  if a IN FDOM fm then FCARD fm else 1 + FCARD fm
\end{verbatim}}

\paragraph {Sub-maps}

The notion of a finite map being a submap of another
({\small\verb+SUBMAP+}, infix) is defined. 
{\small
\begin{verbatim}
  SUBMAP_DEF
    |- !f g. (f SUBMAP g) =
               !x. x IN FDOM f ==> x IN FDOM g /\ (FAPPLY f x = FAPPLY g x)
\end{verbatim}}

\paragraph {Domain and range restriction}

A finite map may have its domain restricted ({\small\verb+DRESTRICT+})
by intersecting with by a set. There is also the notion of domain
subtraction (\verb+\\+, infix).
{\small
\begin{verbatim}
  DRESTRICT_DEF
    |- !f r. (FDOM (DRESTRICT f r) = FDOM f INTER r) /\
             (!x. DRESTRICT f r ' x = 
                    (if x IN FDOM f INTER r then f ' x else FEMPTY ' x)
  DRESTRICT_FUPDATE
    |- !f r x y.
          DRESTRICT (FUPDATE f (x,y)) r =
            if x IN r then FUPDATE (DRESTRICT f r) (x,y) else DRESTRICT f r

  RRESTRICT_DEF
    |- !f r.
         (FDOM (RRESTRICT f r) = {x | x IN FDOM f /\ f ' x IN r}) /\
         !x.
           RRESTRICT f r ' x =
           (if x IN FDOM f /\ f ' x IN r then f ' x else FEMPTY ' x)
  RRESTRICT_FEMPTY
    |- !r. RRESTRICT FEMPTY r = FEMPTY : thm
  RRESTRICT_FUPDATE
    |- !f r x y.
         RRESTRICT (f |+ (x,y)) r =
         (if y IN r then RRESTRICT f r |+ (x,y)
                    else RRESTRICT (DRESTRICT f (COMPL {x})) r)

  fmap_domsub
    |- fm \\ k = DRESTRICT fm (COMPL {k})
   DOMSUB_FUPDATE_THM
    |- !fm k1 k2 v. (fm |+ (k1,v)) \\ k2 = 
                     if (k1 = k2) then (fm \\ k2) else (fm \\ k2) |+ (k1, v)
\end{verbatim}}

\paragraph {Union}

{\small
\begin{verbatim}
  FUNION_DEF
    |- !f g.
         (FDOM (FUNION f g) = FDOM f UNION FDOM g) /\
         !x. FUNION f g ' x = (if x IN FDOM f then f'x else g'x)

  FUNION_FEMPTY_1  |- !g. FUNION FEMPTY g = g
  FUNION_FEMPTY_2  |- !f. FUNION f FEMPTY = f
  FUNION_FUPDATE_1 
    |- !f g x y. FUNION (f |+ (x,y)) g = (FUNION f g) |+ (x,y)
  FUNION_FUPDATE_2
    |- !f g x y.
        FUNION f (FUPDATE g (x,y)) =
          if x IN FDOM f then FUNION f g else (FUNION f g) |+ (x,y)
\end{verbatim}}

\paragraph {Composition and lifting}
Composition of two finite maps (\verb+f_o_f+, infix). Composition of a
finite map with an ordinary function (\verb+o_f+, infix).

{\small
\begin{verbatim}
  f_o_f_DEF
    |- !f g.
         (FDOM (f f_o_f g) = (FDOM g) INTER {x | g ' x IN FDOM f}) /\
         !x. x IN FDOM (f f_o_f g) ==> ((f f_o_f g) ' x = f ' (g ' x))
  o_f_DEF
    |- !f g.
         (FDOM (f o_f g) = FDOM g) /\
         !x. x IN FDOM (f o_f g) ==> ((f o_f g) ' x = f (g ' x))
  f_o_DEF
    |- ((f:('b,'c)fmap) f_o (g:'a->'b)) = f f_o_f (FUN_FMAP g { x | g x IN FDOM f})
  FUN_FMAP_DEF
    |- !f P.
         FINITE P ==>
         (FDOM (FUN_FMAP f P) = P) /\
         !x. x IN P ==> (FUN_FMAP f P ' x = f x)
\end{verbatim}}

\section{Further Mathematics}

\subsection{Divisibility and Greatest Common Divisor}

\subsection{Polynomials}

A separate development that depends only on {\small\verb+realTheory+} is
a theory of polynomials, found in {\small\verb+polyTheory+}. A standard
collection of operations on polynomials, and theorems about them, are
also derived.

\subsection{Probability}
\subsection{Temporal Logic}
\subsection{$\mu$-Calculus}
\subsection{Computation Tree Logic (CTL)}
\subsection{The State-transformer monad}
\subsection{While-loops}
\subsection{List permutations and sorting}
\subsection{Partial orders}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "description"
%%% End:
