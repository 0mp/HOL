\chapter{Theories}\label{HOLtheories}

% LaTeX macros in HOL manuals
%
% \holtxt{..}     for typewriter text that is HOL types or terms.  To
%                 produce backslashes, for /\, \/ and \x. x + 1, use \bs
% \ml{..}         for typewriter text that is ML input, including the
%                 names of HOL API functions, such as mk_const
% \theoryimp{..}  for names of HOL theories.

% Inside \begin{verbatim}, indent contents three spaces, unless
% displaying a HOL session in a box (boxed or session environments).
% In that case, put the session flush against the left margin

% Rather than wrapping begin{verbatim} blocks in \small, which does
% terrible things to line-spacing in the vicinity, use the hol
% environment, thus \begin{hol}\begin{verbatim}...\end{verbatim}\end{hol}

\setcounter{sessioncount}{0}


\newcommand{\konst}[1]{\ensuremath{\mbox{\small{\textbf{\sf{#1}}}}}}
\newcommand{\nil}{\mathbf{[} \;\mathbf{]}}
\newcommand{\cons}[2]{{#1}\mathbf{:}\mathbf{:}{#2}}

\index{theories, in HOL logic@theories, in \HOL{} logic!hierarchies
of} The \HOL{} system provides a collection of theories to base
verification tools or further theory development on.  In the rest of
this section, these theories are briefly described.  It is,
unfortunately, not possible to provide a complete list of all the
definitions and theorems in each theory. Therefore, the sections that
follow provide only an overview of the contents of each theory.  For a
complete list of all the axioms, definitions and theorems in \HOL, see
\REFERENCE.


\section{The theory {\tt min}}\label{minTheory}

The starting theory of \HOL{} is the theory \ml{min}.
\index{min, the HOL theory@\ml{min}, the \HOL{} theory|(}
In this theory, the type constant {\small\verb+bool+} of booleans,
the binary type operator $(\alpha,\beta)${\small\verb+fun+} of functions, and the type
constant {\small\verb+ind+} of individuals are declared. Building on
these types, three primitive constants
\index{constants, in HOL logic@constants, in \HOL{} logic!primitive logical}
\index{primitive constants, of HOL logic@primitive constants, of \HOL{} logic}
are declared: equality, implication, and a choice operator:
\index{ equality, in HOL logic@\ml{=} (equality, in \HOL{} logic)}
\index{equality, in HOL logic@equality, in \HOL{} logic}
\begin{description}
\item [Equality] Equality ({\small\verb+= : 'a -> 'a -> bool+}) is an
  infix operator.
\index{equality, in HOL logic@equality, in \HOL{} logic}
\item [Implication] Implication
  ({\small\verb+==> : bool -> bool -> bool+}) is the
  \emph{material implication} and is an infix operator that is
  right-associative, \ie, \verb+x ==> y ==> z+ parses to the same term
  as \verb+x ==> (y ==> z)+.
\index{implication, in HOL logic@implication, in \HOL{} logic}
\item [Choice] Equality
and implication are standard predicate calculus notions, but choice is
more exotic: if $t$ is a term having type $\sigma${\small\verb+->bool+},
then {\small\verb+@x.+}$t${\small\verb+ x+} (or, equivalently,
{\small\verb+$@+}$t$) denotes \emph{some} member of the set whose
characteristic\index{characteristic predicate, of type definitions}
 function is $t$. If the set is empty, then
{\small\verb+@x.+}$t${\small\verb+ x+} denotes an arbitrary member of the
set denoted by $\sigma$. The constant {\small\verb+@+} is a higher order
version of Hilbert's
\index{Hilbert, D.}
\index{epsilon operator}
 $\hilbert$-operator; it is related to the constant
$\iota$ in Church's formulation of higher order logic. For more details,
see Church's
\index{Church, A.}
original paper \cite{Church}, Leisenring's
\index{Leisenring, A.}
book on Hilbert's $\hilbert$-symbol \cite{Leisenring}, or Andrews'
textbook on type theory \cite{Andrews}.
\end{description}

\medskip

\noindent No theorems or axioms are placed in theory \theoryimp{min}.
The primitive rules of inference of \HOL{} depend on the presence of
\theoryimp{min}.


\section{Basic Theories}

The most basic theories in HOL provide support for a standard
collection of types. The theory \theoryimp{bool} defines the basis of
the \HOL{} logic, including the boolean operations and
quantifiers. On this platform, quite a bit of theorem-proving
infrastructure can already be built. Further basic types are developed
in the theory of pairs (\theoryimp{prod}), disjoint sums
(\theoryimp{sum}), the one-element type (\theoryimp{one}), and the
(\theoryimp{option}) type.


\subsection{The theory \theoryimp{bool}}\label{boolfull}

\index{axioms!primitive, of HOL logic@primitive, of \HOL{} logic|(}
%
At start-up, the initial theory for users of the \HOL{} system is
called \ml{bool}\index{HOL@\HOL{}}, which is constructed when the
\HOL{} system is built. The theory \theoryimp{bool} is an extension of
the combination of the ``conceptual'' theories \theory{LOG} and
\theory{INIT}, described in Chapter~\ref{semantics}.  Thus it contains
the four axioms
%
\index{axioms!in bool theory@in \ml{bool} theory}
%
for higher order logic. These axioms, together with the rules of
inference described in Section~\ref{rules}, constitute the core of the
\HOL{} logic.  Because of the way the \HOL{} system evolved from \LCF,
%
\index{LCF@\LCF}
%
\footnote{To simplify the porting of the LCF theorem-proving tools to
  the HOL system, the HOL logic was made as like PP$\lambda$ (the
  logic built-in to LCF) as possible.} the particular
axiomatization
%
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
%
of higher order logic it uses differs from the classical
axiomatization due to Church\index{Church, A.}  \cite{Church}.  The
biggest difference is that in Church's formulation type
variables
%
\index{type variables, in HOL logic@type variables, in \HOL{} logic!differences from classical}
%
are in the meta-language, whereas in the \HOL{} logic they are part of
the object language.

The logical constants
%
\index{logical constants, in HOL logic@logical constants, in \HOL{} logic}
%
\holtxt{T}~(truth),
%
\index{truth values, in HOL logic@truth values, in \HOL{} logic!constants for}
%
\holtxt{F}~(falsity),
\holtxt{\~{}}~(negation),
%
\index{ negation, in HOL logic@\holtxt{\~{}} (negation, in \HOL{} logic)}
%
\holtxt{/\bs} (conjunction),
%
\index{ conjunction, in HOL logic@\holtxt{/\bs} (conjunction, in \HOL{} logic)}
%
\holtxt{\bs/} (disjunction),
%
\index{ disjunction, in HOL logic@\holtxt{\bs/} (disjunction, in \HOL{} logic)}
%
\holtxt{!} (universal quantification),
%
\index{ universal quantifier, in HOL logic@\holtxt{"!} (universal quantifier, in \HOL{} logic)}
%
\holtxt{?} (existential quantification),
%
\index{ existential quantifier, in HOL logic@\holtxt{?} (existential quantifier, in \HOL{} logic)}
%
and \holtxt{?!} (unique existence quantifier)
%
\index{ exists unique, in HOL logic@\holtxt{?"!} (exists unique, in \HOL{} logic)}
%
can all be defined in terms of equality,
%
\index{equality, in HOL logic@equality, in \HOL{} logic}
%
implication and choice.  The definitions listed below are fairly
standard; each one is preceded by its \ML{} name.  Later definitions
sometimes build on earlier ones.

\begin{hol}
\index{truth values, in HOL logic@truth values, in \HOL{} logic!definition of}
\index{T@\holtxt{T}!definitional axiom for}
\index{disjunction, in HOL logic@disjunction, in \HOL{} logic!definitional axiom for}
\index{conjunction, in HOL logic@conjunction, in \HOL{} logic!definitional axiom for}
\index{iff, in HOL logic@iff, in \HOL{} logic!definitional axiom for}
\index{negation, in HOL logic@negation, in \HOL{} logic!definitional axiom for}
\index{ exists unique, in HOL logic@\holtxt{?"!} (exists unique, in \HOL{} logic)}
\index{F@\holtxt{F}!axiom for}
\index{F@\holtxt{F}!definitional axiom for}
\index{conjunction, in HOL logic@conjunction, in \HOL{} logic!definitional axiom for}
\index{disjunction, in HOL logic@disjunction, in \HOL{} logic!definitional axiom for}
\index{equality, in HOL logic@equality, in \HOL{} logic!primitive axiom for}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL{} logic!definitional axiom for}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL{} logic!definitional axiom for}
\index{exists unique, in HOL logic@exists unique, in \HOL{} logic!definitional axiom for}
\begin{verbatim}
   T_DEF              |- T  = ((\x:bool. x) = (\x. x))

   FORALL_DEF         |- !  = \P:'a->bool. P = (\x. T)

   EXISTS_DEF         |- ?  = \P:'a->bool. P($@ P)

   AND_DEF            |- /\ = \t1 t2. !t. (t1 ==> t2 ==> t) ==> t

   OR_DEF             |- \/ = \t1 t2. !t. (t1 ==> t) ==> (t2 ==> t) ==> t

   F_DEF              |- F  = !t. t

   NOT_DEF            |- ~  = (\t. t ==> F)

   EXISTS_UNIQUE_DEF  |- ?! = (\P. $? P /\ (!x y. P x /\ P y ==> (x = y)))
\end{verbatim}
\end{hol}


There are four
%
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL{} logic!in four primitive axioms}
%
axioms in the theory \theoryimp{bool};
%
\index{bool, the HOL theory@\ml{bool}, the \HOL{} theory}
%
the first three are the following:

\begin{hol}
\index{BOOL_CASES_AX@\ml{BOOL\_CASES\_AX}}
\index{ETA_AX@\ml{ETA\_AX}}
\index{SELECT_AX@\ml{SELECT\_AX}}
\index{implication, in HOL logic@implication, in \HOL{} logic!primitive axiom for}
\index{ choice function, in HOL logic@\holtxt{"@} (choice function, in \HOL{} logic)}
\index{choice axiom}
\index{choice operator, in HOL logic@choice operator, in \HOL{} logic!primitive axiom for}
\begin{verbatim}
   BOOL_CASES_AX   |- !t. (t = T) \/ (t = F)

   ETA_AX          |- !t. (\x. t x) = t

   SELECT_AX       |- !P:'a->bool x. P x ==> P($@ P)
\end{verbatim}
\end{hol}

\noindent
The fourth and last axiom of the \HOL{} logic is the Axiom of
Infinity\index{axiom of infinity}. Its statement is phrased in terms of
the function properties {\small\verb+ONE_ONE+} and {\small\verb+ONTO+}. The
definitions are:

\begin{hol}
\index{ONE_ONE_DEF@\ml{ONE\_ONE\_DEF}}
\index{ONTO_DEF@\ml{ONTO\_DEF}}
\index{one-to-one predicate, in HOL logic@one-to-one predicate, in \HOL{} logic!definitional axiom for}
\index{onto predicate, in HOL logic@onto predicate, in \HOL{} logic!definitional axiom for}
\begin{verbatim}
   ONE_ONE_DEF |- ONE_ONE f = (!x1 x2. (f x1 = f x2) ==> (x1 = x2))

   ONTO_DEF    |- ONTO f    = (!y. ?x. y = f x)
\end{verbatim}
\end{hol}

\noindent The Axiom of Infinity\index{axioms!in bool theory@in \ml{bool} theory} is
%
\begin{hol}
\index{INFINITY_AX@\ml{INFINITY\_AX}}
\index{axiom of infinity}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL{} logic!in infinity axiom}
\begin{verbatim}
  INFINITY_AX  |- ?f:ind->ind. ONE_ONE f /\ ~(ONTO f)
\end{verbatim}
\end{hol}
%
\noindent
This asserts that there exists a one-to-one map from \holtxt{ind} to
itself that is not onto. This implies that the type \holtxt{ind}
denotes an infinite set.
%
\index{axioms!primitive, of HOL logic@primitive, of \HOL{} logic|)}

The three other axioms of the theory \theoryimp{bool}, the rules of
inference in Section~\ref{rules} and the Axiom of Infinity are,
together, sufficient for developing all of standard mathematics. Thus,
in principle, the user of the \HOL{} system should never need to make a
non-definitional
%
\index{axioms!dispensibility of adding}
\index{definitional theories}
%
theory. In practice, it is often very tempting to take the risk of
introducing new axioms because deriving them from definitions can be
tedious---proving that `axioms' follow from definitions amounts to
proving their consistency.

\paragraph {Further definitions}

The theory \theoryimp{bool} also supplies the definitions of a number of
useful constants.
\begin{hol}
\index{COND, the HOL constant@\holtxt{COND}, the \HOL{} constant}
\index{LET, the HOL constant@\ml{LET}, the \HOL{} constant}
\index{conditionals, in HOL logic@conditionals, in \HOL{} logic!definitional axiom for}
\begin{verbatim}
   LET_DEF  |- LET  = \f x. f x
   COND_DEF |- COND = \t t1 t2. @x. ((t=T)==>(x=t1)) /\ ((t=F)==>(x=t2))
   IN_DEF   |- IN   = \x (f:'a -> bool). f x
\end{verbatim}
\end{hol}

The constant \holtxt{LET}
%
\index{let-terms, in HOL logic@\holtxt{let}-terms, in \HOL{} logic!constant for}
%
is used in representing terms containing local variable bindings (\ie\
\holtxt{let}-terms).
%
\index{let-terms, in HOL logic@\holtxt{let}-terms, in \HOL{} logic!definitional axiom for}
%
For example, the concrete syntax \holtxt{let v = M in N} is translated
by the parser to the term \holtxt{LET (\bs{}v.N) M}. For the full
description of how \holtxt{let} expressions are translated, see
Section \ref{prod}.

The constant \holtxt{COND} is used to represent conditional
expressions. The concrete syntax
%
\index{terms, in HOL logic@terms, in \HOL{} logic!conditional}%
\index{conditionals, in HOL logic@conditionals, in \HOL{} logic}%
%
$\holtxt{if}\,t_1\,\holtxt{then}\,t_2\,\holtxt{else}\,t_3$ abbreviates the
application \holtxt{COND $t_1$ $t_2$ $t_3$}. The syntax
$t_1\holtxt{=>}t_2\holtxt{|}t_3$ is also permitted. The system prints
out conditionals in the \holtxt{if-then-else} form by default.

The constant \holtxt{IN} (written as an infix) is the basis of
the modelling of sets by their characteristic functions.  The term
$x\holtxt{ IN }P$ can be read as ``$x$ is an element of the set
$P$'', or (more in line with its definition) as ``the predicate $P$ is
true of $x$''.

Finally, the polymorphic constant $\holtxt{ARB}:\alpha$ denotes a
fixed but arbitrary element. \holtxt{ARB} is occasionally useful when
attempting to deal with the issue of partiality.

\subsubsection{Restricted quantifiers}\label{res-quant}

\index{restricted quantification}
%
The theory \theoryimp{bool} also defines constants that implement
\emph{restricted quantification}. This provides a means of simulating
subtypes and dependent types with predicates. The most heavily used
are restrictions of the existential and universal quantifiers:
%
\begin{verbatim}
   RES_FORALL_DEF |- RES_FORALL = \P m. !x. x IN P ==> m x

   RES_EXISTS_DEF |- RES_EXISTS = \P m. ?x. x IN P /\ m x

   RES_ABSTRACT_DEF |- (!P m x. x IN P ==> (RES_ABSTRACT P m x = m x) /\
                       (!P m1 m2.
                           (!x. x IN P ==> (m1 x = m2 x)) ==>
                            (RES_ABSTRACT P m1 = RES_ABSTRACT P m2)
\end{verbatim}
%
The definition of \ml{RES\_ABSTRACT} is a characterising formula, rather
than a direct equation.  There are two important properties
\begin{itemize}
\item if $y$ is an element of $P$ then $(\bs{}x :: P.\; M)
  y = M[y/x]$
\item If two restricted abstractions agree on all values over their
  (common) restricting set, then they are equal.
\end{itemize}

For completeness, restricted versions of unique existence and
indefinite description are provided, although hardly used.
\begin{verbatim}
   RES_EXISTS_UNIQUE_DEF
    |- RES_EXISTS_UNIQUE = \P m. (?x :: P. m x) /\
                                 (!x y :: P. m x /\ m y ==> (x = y))

   RES_SELECT_DEF
     |- RES_SELECT = \P m. @x. x IN P /\ m x
\end{verbatim}

The definition of \ml{RES\_EXISTS\_UNIQUE} uses the restricted
quantification syntax with the {\small\verb+::+} symbol, referring to
the earlier definitions \ml{RES\_EXISTS} and \ml{RES\_FORALL}.
The \texttt{::} syntax is used with restricted quantifiers to allow
arbitrary predicates to restrict binding variables. The \HOL{} parser
allows restricted quantification of all of a sequence of binding
variables by putting the restriction at the end of the sequence, thus
with a universal quantification:
%
\[
\forall x \, y \, z \, {\tt ::} \; P \, . \; Q(x,y,z)
\]
%
Here the predicate $P$ restricts all of $x$, $y$ and $z$.

\subsubsection{Derived syntactic forms}\label{derived-terms}

\index{type checking, in HOL logic@type checking, in \HOL{} logic!special forms in|(}
\index{quotation, in HOL logic@quotation, in \HOL{} logic!of non-primitive terms|(}
% don't refill the \index entries above, it's important to keep each
% entry on one line
The \HOL{} quotation parser
%
\index{quotation, in HOL logic@quotation, in \HOL{} logic!parser for}
%
can translate various standard logical
notations
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of standard notations}
%
into primitive terms. For example, if \ml{+} has been declared an
infix
%
\index{infixes, in HOL logic@infixes, in \HOL{} logic}
%
(as explained in Section~\ref{theoryfns}), as it is when
\ml{arithmeticTheory} has been loaded, then \ml{``x+1``} is
translated to \ml{``\$+~x~1``}. The escape character \ml{\$}
%
\index{ escape, in HOL logic parser@\ml{\$} (escape, in \HOL{} logic parser)}
\index{declared constants, in HOL logic@declared constants, in \HOL{} logic}
\index{infixes, in HOL logic@infixes, in \HOL{} logic}
%
suppresses the infix behaviour of \ml{+} and prevents the quotation
parser getting confused.  In general, \ml{\$} can be used to suppress
any special syntactic behaviour a token (such as \texttt{if},
\texttt{+} or \texttt{let})
%
\index{tokens!supressing parsing behaviour of}
%
might have. This is illustrated in the table below, in which the terms
in the column headed \textit{`\ML{} quotation'} are translated by the
quotation parser to the corresponding terms in the column headed
\textit{`Primitive term'}.  Conversely, the terms in the latter column
are always printed in the form shown in the former one.  The \ML{}
constructor expressions in the rightmost column evaluate to the same
values (of type \ml{term}) as the other quotations in the same row.

\bigskip

\begin{center}
\index{choice operator, in HOL logic@choice operator, in \HOL{} logic!syntax of}
\index{ negation, in HOL logic@\holtxt{\~{}} (negation, in \HOL{} logic)}
\index{ disjunction, in HOL logic@\holtxt{\bs/} (disjunction, in \HOL{} logic)}
\index{ conjunction, in HOL logic@\holtxt{/\bs} (conjunction, in \HOL{} logic)}
\index{ implication, in HOL logic@\holtxt{==>} (implication, in \HOL{} logic)}
\index{ equality, in HOL logic@\ml{=} (equality, in \HOL{} logic)}
\index{ universal quantifier, in HOL logic@\holtxt{"!} (universal quantifier, in \HOL{} logic)}
\index{ existential quantifier, in HOL logic@\holtxt{?} (existential quantifier, in \HOL{} logic)}
\index{ choice function, in HOL logic@\holtxt{"@} (choice function, in \HOL{} logic)}
\index{terms, in HOL logic@terms, in \HOL{} logic!non-primitive}
\index{terms, in HOL logic@terms, in \HOL{} logic!constructors for}
\index{conditionals, in HOL logic@conditionals, in \HOL{} logic}
\index{conjunction, in HOL logic@conjunction, in \HOL{} logic!constructor for}
\index{disjunction, in HOL logic@disjunction, in \HOL{} logic!constructor for}
\index{equality, in HOL logic@equality, in \HOL{} logic!syntax of}
\index{negation, in HOL logic@negation, in \HOL{} logic!syntax of}
\index{negation, in HOL logic@negation, in \HOL{} logic!constructor for}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL{} logic!syntax of}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL{} logic!syntax of}
\index{implication, in HOL logic@implication, in \HOL{} logic!syntax of}
\index{mk_neg@\ml{mk\_neg}}
\index{mk_disj@\ml{mk\_disj}}
\index{mk_conj@\ml{mk\_conj}}
\index{mk_imp@\ml{mk\_imp}}
\index{mk_eq@\ml{mk\_eq}}
\index{mk_forall@\ml{mk\_forall}}
\index{mk_exists@\ml{mk\_exists}}
\index{mk_select@\ml{mk\_select}}
\index{mk_cond@\ml{mk\_cond}}
\index{mk_let@\ml{mk\_let}}
\index{conjunction, in HOL logic@conjunction, in \HOL{} logic!syntax of}
\begin{tabular}{|l|l|l|l|} \hline
\multicolumn{4}{|c|}{ } \\
\multicolumn{4}{|c|}{\bf Non-primitive terms} \\
\multicolumn{4}{|c|}{ } \\
{\it Kind of term} & {\it \ML\ quotation} &
{\it Primitive term} &
{\it Constructor expression} \\ \hline
 & & & \\
Negation & {\small\verb+~+}$t$ & {\small\verb+$~ +}$t$ & {\small\verb+mk_neg(+}$t${\small\verb+)+} \\ \hline
Disjunction & $t_1${\small\verb+\/+}$t_2$ & {\small\verb+$\/ +}$t_1\ t_2$ &
{\small\verb+mk_disj(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
Conjunction & $t_1$\holtxt{/\bs}$t_2$ & $\holtxt{\$/\bs}\ t_1\ t_2$ &
{\small\verb+mk_conj(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\
\hline
%
Implication & $t_1${\small\verb+==>+}$t_2$ & {\small\verb+$==> +}$t_1\ t_2$ &
{\small\verb+mk_imp(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
Equality & $t_1${\small\verb+=+}$t_2$ & {\small\verb+$= +}$t_1\ t_2$ &
{\small\verb+mk_eq(+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
%
$\forall$-quantification & {\small\verb+!+}$x${\small\verb+.+}$t$ &
\holtxt{\$!(\bs}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_forall(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
$\exists$-quantification & {\small\verb+?+}$x${\small\verb+.+}$t$ &
\holtxt{\$?(\bs}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_exists(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
$\hilbert$-term & {\small\verb+@+}$x${\small\verb+.+}$t$ &
\holtxt{\$@(\bs}$x${\small\verb+.+}$t${\small\verb+)+} & {\small\verb+mk_select(+}$x${\small\verb+,+}$t${\small\verb+)+} \\ \hline
%
Conditional & {\small\verb+if +}$t\ ${\small\verb+then +}$t_1${\small\verb+ else +}$t_2$ &
{\small\verb+COND +}$t\ t_1\ t_2$ & {\small\verb+mk_cond(+}$t${\small\verb+,+}$t_1${\small\verb+,+}$t_2${\small\verb+)+}
 \\ \hline
%
{\small\verb+let+}-expression & {\small\verb+let +}$x${\small\verb+=+}$t_1${\small\verb+ in +}$t_2$ &
\holtxt{LET(\bs}$x${\small\verb+.+}$t_2${\small\verb+)+}$t_1$ &
\holtxt{mk\_let(\bs}$x${\small\verb+.+}$t_1${\small\verb+,+}$t_2${\small\verb+)+} \\ \hline
\end{tabular}
\end{center}

\bigskip

There are constructors, destructors and indicators for all the obvious
constructs. (Indicators, \eg\ \ml{is\_neg}, return truth values
indicating whether or not a term belongs to the syntax class in
question.) In addition to the constructors listed in the table there
are constructors, destructors, and indicators for pairs and lists,
namely \ml{mk\_pair},
%
\index{mk_pair@\ml{mk\_pair}}
%
\ml{mk\_cons}
%
\index{mk_cons@\ml{mk\_cons}}
%
and \ml{mk\_list}
%
\index{mk_list@\ml{mk\_list}}
%
(see \REFERENCE).  The constants \holtxt{COND} and \holtxt{LET} are
explained in Section~\ref{boolfull}.  The constants \holtxt{\bs/},
%
\index{disjunction, in HOL logic@disjunction, in \HOL{} logic!syntax of}
%
\holtxt{/\bs}, \holtxt{==>} and \holtxt{=} are examples of
\textit{infixes} and represent $\vee$, $\wedge$, $\imp$ and equality,
respectively. If $c$ is declared to be an infix, then the \HOL{}
parser will translate $t_1\ c\ t_2$ to {\small\verb+$+}$c\ t_1\ t_2$.

The constants {\small\verb+!+}, {\small\verb+?+} and {\small\verb+@+}
are examples of \label{binder} \textit{binders}
%
\index{binders, in HOL logic@binders, in \HOL{} logic}
%
and represent $\forall$, $\exists$ and $\hilbert$, respectively.  If
$c$ is declared to be a binder, then the \HOL{} parser will translate
\holtxt{$c$ $x$.$t$} to the combination \holtxt{\$$c$(\bs$x$.$t$)}
(\ie\ the application of the constant $c$ to the representation of the
abstraction $\lquant{x}t$).
\index{ function abstraction binder, in HOL logic@\holtxt{\bs} (function abstraction binder, in \HOL{} logic)}

\begin{center}

\index{variables, in HOL logic@variables, in \HOL{} logic!multiple bound}
\index{list_mk_comb@\ml{list\_mk\_comb}|pin}
\index{list_mk_abs@\ml{list\_mk\_abs}|pin}
\index{list_mk_forall@\ml{list\_mk\_forall}|pin}
\index{list_mk_exists@\ml{list\_mk\_exists}|pin}
\index{combinations, in HOL logic@combinations, in \HOL{} logic!abbreviation for multiple}
\index{existential quantifier, in HOL logic@existential quantifier, in \HOL{} logic!abbreviation for multiple}
\index{universal quantifier, in HOL logic@universal quantifier, in \HOL{} logic!abbreviation for multiple}
\begin{tabular}{|l|l|l|} \hline
\multicolumn{3}{|c|}{ } \\
\multicolumn{3}{|c|}{\bf Syntactic abbreviations} \\
\multicolumn{3}{|c|}{ } \\
{\it Abbreviated term} & {\it Meaning} &
{\it Constructor expression} \\ \hline
 & &  \\
$t\ t_1 \cdots t_n$ &
{\small\verb+(+}$\cdots${\small\verb+(+}$t\ t_1${\small\verb+)+}$\cdots t_n${\small\verb+)+} &
{\small\verb+list_mk_comb(+}$t${\small\verb+,[+}$t_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$t_n${\small\verb+])+} \\ \hline
\holtxt{\bs}$x_1\cdots x_n${\small\verb+.+}$t$ &
\holtxt{\bs}$x_1${\small\verb+. +}$\cdots$\holtxt{ \bs}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_abs([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+}
\\ \hline
{\small\verb+!+}$x_1\cdots x_n${\small\verb+.+}$t$ &
{\small\verb+!+}$x_1${\small\verb+. +}$\cdots${\small\verb+ !+}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_forall([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+}
\\ \hline
{\small\verb+?+}$x_1\cdots x_n${\small\verb+.+}$t$ &
{\small\verb+?+}$x_1${\small\verb+. +}$\cdots${\small\verb+ ?+}$x_n${\small\verb+.+}$t$ &
{\small\verb+list_mk_exists([+}$x_1${\small\verb+, +}$\ldots${\small\verb+ ,+}$x_n${\small\verb+],+}$t${\small\verb+)+} \\
\hline
\end{tabular}
\end{center}

\noindent There are also constructors
\ml{list\_mk\_conj}\index{list_mk_conj@\ml{list\_mk\_conj}},
\ml{list\_mk\_disj}\index{list_mk_disj@\ml{list\_mk\_disj}},
\ml{list\_mk\_imp}\index{list_mk_imp@\ml{list\_mk\_imp}} and
for conjunctions, disjunctions, and implications respectively.
The corresponding destructor functions are called \ml{strip\_comb}, \etc,
\index{term constructors, in HOL logic@term constructors, in \HOL{} logic|)}
\index{terms, in HOL logic@terms, in \HOL{} logic!constructors for|)}

\subsubsection{Theorems}

A large number of theorems involving the logical constants are
pre-proved in the theory \theoryimp{bool}. The following theorems
illustrate how higher order logic allows concise expression of
theorems supporting quantifier movement.

\begin{boxed}
\begin{verbatim}
 LEFT_AND_FORALL_THM  |- !P Q. (!x. P x) /\ Q = !x. P x /\ Q
 RIGHT_AND_FORALL_THM |- !P Q. P /\ (!x. Q x) = !x. P /\ Q x

 LEFT_EXISTS_AND_THM  |- !P Q. (?x. P x /\ Q) = (?x. P x) /\ Q
 RIGHT_EXISTS_AND_THM |- !P Q. (?x. P /\ Q x) = P /\ ?x. Q x

 LEFT_FORALL_IMP_THM  |- !P Q. (!x. P x ==> Q) = (?x. P x) ==> Q
 RIGHT_FORALL_IMP_THM |- !P Q. (!x. P ==> Q x) = P ==> !x. Q x

 LEFT_EXISTS_IMP_THM  |- !P Q. (?x. P x ==> Q) = (!x. P x) ==> Q
 RIGHT_EXISTS_IMP_THM |- !P Q. (?x. P ==> Q x) = P ==> ?x. Q x

 LEFT_FORALL_OR_THM   |- !Q P. (!x. P x \/ Q) = (!x. P x) \/ Q
 RIGHT_FORALL_OR_THM  |- !P Q. (!x. P \/ Q x) = P \/ !x. Q x

 LEFT_OR_EXISTS_THM   |- !P Q. (?x. P x) \/ Q = ?x. P x \/ Q
 RIGHT_OR_EXISTS_THM  |- !P Q. P \/ (?x. Q x) = ?x. P \/ Q x

 EXISTS_OR_THM        |- !P Q. (?x. P x \/ Q x) = (?x. P x) \/ ?x. Q x
 FORALL_AND_THM       |- !P Q. (!x. P x /\ Q x) = (!x. P x) /\ !x. Q x

 NOT_EXISTS_THM       |- !P. ~(?x. P x) = !x. ~P x
 NOT_FORALL_THM       |- !P. ~(!x. P x) = ?x. ~P x

 SKOLEM_THM           |- !P. (!x. ?y. P x y) = ?f. !x. P x (f x)
\end{verbatim}
\end{boxed}

Also, a theorem justifying Skolemization ({\small\verb+SKOLEM_THM+}) is
proved. Many other theorems may be found in \theoryimp{bool} theory.

\subsection{Combinators}

\index{function composition, in HOL logic@function composition, in \HOL{} logic|(}

The theory \theoryimp{combin}
\index{combin@\theoryimp{combin}}
\index{combinators, in HOL logic@combinators, in \HOL{} logic}
contains the definitions of function composition (infixed \ml{o})
\index{ function composition operator, in HOL logic@\ml{o} (function composition operator), in \HOL{} logic|(}
and the combinators
\ml{S},
\index{S, the HOL constant@\ml{S}, the \HOL{} constant}
\ml{K},
\index{K, the HOL constant@\ml{K}, the \HOL{} constant}
\ml{I},
\index{I, the HOL constant@\ml{I}, the \HOL{} constant}
\ml{W},
\index{W, the HOL constant@\ml{W}, the \HOL{} constant}
and \ml{C},
\index{C, the HOL constant@\ml{C}, the \HOL{} constant}

\begin{hol}
\begin{verbatim}
   o_DEF |- f o g = (\x. f(g x))
   K_DEF |- K = (\x y. x)
   S_DEF |- S = (\f g x. f x(g x))
   I_DEF |- I = S K K
   W_DEF |- W = (\f x. f x x)
   C_DEF |- C = (\f x y. f y x)
\end{verbatim}
\end{hol}

\noindent The following elementary properties are proved in the theory
\ml{combin}:

\begin{hol}
\begin{verbatim}
   o_THM   |- !f g x. (f o g) x = f(g x)
   o_ASSOC |- !f g h. f o (g o h) = (f o g) o h

   K_THM   |- !x y. K x y = x
   S_THM   |- !f g x. S f g x = f x (g x)
   I_THM   |- !x. I x = x
   W_THM   |- !f x. W f x = f x x
   C_THM   |- !f x y. C f x y = f y x
\end{verbatim}
\end{hol}

Having the symbols \ml{o}, \ml{S}, \ml{K}, \ml{I}, \ml{W}, and \ml{C}
as built-in constants
%
\index{variables, in HOL logic@variables, in \HOL{} logic!with constant names}
%
is sometimes inconvenient because they are often wanted as mnemonic
names for variables (\eg\ \ml{S} to range over sets and \ml{o} to
range over outputs).\footnote{Constants declared in new theories can
  freely re-use these names, with ambiguous inputs resolved by type
  inference.}  Variables with these names can be used in the current
system if \ml{o}, \ml{S}, \ml{K}, \ml{I}, \ml{W}, and \ml{C} are first
hidden (see Section~\ref{hidden}).  In fact, this happens so often
with the constant \holtxt{C} that it is ``hidden'' by default.  While
hidden, it must be written in fully-qualified form, as
\holtxt{combin\$C}.
%
\index{ function composition operator, in HOL logic@\ml{o} (function composition operator), in \HOL{} logic|)}
\index{function composition, in HOL logic@function composition, in \HOL{} logic|)}
\index{constants, in HOL logic@constants, in \HOL{} logic!fully-qualified names of}


\subsection{Pairs}\label{prod}

\index{representing types, in HOL logic@representing types, in \HOL{} logic!pair example of|(}
\index{pairs, in HOL logic@pairs, in \HOL{} logic|(}
\index{product types!in HOL logic@in \HOL{} logic|(}
%
The Cartesian  product  type  operator
%
\index{type operators, in HOL logic@type operators, in \HOL{} logic!for pairs}
%
\holtxt{prod}
%
\index{prod@\holtxt{prod}}
%
is defined in the theory \theoryimp{pair}. Values of type
\holtxt{($\sigma_1$,$\sigma_2$)prod} are ordered pairs whose first
component has type $\sigma_1$ and whose second component has type
$\sigma_2$.  The \HOL{} type parser
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of pairs}
%
converts type expressions of the form \holtxt{:$\sigma_1$\#$\sigma_2$}
%
\index{ product type operator, in HOL logic@\holtxt{\#} (product type operator, in \HOL{} logic)}
%
into \holtxt{($\sigma_1$,$\sigma_2$)prod},
%
\index{ pair constructor, in HOL logic@\ml{,} (pair constructor, in \HOL{} logic)}
%
and the printer inverts this transformation. Pairs
%
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL{} logic}
%
are constructed with an infixed comma symbol

\begin{hol}
\begin{verbatim}
   $, : 'a -> 'b -> 'a # 'b
\end{verbatim}
\end{hol}

\noindent
so, for example, if $t_1$ and $t_2$ have types $\sigma_1$ and
$\sigma_2$ respectively, then $t_1$\ml{,}$t_2$ is a term with type
$\sigma_1$\holtxt{\#}$\sigma_2$. Usually, pairs are written within
brackets: \holtxt{($t_1$,$t_2$)}. The comma symbol associates
%
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL{} logic!associativity of}
%
to the right, so that \holtxt{($t_1$,$t_2$,$\ldots$,$t_n$)} means
\holtxt{($t_1$,($t_2$,$\ldots$,$t_n$))}.

\paragraph {Defining the product type}

The type of Cartesian products is defined by representing a pair
{\small\verb%(%}$t_1${\small\verb%,%}$t_2${\small\verb%)%}
by the function
%
\begin{hol}
\begin{alltt}
   \bs{}a b. (a=\m{t\sb{1}}) /\bs (b=\m{t\sb{2}})
\end{alltt}
\end{hol}
%
\noindent The representing type of
$\sigma_1${\small\verb%#%}$\sigma_2$ is thus
$\sigma_1${\small\verb%->%}$\sigma_2${\small\verb%->bool%}.
It is easy to prove the following theorem.\footnote{This theorem has
an un-reduced $\beta$-redex in order to meet the interface
required by the type definition principle.}
%
\begin{hol}
\begin{verbatim}
   |- ?p:'a->'b->bool. (\p. ?x y. p = \a b. (a = x) /\ (b = y)) p
\end{verbatim}
\end{hol}
%
The type operator {\small\verb%prod%} is defined
by invoking \verb+new_type_definition+ with this theorem
 which results in the definitional axiom
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
\index{axioms!in bool theory@in \ml{bool} theory}
\ml{prod\_TY\_DEF} shown below being asserted in the theory \ml{pair}.
%
\begin{hol}
\begin{verbatim}
   prod_TY_DEF
     |- ?rep. TYPE_DEFINITION (\p. ?x y. p = (\a b. (a = x) /\ (b = y))) rep
\end{verbatim}
\end{hol}
%
Next, the representation and abstraction functions \holtxt{REP\_prod}
and \holtxt{ABS\_prod} for the new type are introduced, along with the
following characterizing theorem, by use of the function
\ml{define\_new\_type\_bijections}.
%
\begin{hol}
\begin{verbatim}
   |- (!a. ABS_prod (REP_prod a) = a) /\
      (!r. (\p. ?x y. p = (\a b. (a=x) /\ (b=y)) r = (REP_prod(ABS_prod r) = r)
\end{verbatim}
\end{hol}

\paragraph {Pairs and projections}

The infix constructor `{\small\verb%,%}' is then defined
to be an application of the abstraction function. Subsequently, two
crucial theorems are proved: {\small\verb+PAIR_EQ+} asserts that equal
pairs have equal components and {\small\verb+ABS_PAIR_THM+} shows that
every term having a product type can be decomposed into a pair of terms.
\begin{hol}
\index{pairing constructor, in HOL logic@pairing constructor, in \HOL{} logic!definition of}
\index{PAIR_EQ@\ml{PAIR\_EQ}}
\index{ABS_PAIR_THM@\ml{ABS\_PAIR\_THM}}
\begin{verbatim}
   COMMA_DEF    |- !x y. $, x y = ABS_prod (\a b. (a = x) /\(b = y))

   PAIR_EQ      |- ((x,y) = (a,b)) = (x=a) /\ (y=b)

   ABS_PAIR_THM |- !x. ?q r. x = (q,r)
\end{verbatim}
\end{hol}
%
By Skolemizing {\small\verb+ABS_PAIR_THM+} and making constant specifications
for {\small\verb+FST+} and {\small\verb+SND+}, the following theorems
are proved.
%
\begin{hol}
\index{PAIR@\ml{PAIR}}
\index{FST, the HOL constant@\ml{FST}, the \HOL{} constant!definition of}
\index{SND, the HOL constant@\ml{SND}, the \HOL{} constant!definition of}
\index{selectors, in HOL logic@selectors, in \HOL{} logic!for pairs}
\begin{verbatim}
   PAIR     |- !x. (FST x,SND x) = x
   FST      |- !x y. FST(x,y) = x
   SND      |- !x y. SND(x,y) = y
\end{verbatim}
\end{hol}
\index{pairs, in HOL logic@pairs, in \HOL{} logic|)}
\index{product types!in HOL logic@in \HOL{} logic|)}
\index{representing types, in HOL logic@representing types, in \HOL{} logic!pair example of|)}

\paragraph{Pairs and functions}

In \HOL{}, a function of type $\alpha \# \beta\to\gamma$ always has a
counterpart of type $\alpha\to\beta\to\gamma$, and \emph{vice versa}.
This conversion is accomplished by the functions \holtxt{CURRY} and
\holtxt{UNCURRY}. These functions are inverses.
%
\begin{hol}
\index{CURRY, the HOL constant@\ml{CURRY}, the \HOL{} constant}
\index{UNCURRY, the HOL constant@\ml{UNCURRY}, the \HOL{} constant}
\begin{verbatim}
   CURRY_DEF    |- !f x y. CURRY f x y = f (x,y)
   UNCURRY_DEF  |- !f x y. UNCURRY f (x,y) = f x y

   CURRY_UNCURRY_THM |- !f. CURRY (UNCURRY f) = f
   UNCURRY_CURRY_THM |- !f. UNCURRY (CURRY f) = f
\end{verbatim}
\end{hol}


\paragraph {Mapping functions over a pair}

Functions $f : \alpha \to \gamma_1$ and $g : \beta\to\gamma_2$ can be
applied component-wise ({\small\verb+##+}, infix) over a pair of type
$\alpha \# \beta$ to obtain a pair of type $\gamma_1 \# \gamma_2$.
%
\begin{hol}
\index{mapping functions, in the HOL logic@mapping functions, in the \HOL{} logic!for pairs}
\index{ PAIR_MAP function@\ml{\#\#} (\holtxt{PAIR\_MAP} function)}
\begin{verbatim}
   PAIR_MAP_THM  |- !f g x y. (f ## g) (x,y) = (f x,g y)
\end{verbatim}
\end{hol}

\paragraph {Binders and pairs}

When doing proofs, statements involving tuples may take the form of a
binding (quantification or $\lambda$-abstraction) of a variable with a
product type. It may be convenient in subsequent reasoning steps to
replace the variables with tuples of variables. The following theorems
support this.
%
\begin{hol}
\begin{verbatim}
  FORALL_PROD  |- (!p. P p) = !p_1 p_2. P (p_1,p_2)
  EXISTS_PROD  |- (?p. P p) = ?p_1 p_2. P (p_1,p_2)
  LAMBDA_PROD  |- !P. (\p. P p) = \(p1,p2). P (p1,p2)
\end{verbatim}
\end{hol}
%
The theorem \ml{LAMBDA\_PROD} involves a \emph{paired
 abstraction}, discussed in Section \ref{HOL-varstruct}.


\paragraph {Wellfounded relations on pairs}

Wellfoundedness, defined in Section \ref{prim-rec-conseq},
is a useful notion, especially for proving termination of
recursive functions. For pairs, the lexicographic combination
of relations ({\small\verb+LEX+}, infix) may be defined by using
paired abstractions. Then the theorem that lexicographic combination
of wellfounded relations delivers a wellfounded relation is easy to
prove.
%
\begin{hol}
\begin{verbatim}
   LEX_DEF =
      |- !R1 R2. R1 LEX R2 = (\(s,t) (u,v). R1 s u \/ (s = u) /\ R2 t v)
   WF_LEX
      |- !R Q. WF R /\ WF Q ==> WF (R LEX Q)
\end{verbatim}
\end{hol}

\subsubsection{Paired abstractions}
\label{HOL-varstruct}
\index{pairs, in HOL logic@pairs, in \HOL{} logic!in abstractions|(}
\index{terms, in HOL logic@terms, in \HOL{} logic!pair|(}
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of quotation syntax|(}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!paired|(}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!uncurrying, in paired|(}

It is notationally convenient to include pairing in the lambda
notation, as a simple pattern-matching mechanism. The quotation parser
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of function abstractions}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!abbreviation for multiple}
\index{terms, in HOL logic@terms, in \HOL{} logic!function abstraction}
will convert the term
{\small\bs\texttt{(}}$x_1${\small\verb%,%}$x_2${\small\verb%).%}$t$
to {\small\verb%UNCURRY(%\bs}$x_1\ x_2${\small\verb%.%}$t${\small\verb%)%}.
The transformation is done recursively so that, for example,
%
\begin{hol}
\begin{alltt}
   \bs(\m{x\sb{1}},\m{x\sb{2}},\m{x\sb{3}}).\m{t}
\end{alltt}
\end{hol}
%
\noindent is converted to
%
\begin{hol}
\begin{alltt}
   UNCURRY \bs\m{x\sb{1}}. UNCURRY(\bs\m{x\sb{2}} \m{x\sb{3}}.\m{t}))
\end{alltt}
\end{hol}
%
\noindent More generally, the quotation parser repeatedly applies the
transformation:
%
\begin{hol}
\begin{alltt}
   \bs(\m{v\sb{1}},\m{v\sb{2}}).\m{t}\m{\quad \leadsto\quad}UNCURRY(\bs\m{v\sb{1}}.\bs\m{v\sb{2}}.\m{t})
\end{alltt}
\end{hol}
%
\noindent until no more variable structures remain. For example:

\vspace{1ex}
\begin{tabular}{ll}
\texttt{\bs($x$,$y$).$t$} &
  $\leadsto$ \texttt{UNCURRY(\bs$x\,y$.$t$)}\\
%
\texttt{\bs($x_1$,$x_2$,$\ldots$,$x_n$).$t$} &
  $\leadsto$ \texttt{UNCURRY(\bs$x_1$.\bs($x_2$,$\ldots$,$x_n$).$t$)}\\
%
\texttt{\bs(($x_1$,$\ldots$,$x_n$),$y_1$,$\ldots$,$y_m$).$t$} &
  $\leadsto$
  \texttt{UNCURRY(\bs($x_1$,$\ldots$,$x_n$).\bs($y_1$,$\ldots$,$y_m$).$t$)}\\
\end{tabular}

\vspace{1ex}

As a result of this parser translation, a variable structure, such as \ml{(x,y)} in
\ml{\bs(x,y).x+y}, is not a subterm of the abstraction
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!subterms of}
in which it occurs; it disappears on parsing.
\index{binders, in HOL logic@binders, in \HOL{} logic!parsing of}
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of binders}
This can lead to unexpected errors (accompanied by obscure error
messages).  For example, antiquoting a pair into the bound variable
position of a lambda abstraction fails:

\begin{session}
\begin{verbatim}
- ``\(x,y).x+y``;
> val it = `\(x,y). x + y` : term

- val p = Term `(x:num,y:num)`;
> val p = `(x,y)` : term

- Lib.try Term `\^p.x+y`;

Exception raised at Term.dest_var:
not a var
! Uncaught exception:
\end{verbatim}
\end{session}
If $b$ is a binder, then \ml{$b$($x_1$,$x_2$).$t$} is parsed as
\ml{$b$(\bs($x_1$,$x_2$).$t$)}, and hence transformed as above.  For
example,
\ml{!(x,y).\ x > y}
parses to
\ml{\$!(UNCURRY(\bs{}x.\bs{}y.\ x > y))}.
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!paired|)}
\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!uncurrying, in paired|)}
\index{pairs, in HOL logic@pairs, in \HOL{} logic!in abstractions|)}
\index{terms, in HOL logic@terms, in \HOL{} logic!pair|)}


\subsubsection{\texttt{let}-terms}
\label{let-exp}

The quotation parser
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of let-terms@of \holtxt{let}-terms}
%
accepts \ml{let}-terms
\index{terms, in HOL logic@terms, in \HOL{} logic!let-@\holtxt{let}-}
\index{let-terms, in HOL logic@\holtxt{let}-terms, in \HOL{} logic!as abbreviations}
similar to those in \ML. For example, the following terms are allowed:

\begin{hol}
\begin{verbatim}
   let x = 1 and y = 2 in x+y

   let f(x,y) = (x*x)+(y*y) and a = 20*20 and b = 50*49 in f(a,b)
\end{verbatim}
\end{hol}

\ml{let}-terms are actually abbreviations for ordinary terms which are
specially supported by the parser and pretty printer.
The constant \ml{LET}
\index{LET@\ml{LET}} is defined (in the theory \ml{bool}) by:

\begin{hol}\index{function abstraction, in HOL logic@function abstraction, in \HOL{} logic!relation to let-terms@relation to \ml{let}-terms}
\begin{verbatim}
   LET = (\f x. f x)
\end{verbatim}
\end{hol}

\noindent and is used to encode \ml{let}-terms in the logic. The parser
repeatedly applies the transformations:

\bigskip

{\small\begin{tabular}{ll}
\texttt{let~$f\,v_1\,\ldots\,v_n$~=~$t_1$~in~$t_2$} &
$\leadsto$~~\texttt{LET(\bs$f$.$t_2$)(\bs$v_1\,\ldots\,v_n$.$t_1$)}\\
%
\texttt{let~($v_1$,$\ldots$,$v_n$)~=~$t_1$~in~$t_2$} &
$\leadsto$~~\texttt{LET(\bs($v_1$,$\ldots$,$v_n$).$t_2$)$t_1$}\\
%
\texttt{let~$v_1$=$t_1$~and~$\ldots$~and~$v_n$=$t_n$~in~$t$} &
$\leadsto$~~\texttt{LET($\ldots$(LET(LET(\bs$v_1\ldots v_n$.$t$)$t_1$)$t_2$)$\ldots$)$t_n$}\\
\end{tabular}}

\bigskip


\noindent The underlying structure of the term can be seen by applying
destructor operations.  For example:

\begin{session}
\begin{verbatim}
- Term `let x = 1 and y = 2 in x+y`;
> val it = `let x = 1 and y = 2 in x + y` : term

- dest_comb it;
> val it = (`LET (LET (\x y. x + y) 1)`, `2`) : term * term

- Term `let (x,y) = (1,2) in x+y`;
> val it = `let (x,y) = (1,2) in x + y` : Term.term

- dest_comb it;
> val it = (`LET (\(x,y). x + y)`, `(1,2)`) : Term.term * Term.term
\end{verbatim}
\end{session}

The reader is recommended to convince himself or herself that the
translations of \ml{let}-terms represent the intuitive meaning suggested by
the surface syntax.
\index{quotation, in HOL logic@quotation, in \HOL{} logic|)}
\index{quotation, in HOL logic@quotation, in \HOL{} logic!of non-primitive terms|)}
\index{terms, in HOL logic@terms, in \HOL{} logic!syntax of|)}
\index{type checking, in HOL logic@type checking, in \HOL{} logic!special forms in|)}

\subsection{Disjoint sums}
\label{sum}
\index{disjoint unions, the HOL theory of@disjoint unions, the \HOL{} theory of|(}
\index{sums (disjoint unions), the HOL theory of@sums (disjoint unions), the \HOL{} theory of|(}


The theory \theoryimp{sum} defines the binary disjoint union type
operator \holtxt{sum}.  A type \holtxt{($\sigma_1$,$\sigma_2$)sum}
denotes the disjoint union of types $\sigma_1$ and $\sigma_2$.  The
type operator \holtxt{sum} can be defined, just as \holtxt{prod} was,
but the details are omitted here.\footnote{The definition of disjoint
  unions in the HOL system is due to Tom Melham. The technical details
  of this definition can be found in~\cite{Melham-banff}.}  The \HOL{}
parser
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of sum types}
%
converts \holtxt{``:$\sigma_1$+$\sigma_2$``}
%
\index{ disjoint union type operator, in HOL logic@\ml{+} (disjoint union type operator, in HOL logic)}
%
into \holtxt{``:($\sigma_1$,$\sigma_2$)sum``}, and the printer inverts
this.

The standard operations on sums are:

\begin{hol}
\index{INL, the HOL constant@\ml{INL}, the \HOL{} constant}
\index{INR, the HOL constant@\ml{INR}, the \HOL{} constant}
\index{ISL, the HOL constant@\ml{ISL}, the \HOL{} constant}
\index{ISR, the HOL constant@\ml{ISR}, the \HOL{} constant}
\index{OUTL, the HOL constant@\ml{OUTL}, the \HOL{} constant}
\index{OUTR, the HOL constant@\ml{OUTR}, the \HOL{} constant}
\begin{verbatim}
   INL  : 'a -> 'a + 'b
   INR  : 'b -> 'a + 'b
   ISL  : 'a + 'b -> bool
   ISR  : 'a + 'b -> bool
   OUTL : 'a + 'b -> 'a
   OUTR : 'a + 'b -> 'b
\end{verbatim}
\end{hol}

\noindent These are all defined as constants in the theory \ml{sum}.  The
constants \ml{INL} and \ml{INR} inject into the left and right summands,
respectively. The constants \ml{ISL} and \ml{ISR} test for membership of the
left and right summands, respectively. The constants \ml{OUTL} and \ml{OUTR}
project from a sum to the left and right summands, respectively.

The following theorem is proved in the theory \ml{sum}. It provides a
complete and abstract characterization of the disjoint sum type, and
is used to justify the definition of functions over sums.

\begin{hol}
\begin{verbatim}
  sum_Axiom  |- !f g. ?! h. (!x. h(INL x) = f x) /\ (!x. h(INR x) = g x)
\end{verbatim}
\end{hol}

\noindent Also provided are the following theorems having to
do with the discriminator functions \ml{ISL} and \ml{ISR}:

\begin{hol}
\begin{verbatim}
   ISL         |- (!x. ISL(INL x)) /\ (!y. ~ISL(INR y))
   ISR         |- (!x. ISR(INR x)) /\ (!y. ~ISR(INL y))

   ISL_OR_ISR  |- !x. ISL x \/ ISR x
\end{verbatim}
\end{hol}

\noindent The \ml{sum} theory also provides the following theorems
relating the projection functions and the discriminators.

\begin{hol}
\begin{verbatim}
   OUTL        |- !x. OUTL(INL x) = x
   OUTR        |- !x. OUTR(INR x) = x

   INL         |- !x. ISL x ==> (INL(OUTL x) = x)
   INR         |- !x. ISR x ==> (INR(OUTR x) = x)
\end{verbatim}
\end{hol}

\index{disjoint unions, the HOL theory of@disjoint unions, the \HOL{} theory of|}
\index{sums (disjoint unions), the HOL theory of@sums (disjoint unions), the \HOL{} theory of|)}


\subsection{The one-element type}%
\index{one, the HOL theory@\ml{one}, the \HOL{} theory}%
\index{one, the HOL type@\ml{one}, the \HOL{} type}%

The theory \ml{one} defines  the type  \ml{one} which  contains one element.
The constant  \ml{one}  is specified  to denote  this element.   The pre-proved
theorems in the theory \ml{one} are:

\begin{hol}
\index{one_axiom@\ml{one\_axiom}}
\index{one, the HOL theorem@\ml{one}, the \HOL{} theorem}
\index{one_Axiom@\ml{one\_Axiom}}
\begin{verbatim}
   one_axiom   |- !(f:'a->one) (g:'a -> one). f = g
   one         |- !(v:one). v = one
   one_Axiom   |- !(e:'a). ?!(fn:one->'a). fn one = e
\end{verbatim}
\end{hol}

\noindent These three theorems are equivalent characterizations of the type
with only one value. The theory \ml{one} is typically used in
constructing more elaborate types.  The one value of the type
\ml{one}, can also be written as \ml{()} by analogy with the unit
value in \ML.  This is also the default way in which this value is
printed by the system pretty-printer.

\subsection{The option type}
\index{options, the HOL theory of@options, the \HOL{} theory of}

The theory \theoryimp{option} defines a type operator \verb+option+
that `lifts' its argument type, creating a type with all of the
values of the argument and one other, specially distinguished value.
The constructors of this type are
\begin{hol}
\begin{verbatim}
   NONE : 'a option
   SOME : 'a -> 'a option
\end{verbatim}
\end{hol}
Options can be used to model partial functions.  If a function of type
$\alpha\rightarrow\beta$ does not have useful $\beta$ values for all
$\alpha$ inputs, then this distinction can be marked by making the
range of the function $\beta\,\konst{option}$, and mapping the
undefined $\alpha$ values to \holtxt{NONE}.

An inductive type, options have a recursion theorem supporting the
definition of primitive recursive functions over option values.
%
\begin{hol}
\begin{verbatim}
   option_Axiom
     |- !e f.
         ?h:'a option -> 'b.
           (!x. h (SOME x) = f x) /\
           (h NONE = e)
\end{verbatim}
\end{hol}
The \theoryimp{option} theory also defines a case constant that allows
one to inspect option values in a ``pattern-matching'' style.
\begin{hol}
\begin{verbatim}
   case e of
      NONE -> u
   || SOME x -> f x
\end{verbatim}
\end{hol}
%
The constant underlying this syntactic sugar is \verb+option_case+
with definition
\begin{hol}
\begin{verbatim}
   option_case_def |- (option_case u f NONE = u) /\
                      (option_case u f (SOME x) = f x)
\end{verbatim}
\end{hol}
%
Another useful function maps a function over an option:
%
\index{mapping functions, in the HOL logic@mapping functions, in the \HOL{} logic!for options}
\begin{hol}
\begin{verbatim}
   OPTION_MAP_DEF  |- (OPTION_MAP f NONE = NONE) /\
                      (OPTION_MAP f (SOME x) = SOME (f x))
\end{verbatim}
\end{hol}
Finally, the \holtxt{THE} function takes a \holtxt{SOME}
value to that constructor's argument, and is unspecified on
\holtxt{NONE}:
\begin{hol}
\begin{verbatim}
   THE_DEF   |- THE (SOME x) = x
\end{verbatim}
\end{hol}

\section{Numbers}

The natural numbers, integers, and real numbers are provided in a
series of theories. Also available are theories of $n$-bit words
(numbers modulo $2^n$), floating point and fixed point numbers.

\subsection{Natural numbers}

The natural numbers are developed in a series of theories:
\theoryimp{num}, \theoryimp{prim\_rec}, \theoryimp{arithmetic}, and
\theoryimp{numeral}. In \theoryimp{num}, the type of numbers is
defined from the Axiom of Infinity, and Peano's axioms are derived. In
\theoryimp{prim\_rec} the Primitive Recursion theorem is proved. Based
on that, a large theory treating the standard arithmetic operations is
developed in \theoryimp{arithmetic}. Lastly, a theory of numerals is
developed.

\subsubsection{The theory \theoryimp{num}}

The theory \theoryimp{num}
\index{num, the theory in HOL logic@\ml{num}, the theory in \HOL{} logic}
defines the type \ml{num} of natural numbers to be
isomorphic to a countable subset of the primitive type \ml{ind}.  In this
theory, the constants \ml{0}
\index{ zero, in HOL logic@\ml{0} (zero, in \HOL{} logic)}
and \ml{SUC} (the successor function) are defined
and Peano's axioms
\index{axioms!in num theory@in \ml{num} theory}
\index{Peano's axioms}
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
pre-proved in the form:

\begin{hol}
\index{NOT_SUC@\ml{NOT\_SUC}}
\index{INV_SUC@\ml{INV\_SUC}}
\index{induction theorems, in HOL logic@induction theorems, in \HOL{} logic!for natural numbers}
\begin{verbatim}
   NOT_SUC    |- !n. ~(SUC n = 0)
   INV_SUC    |- !m n. (SUC m = SUC n) ==> (m = n)
   INDUCTION  |- !P. P 0 /\ (!n. P n ==> P(SUC n)) ==> (!n. P n)
\end{verbatim}
\end{hol}

In higher order logic, Peano's axioms are sufficient for developing
number theory because addition and multiplication can be defined. In
first order logic these must be taken as primitive.  Note also that
\ml{INDUCTION} could not be stated as a single axiom in first order
logic because predicates (\eg\ \holtxt{P}) cannot be quantified.

\subsubsection{The theory \theoryimp{prim\_rec}}
\label{prim_rec}

\index{primitive recursion theorem!for numbers|(}
\index{prim_rec@\ml{prim\_rec}|(}
In classical logic, unlike domain theory logics such as \PPL,
%
\index{PPlambda (same as PPLAMBDA), of LCF system@\ml{PP}$\lambda$ (same as \ml{PPLAMBDA}), of \ml{LCF} system}
%
arbitrary recursive definitions
%
\index{recursive definitions, in classical logics}
%
are not allowed. For example, there is no function $f$ (of type
\ml{num->num}) such that

\begin{alltt}
   !\(x\). \(f\) \(x\) = (\(f\) \(x\)) + 1
\end{alltt}
Certain restricted forms of recursive
%
\index{primitive recursive functions}
%
definition do, however, uniquely define functions. An important
example are the \emph{primitive recursive} functions.\footnote{In
  higher order logic, primitive recursion is much more powerful than
  in first order logic; for example, Ackermann's function can be
  defined by primitive recursion in higher order logic.} For any $x$
and $f$ the \emph{primitive recursion theorem} tells us that there is
a unique function \holtxt{fn} such that:

\begin{alltt}
   (fn 0 = \(x\)) /\bs (!\(n\). fn(SUC \(n\)) = f (fn \(n\)) \(n\))
\end{alltt}

The primitive recursion theorem, named \ml{num\_Axiom} in \HOL,
follows from Peano's
%
\index{Peano's axioms}
%
axioms.

\begin{hol}\index{num_Axiom@\ml{num\_Axiom}}
\index{characterizing theorem!for numbers}
\begin{verbatim}
   num_Axiom  |- !x f. ?fn. (fn 0 = x) /\ (!n. fn(SUC n) = f n (fn n))
\end{verbatim}
\end{hol}

\noindent The theorem states the validity of primitive recursive
definitions on the natural numbers: for any \ml{x} and \ml{f} there exists a
corresponding total function \ml{fn} which satisfies
the primitive recursive definition whose form is determined by \ml{x} and
\ml{f}.

\paragraph{The less-than relation}

The less-than relation `\holtxt{<}'
\index{ less than, in HOL logic@\ml{<} (less than, in \HOL{} logic)}
\index{less than, in HOL logic@less than, in \HOL{} logic}
is most naturally defined by primitive recursion. However, in our
development it is needed for the proof of the
  primitive recursion theorem, so it must be defined before definition
  by primitive recursion is available. The theory \theoryimp{prim\_rec}
  therefore contains the following non-recursive definition of \ml{<}:

\begin{hol}
\index{LESS@\ml{LESS}}
\begin{verbatim}
   LESS  |- !m n. m < n = ?P. (!n. P(SUC n) ==> P n) /\ P m /\ ~P n
\end{verbatim}
\end{hol}

\noindent
This definition says that {\small\verb%m < n%} if there exists a set (with
characteristic function {\small\verb%P%}) that is downward
closed\footnote{A set of numbers is \textit{downward closed} if whenever it
contains the successor of a number, it also contains the number.} and
contains {\small\verb%m%} but not {\small\verb%n%}.

\subsubsection{Mechanizing primitive recursive definitions}
\label{num-prim-rec}

\index{type definitions, in HOL logic@type definitions, in \HOL{} logic!primitive recursive|(}
\index{recursive definitions, in HOL logic@recursive definitions, in \HOL{} logic!automated, for numbers}
\index{primitive recursion theorem!automated use of, in HOL system@automated use of, in \HOL{} system|(}
The primitive
\index{primitive recursive definitions, in HOL logic@primitive recursive definitions, in \HOL{} logic!justification of}
recursion theorem can be used to justify any definition of a function
on the natural numbers by primitive recursion.  For example, a
primitive recursive definition in higher order logic of the form

\begin{hol}
\begin{alltt}
   fun 0       x\(\sb{1}\) \m{\dots} x\(\sb{i}\) = \m{f\sb{1}[}x\(\sb{1}\)\m{,\ldots,\,} x\(\sb{i}]\)
   fun (SUC n) x\(\sb{1}\) \m{\dots} x\(\sb{i}\) = \m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\m{,} x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
\end{alltt}
\end{hol}

\noindent where all the free variables in the  terms $t_1$,
\dots, $t_i$ are contained in $\{$\ml{n}, $\ml{x}_1$, \dots, $\ml{x}_i\}$,
is logically equivalent to:

\begin{hol}
\begin{alltt}
   fun 0       = \bs{}x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
   fun (SUC n) = \bs{}x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\m{,}x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)
               = (\bs{}f n x\(\sb{1}\) \m{\dots} x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\m{,} x\(\sb{1}\)\m{,\ldots,\,}x\(\sb{i}]\)) (fun n) n
\end{alltt}
\end{hol}

The existence  of  a  recursive  function  \ml{fun} which  satisfies these two
equations follows directly from the primitive recursion theorem
\ml{num\_Axiom} shown above.   Specializing the  quantified variables \verb!x!
and \verb!f!  in  a suitably  type-instantiated version  of \ml{num\_Axiom} so
that

\begin{hol}
\begin{alltt}
   x\m{=}\bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)  {\rm and}  f\(=\)\bs{}f n x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\))
\end{alltt}
\end{hol}

\noindent yields the existence theorem shown below:

\begin{hol}
\begin{alltt}
   |- ?fn. fn 0       = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\) /\bs{}
           fn (SUC n) = (\bs{}f n x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}f \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)) (fn n) n
\end{alltt}
\end{hol}

\noindent This theorem allows a constant \ml{fun} to be introduced (via the
definitional mechanism of constant specifications---see Section~\ref{conspec})
to denote the recursive function that satisfies the two equations in the body
of the theorem. Introducing a constant \ml{fun} to name the function asserted
to exist by the theorem shown above, and simplifying using $\beta$-reduction,
yields the following theorem:

\begin{hol}
\begin{alltt}
   |- fun 0       = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\) /\bs{}
      fun (SUC n) = \bs{}x\(\sb{1}\) \(\dots\) x\(\sb{i}\).\m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
\end{alltt}
\end{hol}

\noindent It follows immediately from this theorem that the constant \ml{fun}
satisfies the primitive recursive defining equations given by the theorem shown
below:

\begin{hol}
\begin{alltt}
   |- fun 0 x\(\sb{1}\) \(\dots\) x\(\sb{i}\) = \m{f\sb{1}[}x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
      fun (SUC n) x\(\sb{1}\) \(\dots\) x\(\sb{i}\) = \m{f\sb{2}[}fun n \m{t\sb{1} \dots t\sb{i},} n\(,\) x\(\sb{1}\)\(,\ldots,\,\)x\(\sb{i}]\)
\end{alltt}
\end{hol}

To automate the use of the primitive recursion theorem in deriving
recursive definitions of this kind, the \HOL{} system provides a function
which automatically proves the existence of primitive recursive
functions and then makes a constant specification to introduce the constant
that denotes such a function:

\begin{boxed}
\index{new_recursive_definition@\ml{new\_recursive\_definition}|pin}
\begin{verbatim}
   new_recursive_definition :
      {def : term, name : string, rec_axiom : thm} -> thm
\end{verbatim}
\end{boxed}

\noindent In fact, \ml{new\_recursive\_definition} handles
primitive recursive definitions over a range of types, not just the
natural numbers. For details, see the \REFERENCE\ documentation.

More conveniently still, the \ml{Define} function (see
Section~\ref{sec:high-level-proof-steps}) supports primitive
recursion, along with other styles of recursion, and does not require
the user to quote the primitive recursion axiom. It may, however,
require termination proofs to be performed; fortunately, these need
not be done for primitive recursions.

\subsubsection{Dependent Choice and wellfoundedness}
\label{prim-rec-conseq}

The primitive recursion theorem is useful beyond its main purpose of
justifying recursive definitions. For example, the theory
\theoryimp{prim\_rec} proves the Axiom of Dependent Choice ({\small\verb+DC+}).

\begin{hol}
\index{axiom of dependent choice (DC)@axiom of dependent choice (\ml{DC})}
\begin{verbatim}
   DC  |- !P R a.
            P a /\ (!x. P x ==> ?y. P y /\ R x y)
             ==>
           ?f. (f 0 = a) /\ !n. P (f n) /\ R (f n) (f (SUC n))
\end{verbatim}
\end{hol}

The proof uses {\small\verb+SELECT_AX+}. The theorem {\small\verb+DC+}
is useful when one wishes to build a function having a certain
property from a relation. For example, one way to define the
wellfoundedness of a relation $R$ is to say that it has no infinite
decreasing $R$ chains.
%
\begin{hol}
\index{wellfounded@\ml{wellfounded}}
\begin{verbatim}
   wellfounded_def
     |- wellfounded (R:'a->'a->bool) = ~?f. !n. R (f (SUC n)) (f n)

   WF_IFF_WELLFOUNDED
     |- !R. WF R = wellfounded R
\end{verbatim}
\end{hol}
By use of {\small\verb+DC+}, this statement can be proved
to be equal to the notion of wellfoundedness {\small\verb+WF+}
(namely, that every set has an $R$-minimal element) defined in the theory
\theoryimp{relation}.

Theorems asserting the wellfoundedness of the predecessor relation and
the less-than relation, as well as the wellfoundedness of measure
functions are also proved in \theoryimp{prim\_rec}.

\begin{hol}
\index{WF_PRED@\ml{WF\_PRED}}
\index{WF_LESS@\ml{WF\_LESS}}
\index{measure_def@\ml{measure\_def}}
\index{WF_measure@\ml{WF\_measure}}
\begin{verbatim}
   WF_PRED     |- WF (\x y. y = SUC x)
   WF_LESS     |- WF $<

   measure_def |- measure = inv_image $<
   measure_thm |- !f x y. measure f x y = f x < f y
   WF_measure  |- !m. WF (measure m)
\end{verbatim}
\end{hol}


\subsection{Arithmetic}
\index{arithmetic, the HOL theory of@arithmetic, the \HOL{} theory of}

The \HOL{} theory \theoryimp{arithmetic} contains primitive recursive
definitions of the following standard arithmetic operators.

\begin{hol}
\index{ADD@\ml{ADD}}
\index{SUB@\ml{SUB}}
\index{MULT@\ml{MULT}}
\index{EXP, the HOL constant@\holtxt{EXP}, the \HOL{} constant}
\index{ subtraction, in HOL logic@\holtxt{-} (subtraction, in \HOL{} logic)}
\index{ multiplication, in HOL logic@\holtxt{*} (multiplication, in \HOL{} logic)}
\index{ exponentiation, in HOL logic@\holtxt{**} (exponentiation, in \HOL{} logic)}
\begin{verbatim}
   ADD    |- (!n. 0 + n = n) /\
             (!m n. (SUC m) + n = SUC(m + n))

   SUB    |- (!m. 0 - m = 0) /\
             (!m n. (SUC m) - n = if m < n then 0 else SUC(m - n))

   MULT   |- (!n. 0 * n = 0) /\
             (!m n. (SUC m) * n = (m * n) + n)

   EXP    |- (!m. m EXP 0 = 1) /\
             (!m n. m EXP (SUC n) = m * (m EXP n))
\end{verbatim}
\end{hol}
%
Note that \holtxt{EXP} is an infix. The infix notation
\holtxt{**} may be used in place of \holtxt{EXP}. Thus
(\holtxt{x EXP y}) means $x^y$, and so does (\holtxt{x ** y}).

\paragraph{Comparison operators}

A full set of comparison operators is defined in terms of \verb+<+.

\begin{hol}
\index{ greater than, in HOL logic@\ml{>} (greater than, in \HOL{} logic)}
\index{ less or equal, in HOL logic@\ml{<=} (less or equal, in \HOL{} logic)}
\index{ greater or equal, in HOL logic@\ml{>=} (greater or equal, in \HOL{} logic)}
\begin{verbatim}
   GREATER_DEF    |- !m n. m > n = (n < m)
   LESS_OR_EQ     |- !m n. m <= n = (m < n \/ (m = n))
   GREATER_OR_EQ  |- !m n. m >= n = (m > n \/ (m = n))
\end{verbatim}
\end{hol}

\paragraph{Division and modulus}

A constant specification is used to introduce division ({\small\verb+DIV+}, infix) and
modulus ({\small\verb+MOD+}, infix) operators, together with their
characterizing property.
\begin{hol}
\index{MOD, the HOL constant@\ml{MOD}, the \HOL{} constant}
\index{DIV, the HOL constant@\ml{DIV}, the \HOL{} constant}
\begin{verbatim}
   DIVISION
     |- !n. 0 < n ==> !k. (k = ((k DIV n) * n) + (k MOD n)) /\ (k MOD n) < n
\end{verbatim}
\end{hol}

\paragraph{Even and odd}

The properties of a number being even or odd are defined recursively.
%
\begin{hol}
\index{EVEN, the HOL constant@\ml{EVEN}, the \HOL{} constant}
\index{ODD, the HOL constant@\ml{ODD}, the \HOL{} constant}
\begin{verbatim}
   EVEN |- (EVEN 0 = T) /\ !n. EVEN (SUC n) = ~EVEN n

   ODD  |- (ODD 0 = F) /\ !n. ODD (SUC n) = ~ODD n
\end{verbatim}
\end{hol}

\paragraph{Maximum and minimum}

The minimum and maximum of two numbers are defined in the usual way.
%
\begin{hol}
\index{MIN, the HOL constant@\ml{MIN}, the \HOL{} constant}
\index{MAX, the HOL constant@\ml{MAX}, the \HOL{} constant}
\begin{verbatim}
   MAX_DEF |- !m n. MAX m n = (if m < n then n else m)
   MIN_DEF |- !m n. MIN m n = (if m < n then m else n)
\end{verbatim}
\end{hol}

\paragraph{Factorial}
\index{FACT, the HOL constant@\ml{FACT}, the \HOL{} constant}

The factorial of a number is a primitive recursive definition.
%
\begin{hol}
\begin{verbatim}
   FACT |- (FACT 0 = 1) /\ !n. FACT (SUC n) = SUC n * FACT n
\end{verbatim}
\end{hol}

\paragraph{Function iteration}
\index{FUNPOW, the HOL constant@\ml{FUNPOW}, the \HOL{} constant}

The iterated application $f^n x$ of a function $f : \alpha \to
\alpha$ is defined by primitive recursion. The definition
(\ml{FUNPOW}) is tail-recursive, which can be awkward to reason
about. An alternative characterization (\ml{FUNPOW\_SUC}) may be easier
to apply when doing proofs.
%
\begin{hol}
\begin{verbatim}
   FUNPOW
     |- (!f x. FUNPOW f 0 x = x) /\
        (!f n x. FUNPOW f (SUC n) x = FUNPOW f n (f x))
   FUNPOW_SUC
     |- !f n x. FUNPOW f (SUC n) x = f (FUNPOW f n x)
\end{verbatim}
\end{hol}

\medskip

On this basis, an \adhoc\ but useful collection of over two hundred
and fifty elementary theorems of arithmetic are proved when \HOL{} is
built and stored in the theory \theoryimp{arithmetic}.  For a complete
list of the available theorems, see \REFERENCE.  See also
Section~\ref{sec:while-loops} for discussion of the \holtxt{LEAST}
operator, which returns the least number satisfying a predicate.

\subsubsection{Grammar information}

The following table gives the parsing status of the arithmetic
constants.

\begin{center}
{\small
\begin{tabular}{@{}ccc}
Operator & Strength & Associativity \\ \hline
\holtxt{>=} & 450 & right \\
\holtxt{<=} & 450 & right \\
\holtxt{>} & 450 & right \\
\holtxt{<} & 450 & right \\
\holtxt{+} & 500 & left \\
\holtxt{-} & 500 & left \\
\holtxt{*} & 600& left \\
\holtxt{DIV} & 600 & left \\
\holtxt{MOD} & 650 & left \\
\holtxt{EXP} & 700 & right \\
\end{tabular}}
\end{center}

\subsection{Numerals}\label{numeral}

The type \ml{num}
\index{num, the type in \HOL{} logic@\ml{num}, the type in \HOL{} logic}
is usually thought of as being supplied with an infinite collection of
numerals: \ml{1}, \ml{2}, \ml{3}, \etc.  However, the \HOL{} logic has
no way to define such infinite families of constants; instead, all
numerals other than $0$ are actually built up from the constants
introduced by the following definitions:
\begin{verbatim}
   NUMERAL_DEF |- !x. NUMERAL x = x

   BIT1        |- !n. BIT1 n = n + (n + SUC 0)
   BIT2        |- !n. BIT2 n = n + (n + SUC(SUC 0))

   ALT_ZERO    |- ZERO = 0
\end{verbatim}

\noindent For example, the numeral $5$ is represented by the term
\[
   \ml{NUMERAL}(\ml{BIT1}(\ml{BIT2}\;\ml{ZERO}))
\]
and the \HOL{} parser and pretty-printer make such terms appear as
numerals. This binary representation for numerals allows for
asymptotically efficient calculation. Theorems supporting arithmetic
calculations on numerals can be found in the \theoryimp{numeral}
theory; these are mechanized by the \verb+reduce+ library. Thus,
arithmetic calculations are performed by deductive steps in \HOL.
For example the following calculation of $2 ^{(1023 + 14)/9}$ takes
approximately 70,000 primitive inference steps and returns in two
seconds.
%
\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
- reduceLib.REDUCE_CONV ``2 EXP ((1023 + 14) DIV 9)``;

> val it = |- 2 ** ((1023 + 14) DIV 9) = 41538374868278621028243970633760768
\end{verbatim}
\end{session}

\paragraph {Construction of numerals}
\index{numerals, in HOL logic@numerals, in \HOL{} logic!construction of}

Numerals may of course be built using \ml{mk\_comb}, and taken apart with
\ml{dest\_comb}; however, a more convenient interface to this
functionality is provided by the functions \ml{mk\_numeral},
\ml{dest\_numeral}, and \ml{is\_numeral} (found in the structure
\ml{numSyntax}). These entrypoints make use of an \ML{} structure
\ml{Arbnum} which implements arbitrary precision numbers {\verb+num+}. The
following session shows how \HOL{} numerals are constructed from elements of
type \verb+num+ and how numerals are destructed. The structure
{\small\verb+Arbnum+} provides a full collection of arithmetic
operations, using the usual names for the operations, \eg \verb|+|,
\verb|*|, \verb|-|, \etc.

\begin{session}
\begin{verbatim}
- numSyntax.mk_numeral
     (Arbnum.fromString "3432432423423423234");
> val it = ``3432432423423423234`` : term

- numSyntax.dest_numeral it;
> val it = 3432432423423423234 : num

- Arbnum.+(it,it);
> val it = 6864864846846846468 : num
\end{verbatim}
\end{session}

\paragraph{Numerals and the parser}
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of numerals}
\index{tokens!parsing numerals}
\index{numerals, in HOL logic@numerals, in \HOL{} logic!parsing}
%
Simple digit sequences are parsed as decimal numbers, but the parser
also supports the input of numbers in binary, octal and hexadecimal
notation.  Numbers may be written in binary and hexadecimal form by
prefixing them with the strings \holtxt{0b} and \holtxt{0x} respectively.  The
`digits' A--F in hexadecimal numbers may be written in upper or lower
case.  Binary numbers have their most significant digits left-most. In
the interests of backwards compatibility, octal numbers are not
enabled by default, but if the reference
\ml{base\_tokens.allow\_octal\_input} is set to \ml{true}, then octal
numbers are those that appear with leading zeroes.

Finally, all numbers may be padded with underscore characters
(\ml{\_}).  These can be used to groups digits for added legibility
and have no semantic effect.

Thus
\begin{session}
\begin{verbatim}
- ``0xAA``;
> val it = ``170`` : term

- ``0b1010_1011``;
> val it = ``171`` : term

- base_tokens.allow_octal_input := true;
> val it = () : unit

- ``067``;
> val it = ``55`` : term
\end{verbatim}
\end{session}

\paragraph{Numerals and Peano numbers}

Numerals are related to numbers built from \holtxt{0} and \holtxt{SUC}
via the derived inference rule \ml{num\_CONV}, found in the
\ml{numLib} library.

\begin{boxed}
\index{num_CONV@\ml{num\_CONV}|pin}
\begin{verbatim}
   num_CONV : term -> thm
\end{verbatim}
\end{boxed}

\noindent \ml{num\_CONV} can be used to generate the `\ml{SUC}'
equation for any non-zero numeral.  For example:

\begin{session}
\begin{verbatim}
- load "numLib"; open numLib;

- num_CONV ``2``;
> val it = |- 2 = SUC 1 : thm

- num_CONV ``3141592653``;
> val it = |- 3141592653 = SUC 3141592652 : thm
\end{verbatim}
\end{session}

\noindent The \ml{num\_CONV} function works purely by inference.

\subsubsection{Overloading of arithmetic operators}
\label{arith-overloading}

When other numeric theories are loaded (such as those for the reals or
integers), numerals are overloaded so that the numeral {\small\verb+1+} can
actually stand for a natural number, an integer or a real value. The
parser has a pass of overloading resolution in which it attempts to
determine the actual type to give to a numeral. For example, in the
following session, the theory of integers is loaded, whereupon the
numeral \verb+2+ is taken to be an integer.
%
\begin{session}
\begin{verbatim}
- load "integerTheory";
> val it = () : unit

- ``2``;
<<HOL message: more than one resolution of overloading was possible.>>
> val it = `2` : term

- type_of it;
> val it = `:int` : hol_type
\end{verbatim}
\end{session}

 In order to precisely specify the desired type, the user can use single
character suffixes (`\ml{n}' for the natural numbers, and `\ml{i}' for
the integers):
\begin{session}
\begin{verbatim}
- type_of ``2n``;
> val it = `:num` : hol_type

- type_of ``42i``;
> val it = `:int` : hol_type
\end{verbatim}
\end{session}

A numeric literal for a \HOL{} type other than \verb+num+, such as
\verb+42i+,  is represented by the application of an
\emph{injection} function of type {\small\verb+num -> ty+} to a
numeral. The injection function is different for each type
{\small\verb+ty+}. See Section \ref{integers} for further discussion.

The functions {\verb+mk_numeral+}, {\verb+dest_numeral+}, and
{\verb+is_numeral+} only work for numerals, and not for numeric
literals with character suffixes other than {\small\verb+n+}. For
information on how to install new character suffixes, consult the
\ml{add\_numeral\_info} entry in \REFERENCE.

\subsection{Integers}
\label{integers}
\index{integers, the HOL theory of@integers, the \HOL{} theory of}

There is an extensive theory of integers in \HOL. The type of integers
is constructed as a quotient on pairs of natural numbers. A standard
collection of operators are defined. These are overloaded with
similar operations on the natural numbers, and on the real numbers.
The constants defined in the integer theory include those found in the
following table.

\begin{center}
{\small
\begin{tabular}{@{}cccc}
Constant & Overloaded symbol & Strength & Associativity \\ \hline
{\small\verb+int_ge+} &{\small\verb+>=+} & 450 & right \\
{\small\verb+int_le+} &{\small\verb+<=+} & 450 & right \\
{\small\verb+int_gt+} &{\small\verb+>+}  & 450 & right \\
{\small\verb+int_lt+} &{\small\verb+<+}  & 450 & right \\
{\small\verb+int_add+} &{\small\verb%+%} & 500 & left \\
{\small\verb+int_sub+} &{\small\verb%-%} & 500 & left \\
{\small\verb+int_neg+} &{\small\verb%~%} & 900 & trueprefix \\
{\small\verb+int_mul+} &{\small\verb%*%} & 600 & left \\
{\small\verb%/%} & & 600 & left \\
{\small\verb+%+} & & 650 & left \\
{\small\verb+int_exp+} &{\small\verb%**%} & 700 & right \\
{\small\verb+int_of_num+} &{\small\verb%&%} & & prefix \\
\end{tabular}}
\end{center}

The overloaded symbol {\small\verb+& : num -> int+} denotes the
injection function from natural numbers to integers. The following
session illustrates how overloading and integers literals are treated.

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
Term `1i = &(1n + 0n)`;
> val it = `1 = & (1 + 0)` : term

- show_numeral_types := true;
> val it = () : unit

- Term `&1 = &(1n + 0n)`;
<<HOL message: more than one resolution of overloading was possible.>>
> val it = `1i = & (1n + 0n)` : Term.term
\end{verbatim}
\end{session}


\subsection{Real numbers}
\index{real numbers, the HOL theory of@real numbers, the \HOL{} theory of|(}

There is an extensive collection of theories that make up the
development of real numbers and analysis in HOL, due to John Harrison
\cite{jrh:thesis}. We will only give a sketchy overview of the
development; the interested reader should consult \REFERENCE\ and
Harrison's thesis.

The axioms for the real numbers are derived from the `half reals' which
are constructed from the `half rationals'. This part of the development
is recorded in {\small\verb+hratTheory+} and
{\small\verb+hrealTheory+}, but is not used once the reals have been
constructed. The real axioms are derived in the theory
{\small\verb+realaxTheory+}. A standard collection of operators on the
reals, and theorems about them, is found in {\small\verb+realaxTheory+}
and {\small\verb+realTheory+}. The operators and their parse status are
listed in the following table.

\begin{center}
{\small
\begin{tabular}{@{}cccc}
Constant & Overloaded symbol & Strength & Associativity \\ \hline
{\small\verb+real_ge+} &{\small\verb+>=+} & 450 & right \\
{\small\verb+real_lte+} &{\small\verb+<=+} & 450 & right \\
{\small\verb+real_gt+} &{\small\verb+>+}  & 450 & right \\
{\small\verb+real_lt+} &{\small\verb+<+}  & 450 & right \\
{\small\verb+real_add+} &{\small\verb%+%} & 500 & left \\
{\small\verb+real_sub+} &{\small\verb%-%} & 500 & left \\
{\small\verb+real_neg+} &{\small\verb%~%} & 900 & trueprefix \\
{\small\verb+real_mul+} &{\small\verb%*%} & 600 & left \\
{\small\verb+real_div+} & {\small\verb%/%} & 600 & left \\
{\small\verb+pow+} & &700 & right \\
{\small\verb+real_of_num+} &{\small\verb%&%} & & prefix \\
\end{tabular}}
\end{center}

On the basis of {\small\verb+realTheory+}, the following  sequence of
theories is constructed:

\begin{description}
\item [topology] Topologies and metric spaces, including metric on
the real line.
\item [nets] Moore-Smith covergence nets, and special cases like
sequences.
\item [seq] Sequences and series of real numbers.
\item [lim] Limits, continuity and differentiation.
\item [powser] Power series.
\item [transc] Transcendental functions, \emph{e.g.}, exp, sin,
cos, ln, root, sqrt, pi, tan, asn, acs, atn. Also the Kurzweil-Henstock
gauge integral the fundamental theorem of calculus, and McLaurin's
theorem.

\end{description}
\index{real numbers, the HOL theory of@real numbers, the \HOL{} theory of|)}

\subsection{Probability theory}\label{prob}

A foundational construction of probability theory developed by Joe
Hurd~\cite{hurd-thesis}. First a type of boolean sequences is defined
to model an infinite sequence of coin flips. Next a probability
function is formalized which takes as input a set of boolean
sequences, and returns a real number between 0 and 1. Unfortunately
not all sets can be assigned a probability (the Banach-Tarski
paradox), rather the sets that can be assigned a probability are
called \emph{measurable sets}, and this is also formalized in the
HOL theory.

Building on this foundation, the probability theory is used to define
a sampling function that takes an infinite sequence of coin flips and
a positive integer $N$, and returns an integer $n$ in the range $0\le
n < N$, picked uniformly at random from the available choices. This
sampling function for the uniform distribution is later used to verify
the Miller-Rabin primality test.


\subsection{Theories of $n$-bit words}
\index{n-bit words, the HOL theory of@$n$-bit words, the \HOL{} theory of|(}

{
\newcommand{\bitwise}{\ensuremath\mathtt{BITWISE}}
\newcommand{\slice}{\ensuremath\mathtt{SLICE}}
\newcommand{\bits}{\ensuremath\mathtt{BITS}}
\newcommand{\minn}{\ensuremath\mathtt{MIN}}
\newcommand{\bit}{\ensuremath\mathtt{BIT}}
\newcommand{\suc}{\ensuremath\mathtt{SUC}}
\newlength{\entrysize}
\newcommand{\cdotfill}{\hspace*{\fill}\ensuremath{\cdots}\hspace*{\fill}}

\HOL{} provides support for reasoning about natural numbers as
fixed-width bit strings.  This is done with a special executable
called \ml{mkword.exe}, which makes $n$-bit numbers available.  For
example, \ml{mkword.exe~16} builds the theory \theoryimp{word16},
which defines the type \holtxt{word16}, and all of the appropriate
operations on that type.  Such types are prevalent in computer
architectures where, for example, one might find: bytes/octets
(\ml{word8}), half-words (\ml{word16}), words (\ml{word32}) and
long-words (\ml{word64}).

Another theory of words in \HOL{}, Wai Wong's \theoryimp{word} theory,
is more generic.  It supports words with differing number bases and
word lengths~\cite{wong}.  The underlying data type for that theory is
the list: the theory was developed on top of Paul Curzon's
\ml{rich\_list} theory.  However, \HOL's type system does not directly
support predicate sub-types and so, when using the theory, word
lengths must be explicitly declared with the insertion of predicates.

In the \theoryimp{word$\langle{}n\rangle$} theories, $n$-bit words are
represented as equivalence classes of natural numbers, \ie{} sets of
numbers equivalent modulo $2^n$.  This has been implemented in \HOL{}
via an \ML{} functor which makes use of the system's equivalence type
package.  Each theory instance is for a \emph{fixed} word size---this
works well provided that only a small selection of word sizes are
required.  Word operations and theorems are lifted from the
representing type \ie{} from natural number operations.  Consequently,
the word operations are naturally and concisely defined.  Natural
number theorems and reductions are used in proving word theorems and
for ground-term (variable free) evaluation.

\paragraph{Generating a word theory}

\index{mkword.exe executable@\ml{mkword.exe} executable}
\index{n-bit words, the HOL theory of@$n$-bit words, the \HOL{} theory of!generating instances of}
The executable \ml{mkword.exe} in the \ml{n\_bit} library constructs a
word theory for a given word length.\footnote{The word length cannot
  be zero.}  This command creates \ml{Theory.sml} and \ml{Lib.sml}
files with the prefix \ml{word$\langle{}n\rangle$} in the working
directory and these sources are then compiled. When the \ml{-sys}
option is selected the object files are copied to the \ml{SIGOBJ}
directory.\footnote{However, there will not be an on-line help entry
  for the new theory.}  The word theory does not have a script file
and so \ml{Holmake} does not automatically update these theories \eg{}
when \HOL\ is re-built.  The easiest way to manage this is to use a
\ml{Holmakefile} which includes the necessary calls to
\ml{mkword.exe}, as in the sample file \ml{Holmakefile.example-32}, in
the directory \ml{<holdir>/src/n\_bit/help}.


\subsubsection{Bits}
\label{bits}

The most basic theory in the library is the theory \ml{bits} -- this
theory defines some bit operations over the natural numbers and is
used in defining some $n$-bit word operations.  (No new data types are
provided by this theory, and it does not need to be built by the
\ml{mkword.exe} executable.)  The main functions are: \holtxt{BITS},
\holtxt{SLICE}, \holtxt{BIT} and \holtxt{BITWISE}.  These are defined
using operations from the theory \theoryimp{arithmetic}; in
particular, \holtxt{DIV}, \holtxt{MOD} and \holtxt{EXP}.  The
predicate \holtxt{BIT n b} is true if, and only if, the bit $n$ of
number $b$ has value one.  The other operations are illustrated in
Figures~\ref{bits-slice} and~\ref{bitwise}.
\index{BITS, the HOL constant@\holtxt{BITS}, the \HOL{} constant}%
\index{SLICE, the HOL constant@\holtxt{SLICE}, the \HOL{} constant}%
\index{BIT, the HOL constant@\ml{BIT}, the \HOL{} constant}%
\index{BITWISE, the HOL constant@\ml{BITWISE}, the \HOL{} constant}%

\begin{figure}
\begin{center}
\input{figs/bits.tex} \\[3mm]
(a) \ml{BITS h l b}. \\[6mm]
\input{figs/slice.tex} \\[3mm]
(b) \ml{SLICE h l b}.
\end{center}
\caption{Bit field functions.\label{bits-slice}}
\end{figure}

\begin{figure}
\begin{center}
\input{figs/bitw.tex}
\end{center}
\caption{\ml{BITWISE l f a b}. Here $x\diamond y = (f(x)(y) \Rightarrow 1 \mid 0)$.\label{bitwise}}
\end{figure}

The \ml{numeral\_bits} theory provides a group of theorems that allow
the \ml{bits} theory functions to be evaluated more efficiently.  This
is done by working with \HOL's internal representation of numerals
\ie{} in terms of \holtxt{ZERO}, \holtxt{BIT1} and \holtxt{BIT2}.

Some of the most significant (useful) theorems in \ml{bits} theory are presented below:\begin{eqnarray*}
\mathtt{SLICE\_THM} & \vdash & \forall n\,h\,l.\ \;\slice\ h\ l\ n = (\bits\ h\ l\ n) * 2^l \\[4pt]
\mathtt{BITS\_COMP\_THM2} & \vdash & \forall h_1\,l_1\,h_2\,l_2\,n.\\*
&& \ \bits\ h_2\ l_2\ (\bits\ h_1\ l_1\ n) = \bits\ (\minn\ h_1\ (h_2 + l_1))\ (l_2 + l_1)\ n \\[4pt]\mathtt{SLICE\_COMP\_THM} & \vdash &
   \forall h\,m\,l\,n.\ \;\suc(m) \leq h \mbox{ and } l \leq m \Rightarrow \\*
&& \quad (\slice\ h\ (\suc\ m)\ n + \slice\ m\ l\ n = \slice\ h\ l\ n) \\[4pt]
\mathtt{SLICE\_COMP\_THM2} & \vdash &
   \forall h_2\,l_2\,h_1\,l_1\,n.\ \; h_2 \leq h_1 \mbox{ and } l_1 \leq l_2 \Rightarrow \\*&& \quad (\slice\ h_2\ l_2\ (\slice\ h_1\ l_1\ n) = \slice\ h_2\ l_2\ n) \\[4pt]
\mathtt{BITWISE\_THM} & \vdash &   \forall x\,n\,f\,a\,b.\ \;
        x < n \Rightarrow \\*
&& \quad (\bit\ x\ (\bitwise\ n\ f\ a\ b) = f\ (\bit\ x\ a)\ (\bit\ x\ b))
\end{eqnarray*}

\noindent
The theorem \ml{SLICE\_THM} shows that \ml{SLICE} is a shifted version
of \ml{BITS}.  The theorems \ml{BITS\_COMP\_THM2} and
\ml{SLICE\_COMP\_THM2} are used in simplifying repeated applications
of \ml{BITS} and \ml{SLICE}.  The theorem \ml{SLICE\_COMP\_THM} shows
that adjoining slices of the same number can be combined into a single
slice.  Finally, theorem \ml{BITWISE\_THM} shows that every bit in the
result of a \ml{BITWISE} operations is the expected single-bit
function of the corresponding bits in the arguments.

%% Section~\ref{mkword} shows how to build a word theory for a given word
%% length.  The construction of the word type is described in
%% Section~\ref{type}.  Word constants and operations are discussed in
%% Section~\ref{ops} -- this includes: maps to/from the natural numbers;
%% bit field, arithmetic and Boolean operations; as well as orderings and
%% shifts.  Ground term evaluation and pretty printing are discussed in
%% Section~\ref{eval}, and finally Section~\ref{multiple} shows how to
%% work with multiple word sizes.


\subsubsection{The word type---constants and operations} \label{type}

The word type is declared in \HOL{} using the function
\ml{define\_equivalence\_type}, which is in the library
\ml{quotient}.  The following equivalence relation is used to
construct the word type:
\[ a \equiv b = (a \bmod 2^\ell = b \bmod 2^\ell) \]
where $\ell$ is the word length.  One can observe that this relation
is reflexive, symmetric and transitive.  The \emph{representing type}
for words is $\mathtt{num}\rightarrow\mathtt{bool}$ \ie{} words are
represented by the $2^\ell$ unique predicates ${\equiv_a}$ where
${\equiv_a}(b) = (a \equiv b)$.  That is, one can consider the
predicate ${\equiv_i}$ to be representing the $\ell-bit$ word with
value $i \bmod 2^\ell$.  Observe that for all $j$ and $i < 2^\ell$:
${\equiv_{j\cdot 2^\ell + i}} = {\equiv_i}$.

The \HOL\ constant \ml{WL} is equal to the word length $\ell$ and
\ml{HB} is the highest bit position, that is, $\ell - 1$.

\paragraph{Mapping To and From the Natural Numbers}

The function \ml{w2n} maps a word to a natural number; when given a
word represented by the predicate ${\equiv_i}$ the value returned is
$i \bmod 2^\ell$ -- this is the \emph{standard class representative}
for the equivalence class.  The function \ml{n2w} maps a natural
numbers to a word: for number $i$ the returned word has representative
${\equiv_i}$.

The map \ml{n2w} is the primary means of constructing new words and
word operations are evaluated via natural number reductions; see
Section~\ref{eval}.

\paragraph{Bits and Slices}

The map \ml{w2n} is used to define the functions: \ml{WORD\_BITS},
\ml{WORD\_BIT} and \ml{WORD\_SLICE}.  The word is mapped to a natural
number before applying the corresponding function from
Section~\ref{bits}.  The predicates \ml{LSB} and \ml{MSB} specialise
\ml{WORD\_BIT} to bit positions zero and $\ell - 1$ respectively.

\paragraph{Arithmetic and Orderings}

Addition, negation (two's complement), subtraction and multiplication
are all provided.  The two's complement maps ${\equiv_i}$ to
${\equiv_{2^\ell - (i \bmod 2^\ell)}}$ and subtraction is the addition
of the two's complement.

Eight orderings are provided: these are signed and unsigned versions
of $<$, $\leq$, $>$ and $\geq$.  The unsigned versions are suffixed by
a full-stop; for example, \ml{<.} is unsigned less than.  The signed
versions are for the two's complement representation \ie{} where bit
$\ell - 1$ is taken to have value $-2^\ell$.  (At present, maps to and
from the integers have not been provided.)  The orderings are defined
using the function \ml{CMP\_NZCV} -- this subtracts one word from
another and returns the negative, zero, carry and overflow flag
values.  For example, \ml{a <.\ b} is true when the carry flag for
\ml{a - b} is false.  A group of theorems are provided to connect
these orderings with their natural number counterparts; for example,
\ml{LO\_EVAL} (see Section~\ref{eval}).

\paragraph{Shifts}

Six types of shifting are supported: logical shift left (which is
synonymous with arithmetic shift left), rotate left and four types of
shift right.  Shifting left $i$ places is defined to be multiplication
by the word with value $2^i$.  Rotating left $i$ places can be achieved
by rotating right $\ell - i$ places.  Figure~\ref{right-one} shows the
natural number (one place) shift operations upon which the word shift
rights are based: these are lifted to words, giving the operations
\ml{word\_ror1}, \ml{word\_lsr1}, \ml{word\_asr1} and \ml{RRX}.  The
first three operations can be iterated and this gives the operations:
rotate right (\ml{\#>>}), logical shift right (\ml{>>>}) and
arithmetic shift right (\ml{>>}).  The theorems \ml{ROR\_THM},
\ml{LSR\_THM} and \ml{ASR\_THM} provide a more helpful semantics for
these operations; they are especially useful for ground-term
evaluation, see Section~\ref{eval}.

\begin{figure}
\begin{center}
\setlength{\entrysize}{7.5mm}
\input{figs/ror.tex} \\[3mm]
(a) Rotate right (\ml{ROR\_ONE}). \\[6mm]
\input{figs/lsr.tex} \\[3mm]
(b) Logical shift right (\ml{LSR\_ONE}). \\[6mm]
\input{figs/asr.tex} \\[3mm]
(c) Arithmetic shift right (\ml{ASR\_ONE}). \\[6mm]
\input{figs/rrx.tex} \\[3mm]
(d) Rotate right with extend (\ml{RRXn c}).
\end{center}
\caption{One place shift right operations.\label{right-one}}
\end{figure}

\paragraph{Boolean Operations}

The one's complement (bitwise bit inversion) is given by the function
\ml{NOT} and this maps ${\equiv_i}$ to ${\equiv_{2^\ell -1 - (i \bmod
    2^\ell)}}$.  Bitwise conjunction (\ml{\&}), disjunction (\ml{|})
and exclusive-or (\ml{\#}) are also defined.  These operations are
lifted versions of the function \ml{BITWISE} specialised to the word
length $\ell$ and with the appropriate Boolean operation.

\paragraph{Word Constants}

The following table shows the values for some pre-defined word constants:
\begin{center}
\small
\begin{tabular}{cc}
Constant & Numeric Value \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\ml{word\_{}0} & $0$ \\
\ml{word\_{}1} & $1$ \\
\ml{word\_T} & $2^\ell - 1$ \\
\ml{word\_L} & $2^{\ell - 1}$ \\
\ml{word\_H} & $2^{\ell - 1} - 1$
\end{tabular}
\end{center}

The constant \ml{word\_T} represents `true' for the Boolean operations
-- every bit is set high.  Likewise, \ml{word\_{}0} represents the
number zero and also `false'.  In the two's complement system
\ml{word\_L} is the most negative value and \ml{word\_H} is the most
positive value.  This is captured in the theorems \ml{WORD\_L\_LESS\_EQ}
and \ml{WORD\_LESS\_EQ\_H}.

\paragraph{Table of Operators}

The strength and associativity of the word operations are as follows:
\begin{center}
\small
\begin{tabular}{lccc}
Constant & (Overloaded) Symbol & Strength & Associativity \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\ml{word\_lt} & \ml{<} & 450 & right \\
\ml{word\_le} & \ml{<=} & 450 & right \\
\ml{word\_gt} & \ml{>} & 450 & right \\
\ml{word\_ge} & \ml{>=} & 450 & right \\
\ml{word\_lo} & \ml{<.} & 450 & right \\
\ml{word\_ls} & \ml{<=.} & 450 & right \\
\ml{word\_hi} & \ml{>.} & 450 & right \\
\ml{word\_hs} & \ml{>=.} & 450 & right \\
\ml{word\_add} & \ml{+} & 500 & left \\
\ml{word\_sub} & \ml{-} & 500 & left \\
\ml{word\_mul} & \ml{*} & 550 & left \\
\ml{bitwise\_or} & \ml{|} & 625 & left \\
\ml{bitwise\_eor} & \ml{\#} & 625 & left \\
\ml{bitwise\_and} & \ml{\&} & 650 & left \\
\ml{word\_lsl} & \ml{<<} & 680 & left \\
\ml{word\_lsr} & \ml{>>>} & 680 & left \\
\ml{word\_asr} & \ml{>>} & 680 & left \\
\ml{word\_ror} & \ml{\#>>} & 680 & left \\
\ml{word\_{}1comp} & \ml{NOT} & 900 & trueprefix \\
\ml{word\_{}2comp} & \verb"~" & 900 & trueprefix \\
\end{tabular}
\end{center}

\subsubsection{Evaluation and Pretty Printing} \label{eval}

The conversion \ml{WORD\_CONV} can be used to evaluate word
expressions; it uses re-write theorems for word
terms containing the map \ml{n2w}.  For example, word addition and
unsigned less-than can be evaluated using the theorems:

\begin{hol}
\begin{verbatim}
   ADD_EVAL |- !a b. n2w a + n2w b = n2w (a + b)
    LO_EVAL |- !m n. n2w m <. n2w n = MOD_2EXP WL m < MOD_2EXP WL n
\end{verbatim}
\end{hol}

\noindent Natural number reductions are used to evaluate the right-hand side.
When entering numeral values, the suffix \ml{w} denotes a word and the
prefixes \ml{0x}, \ml{0} and \ml{0b} denote hexadecimal, octal and binary values.
This is illustrated for eight bit words in the session below.

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
- load "word8Lib";
- open word8Lib;
> ..
- WORD_CONV ``250w + 0b1000w``;
> val it = |- 250w + 8w = 2w : thm
- WORD_CONV ``21w <. 56w``;
> val it = |- 21w <. 56w = T : thm
\end{verbatim}
\end{session}

The shift right operations are evaluated efficiently by using theorems
that express the result in term of \ml{BITS}.  This ensures that the
run-time is still quick when shifting by a large value.

\begin{session}
\begin{verbatim}
- time WORD_CONV ``14w #>> 100001``;
runtime: 0.020s,    gctime: 0.010s,     systime: 0.000s.
> val it = |- 14w #>> 100001 = 7w : thm
\end{verbatim}
\end{session}

\index{printing, in HOL logic@printing, in \HOL{} logic!of n-bit word values@of $n$-bit word values}
It is possible to display word values as signed (two's complement)
decimals or as signed or unsigned binary, octal or hexadecimal
numbers.  The pretty printing directives are listed in \REFERENCE.
These functions are helpful when checking the results of computations.
\begin{session}
\begin{verbatim}
- pp_word_unsigned_bin();
> val it = () : unit
- WORD_CONV ``219w #>> 5``;
> val it = |- 0b11011011w #>> 5 = 0b11011110w : thm
- pp_word_signed_dec();
> val it = () : unit
- WORD_CONV ``20w - 24w``;
> val it = |- 20w - 24w = ~4w : thm
\end{verbatim}
\end{session}

\noindent Pretty printing can be turned off using the function \ml{pp\_word\_off}.

\subsubsection{Working with Multiple Word Sizes} \label{multiple}

The executable \ml{mkword.exe} can be run as many times as is needed,
generating theories for different word sizes.  If multiple word
theories are opened then one has to ensure that the operator
overloading is resolved correctly.  The session below shows how to do
this by declaring the type of a variable, or by using the theory
names.  These methods are also required when opening other theories;
for example \ml{arithmetic} and \ml{integer}.

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
- open word8Theory word4Theory;
- val _ = show_types := true;

- ``a + b``;
<<HOL message: more than one resolution of overloading was possible>>
> val it = ``(a :word4) + (b :word4)`` : term

- ``(a:word8) + b``;
> val it = ``(a :word8) + (b :word8)`` : term

- ``word8$word_add a b``;
> val it = ``(a :word8) + (b :word8)`` : term

- WORD_SUB_SUB;
> val it = |- !(a :word4) (b :word4) (c :word4). a - (b - c) = a + c - b : thm

- word8Theory.WORD_SUB_SUB;
> val it = |- !(a :word8) (b :word8) (c :word8). a - (b - c) = a + c - b : thm
\end{verbatim}
\end{session}

It is possible to define concatenation and casting functions by first
mapping words to the natural numbers using \ml{w2n} and then
constructing words with \ml{n2w}.  The function \ml{SIGN\_EXTEND} is
provided in \ml{bits} theory to make it easier to define two's
complement conversions.
\begin{session}
\begin{verbatim}
- show_types:=false;
> val it = () : unit

- app load ["word8Lib","word4Lib"];
> val it = () : unit

- word4Lib.pp_word_unsigned_bin();
> val it = () : unit

- word8Lib.pp_word_unsigned_bin();
> val it = () : unit

- word4Lib.WORD_CONV ``word8$n2w (SIGN_EXTEND 4 8 (w2n (n2w 12)))``;
<<HOL message: more than one resolution of overloading was possible>>
> val it = |- n2w (SIGN_EXTEND 4 8 (w2n 0b1100w)) = 0b11111100w : thm
\end{verbatim}
\end{session}

\index{n-bit words, the HOL theory of@$n$-bit words, the \HOL{} theory of|)}
} % matches bracket at beginning of n-bit section, where some n-bit
  % specific macros are defined

\section{Sequences}

\HOL{} provides theories for various kinds of sequences: finite lists, lazy lists,
paths, and finite strings.

\subsection{Lists}\label{avra_list}
\index{list, the type operator in HOL logic@\ml{list}, the type operator in \HOL{} logic}
\index{types, in HOL logic@types, in \HOL{} logic!tools for construction of}
\index{lists, the HOL theory of@lists, the \HOL{} theory of|(}
\index{ lists, the HOL theory of@\ml{[} $\cdots$ \ml{;} $\cdots$ \ml{]} (lists, the \HOL{} theory of)|(}

\HOL{} lists are inductively defined finite sequences where each
element in a list has the same type. The theory \ml{list} introduces
the unary type operator $\alpha \; \konst{list}$ by a type definition
and a standard collection of list processing functions are
defined. The primitive constructors {\small\verb+NIL+} and {\small\verb+CONS+}
%
\begin{hol}
\index{NIL, the HOL constant@\holtxt{NIL}, the \HOL{} constant}
\index{CONS, the HOL constant@\holtxt{CONS}, the \HOL{} constant}
\begin{verbatim}
   NIL  : 'a list
   CONS : 'a -> 'a list -> 'a list
\end{verbatim}
\end{hol}
%
are used to build lists and have been defined from the representing type for
lists. The \HOL{} parser
%
\index{parsing, of HOL logic@parsing, of \HOL{} logic!of list expressions}
%
has been specially modified to parse the expression \holtxt{[]} into
\holtxt{NIL}, to parse the expression \holtxt{h::t} into \holtxt{CONS
  h t}, and to parse the expression \holtxt{[$t_1$;$t_2$;\dots;$t_n$]}
into \holtxt{CONS $t_1$ (CONS $t_2$ $\cdots$ (CONS $t_n$ NIL)
  $\cdots$)}.  The \HOL{} printer
%
\index{printing, in HOL logic@printing, in \HOL{} logic!of list expressions}
%
reverses these transformations.

Based on the inductive characterization of the type, the following
fundamental theorems about lists
\index{list theorems, in HOL logic@list theorems, in \HOL{} logic|(}
are proved and stored in the theory \ml{list}.

\begin{hol}
\index{list_Axiom@\ml{list\_Axiom}}
\index{axioms!non-primitive, of HOL logic@non-primitive, of \HOL{} logic}
\index{induction theorems, in HOL logic@induction theorems, in \HOL{} logic!for lists}
\index{characterizing theorem!for lists}
\begin{verbatim}
   list_Axiom
     |- !x f. ?fn. (fn [] = x) /\ (!h t. fn (h::t) = f(fn t)h t)
   list_INDUCT
     |- !P. P [] /\ (!t. P t ==> (!h. P(h::t))) ==> (!l. P l)
   list_CASES
     |- !l. (l = []) \/ (?t h. l = h::t)
   CONS_11
     |- !h t h' t'. (h::t = h'::t') = (h = h') /\ (t = t')
   NOT_NIL_CONS
     |- !h t. ~([] = h::t)
   NOT_CONS_NIL
     |- !h t. ~(h::t = [])
\end{verbatim}
\end{hol}

The theorem \ml{list\_Axiom} shown above is analogous to the primitive
recursion theorem
%
\index{primitive recursion theorem!for lists}
%
on the natural numbers discussed above in Section~\ref{num-prim-rec}.
It states the validity of primitive recursive definitions on lists,
and can be used to justify any such definition.  The \ML{} function
\ml{new\_recursive\_definition} uses this theorem to do
automatic
%
\index{primitive recursion theorem!automated use of, in HOL system@automated use of, in \HOL{} system|)}
%
proofs of the existence of primitive recursive functions on lists and
then make constant specifications to introduce constants that denote
such functions.

The induction theorem for lists, \ml{list\_INDUCT}, provides the main
proof tool used to reason about operations that manipulate lists. The
theorem \ml{list\_CASES} is used to perform case analysis on whether a
list is empty or not.

The theorem {\small\verb+CONS_11+} shows that {\small\verb+CONS+} is injective;
the theorems {\small\verb+NOT_NIL_CONS+} and {\small\verb+NOT_CONS_NIL+} show that
{\small\verb+NIL+} and {\small\verb+CONS+} are distinct, \ie,
cannot give rise to the same structure. Together, these three theorems
are used for equational reasoning about lists.

The predicate \ml{NULL} and the selectors
%
\index{selectors, in HOL logic@selectors, in \HOL{} logic!for lists}
%
\ml{HD} and \ml{TL} are defined in the theory \theoryimp{list} by
%
\begin{hol}
\index{NULL, the HOL constant@\ml{NULL}, the \HOL{} constant}
\index{HD, the HOL constant@\ml{HD}, the \HOL{} constant}
\index{TL, the HOL constant@\ml{TL}, the \HOL{} constant}
\begin{verbatim}
   NULL |- NULL [] /\ (!h t. ~NULL(h::t))
   HD   |- !h t. HD(h::t) = h
   TL   |- !h t. TL(h::t) = t
\end{verbatim}
\end{hol}

\noindent The following functions on lists are also defined in the theory \ml{list}.
%
%
\paragraph{Case expressions}

Compound \HOL{} expressions that branch based on whether a term is an
empty or non-empty list have the surface syntax (roughly borrowed from
ML)
\begin{hol}
\begin{verbatim}
   case e1
    of [] -> e2
    || (h::t) -> e3
\end{verbatim}
\end{hol}
%
Such an expression is translated to
$\konst{list\_case}\ e_2\ (\lambda h\; t.\ e_3)\ e_1$ where the constant
{\small\verb+list_case+} is defined as follows:
\begin{hol}
\begin{verbatim}
   list_case_def
     |- (!v f. list_case v f [] = v) /\
        (!v f a0 a1. list_case v f (a0::a1) = f a0 a1)
\end{verbatim}
\end{hol}

\paragraph{List membership}
\index{MEM, the HOL constant@\ml{MEM}, the \HOL{} constant}

Membership in a list, \ml{MEM}, is defined as follows:
%
\begin{hol}
\begin{verbatim}
   MEM |- (!x. MEM x [] = F) /\
          (!x h t. MEM x (h::t) = (x = h) \/ MEM x t)
\end{verbatim}
\end{hol}

\paragraph {Concatenation of lists}
\index{APPEND, the HOL constant@\ml{APPEND}, the \HOL{} constant}
\index{concatenation, of lists!in HOL logic@in \HOL{} logic}
\index{FLAT, the HOL constant@\ml{FLAT}, the \HOL{} constant}

Binary list concatenation ({\small\verb+APPEND+}) may also be denoted by
the infix operator {\small\verb|++|}; thus the expression
{\small\verb|L1 ++ L2|} is translated into {\small\verb+APPEND L1 L2+}.
The concatenation of a list of lists into a list is achieved by
{\small\verb+FLAT+}.
%
\begin{hol}
\begin{verbatim}
   APPEND
     |- (!l. APPEND [] l = l) /\
        (!l1 l2 h. APPEND (h::l1) l2 = h::APPEND l1 l2)
   FLAT
     |- (FLAT [] = []) /\ (!h t. FLAT(h::t) = h ++ FLAT t)
\end{verbatim}
\end{hol}

\paragraph {Numbers and lists}
\index{LENGTH, the HOL constant@\ml{LENGTH}, the \HOL{} constant}
\index{EL, the HOL constant@\ml{EL}, the \HOL{} constant}
\index{list_size, the HOL constant@\ml{list\_size}, the \HOL{} constant}

The length (\holtxt{LENGTH}) and size (\holtxt{list\_size}) of a list
are suported notions. The size of a list takes account of the size of
each element of the list (given by parameter
$f:\alpha\to\konst{num}$), while the length of the list ignores the
size of each list element. The alternate length definition
(\holtxt{LEN}) is tail-recursive.
%
\begin{hol}
\begin{verbatim}
   LENGTH
     |- (LENGTH [] = 0) /\ (!h t. LENGTH (h::t) = SUC(LENGTH t))
   LEN_DEF
     |- (!n. LEN [] n = n) /\ !h t n. LEN (h::t) n = LEN t (n + 1)
   list_size_def
     |- (!f. list_size f [] = 0) /\
        !f a0 a1. list_size f (a0::a1) = 1 + (f a0 + list_size f a1))
   EL
     |- (!l. EL 0 l = HD l) /\ (!l n. EL (SUC n) l = EL n (TL l))
\end{verbatim}
\end{hol}

\noindent
Note that the extraction of the $n$th element (\holtxt{EL}) of a
list starts its indexing from 0.

\paragraph {Mapping functions over lists}
\index{MAP, the HOL constant@\ml{MAP}, the \HOL{} constant}
\index{MAP2, the HOL constant@\ml{MAP2}, the \HOL{} constant}
\index{mapping functions, in the HOL logic@mapping functions, in the \HOL{} logic!for lists}

There are functions for mapping a function $f : \alpha \to \beta$ over
a single list (\holtxt{MAP}) or a function $f : \alpha \to \beta
\to \gamma$ over two lists (\holtxt{MAP2}).
\begin{hol}
\begin{verbatim}
   MAP
     |- (!f. MAP f [] = []) /\
        (!f h t. MAP f (h::t) = f h::MAP f t)
   MAP2
     |- (!f. MAP2 f [] [] = []) /\
        !f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2
\end{verbatim}
\end{hol}
The behaviour of \holtxt{MAP2} in the cases when it is given lists of
unequal lengths is unspecified.

\paragraph {Predicates over lists}
\index{FILTER, the HOL constant@\ml{FILTER}, the \HOL{} constant}
\index{EVERY, the HOL constant@\ml{EVERY}, the \HOL{} constant}
\index{ALL_DISTINCT, the HOL constant@\ml{ALL\_DISTINCT}, the \HOL{} constant}
\index{EXISTS, the HOL constant (over lists)@\ml{EXISTS}, the \HOL{}
  constant (over lists)}

Predicates can be applied to lists in a universal sense (the predicate
must hold of every element in the list) or an existential sense (the
predicate must hold of some element in the list). This functionality
is supported by \holtxt{EVERY} and \holtxt{EXISTS}, respectively. The
elimination of all elements in list not satisfying a given predicate
is performed by \holtxt{FILTER}.
\begin{hol}
\begin{verbatim}
   EVERY_DEF
     |- (!P. EVERY P [] = T) /\
        (!P h t. EVERY P (h::t) = P h /\ EVERY P t)
   EXISTS_DEF
     |- (!P. EXISTS P [] = F) /\
        (!P h t. EXISTS P (h::t) = P h \/ EXISTS P t)
   FILTER
     |- (!P. FILTER P [] = []) /\
        (!P h t. FILTER P (h::t) = if P h then h::FILTER P t else FILTER P t)
   ALL_DISTINCT
     |- (ALL_DISTINCT [] = T) /\
        (!h t. ALL_DISTINCT (h::t) = ~MEM h t /\ ALL_DISTINCT t)
\end{verbatim}
\end{hol}
The predicate \holtxt{ALL\_DISTINCT} holds on a list just in case no
element in the list is equal to any other.

\paragraph {Folding}
\index{FOLDL, the HOL constant@\ml{FOLDL}, the \HOL{} constant}
\index{FOLDR, the HOL constant@\ml{FOLDR}, the \HOL{} constant}

Applying a binary function $f : \alpha\to\beta\to\beta$ pairwise
through a list and accumulating the result is known as
\emph{folding}. At times, it is necessary to do this operation
from left-to-right (\holtxt{FOLDL}), and at others the
right-to-left direction (\holtxt{FOLDR}) is required.
\begin{hol}
\begin{verbatim}
   FOLDL
     |- (!f e. FOLDL f e [] = e) /\
        (!f e x l. FOLDL f e (x::l) = FOLDL f (f e x) l)
   FOLDR
     |- (!f e. FOLDR f e [] = e) /\
        (!f e x l. FOLDR f e (x::l) = f x (FOLDR f e l))
\end{verbatim}
\end{hol}

\paragraph {List reversal}

The reversal of a list (\holtxt{REVERSE}) and its tail recursive
counterpart \holtxt{REV} are defined in \theoryimp{list}.
\begin{hol}
\begin{verbatim}
   REVERSE_DEF
     |- (REVERSE [] = []) /\
        (!h t. REVERSE (h::t) = REVERSE t ++ [h])
   REV_DEF
     |- (!acc. REV [] acc = acc) /\
        (!h t acc. REV (h::t) acc = REV t (h::acc))
\end{verbatim}
\end{hol}

\paragraph {Conversion to sets}

Lists can be converted to sets (\ml{LIST\_TO\_SET}) by partial
application of \holtxt{MEM}. The somewhat terse definition is used to
derive the theorem \ml{IN\_LIST\_TO\_SET}.
%
\begin{hol}
\begin{verbatim}
  LIST_TO_SET
    |- LIST_TO_SET = combin$C MEM
  IN_LIST_TO_SET
    |- x IN LIST_TO_SET l = MEM x l
\end{verbatim}
\end{hol}
%
Further support for translating between different kinds of
collections may be found in the \theoryimp{container} theory.

\paragraph {Pairs and lists}

Two lists of equal length may be component-wise paired by
the {\small\verb+ZIP+} operation. The result is unspecified
when the lists are not the same length. The inverse operation,
{\small\verb+UNZIP+}, translates a list of pairs into a pair of
lists.
\begin{hol}
\begin{verbatim}
  ZIP
    |- (ZIP ([],[]) = []) /\
       (!x1 l1 x2 l2. ZIP (x1::l1,x2::l2) = (x1,x2)::ZIP (l1,l2))
  UNZIP_THM
    |- (UNZIP [] = ([],[])) /\
       (UNZIP ((x,y)::t) = let (L1,L2) = UNZIP t in (x::L1,y::L2))
\end{verbatim}
\end{hol}

\paragraph {Alternate access}
\index{LAST, the HOL constant@\ml{LAST}, the \HOL{} constant}
\index{FRONT, the HOL constant@\ml{FRONT}, the \HOL{} constant}
%
Lists are essentially treated in a stack-like manner. However, at
times it is convenient to access the last element
(\holtxt{LAST}) of a non-empty list directly. The last element
of a non-empty list is dropped by \holtxt{FRONT}.
\begin{hol}
\begin{verbatim}
  LAST_DEF
    |- !h t. LAST (h::t) = if t = [] then h else LAST t
  FRONT_DEF
    |- !h t. FRONT (h::t) = if t = [] then [] else h::FRONT t
  APPEND_FRONT_LAST
    |- !l. ~(l = []) ==> (FRONT l ++ [LAST l] = l)
\end{verbatim}
\end{hol}
%
Joining the front part and the last element of a non-empty list yields
the original list.  Both \holtxt{LAST} and \holtxt{FRONT}
are unspecified on empty lists.

\vspace{1ex}
\noindent For a complete list of available theorems in
\theoryimp{list}, see \REFERENCE.  Further development of list
theory can be found in \theoryimp{rich\_list}.

\subsubsection{List permutations and sorting}
\index{permutations (of lists), the HOL theory of@permutations (of lists), the \HOL{} theory of}
\index{sorting, the HOL theory of@sorting, the \HOL{} theory of}

The \theoryimp{sorting} theory defines a notion of two lists being
permutations of each other, then defines a general notion of sorting,
then shows that Quicksort is a sorting function.

\paragraph{List permutation}

Two lists are in permutation if they have exactly the same members,
and each member has the same number of occurrences in both lists. One
definition (\holtxt{PERM}) that captures this relationship is the
following:
%
\begin{hol}
\begin{verbatim}
   PERM_DEF
     |- !L1 L2. PERM L1 L2 = !x. FILTER ($= x) L1 = FILTER ($= x) L2
   PERM_IND =
     |- !P.
          P [] [] /\
          (!x l1 l2. P l1 l2 ==> P (x::l1) (x::l2)) /\
          (!x y l1 l2. P l1 l2 ==> P (x::y::l1) (y::x::l2)) /\
          (!l1 l2 l3. P l1 l2 /\ P l2 l3 ==> P l1 l3)
         ==>
         !l1 l2. PERM l1 l2 ==> P l1 l2
\end{verbatim}
\end{hol}
%
A derived induction theorem (\holtxt{PERM\_IND}) is very
useful in proofs about permutations.

\paragraph{Sorting}

A list is $R$-sorted if $R$ holds pairwise through the list. This
notion (\holtxt{SORTED}) is captured by a recursive definition. Then
a function of type
%
\begin{hol}
\begin{verbatim}
   ('a -> 'a -> bool) -> 'a list -> 'a list
\end{verbatim}
\end{hol}
%
is a sorting function (\holtxt{SORTS}) with respect to $R$ if
it delivers a permutation of its input, and the result is $R$-sorted.
%
\begin{hol}
\begin{verbatim}
   SORTED_DEF
     |- (SORTED R [] = T) /\
        (SORTED R [x] = T) /\
        (SORTED R (x::y::rst) = R x y /\ SORTED R (y::rst))
   SORTS_DEF
     |- !f R. SORTS f R = !l. PERM l (f R l) /\ SORTED R (f R l)
\end{verbatim}
\end{hol}
%
Quicksort is defined in the usual functional programming style, and
it is indeed a sorting function, provided $R$ is a transitive and
total relation.
%
\begin{hol}
\begin{verbatim}
   QSORT_DEF =
     |- (QSORT ord [] = []) /\
        (QSORT ord (h::t) =
           let (l1,l2) = PARTITION (\y. ord y h) t
           in
             QSORT ord l1 ++ [h] ++ QSORT ord l2)
   QSORT_SORTS
     |- !R. transitive R /\ total R ==> SORTS QSORT R
\end{verbatim}
\end{hol}

\index{lists, the HOL theory of@lists, the \HOL{} theory of|)}
\index{ lists, the HOL theory of@\ml{[} $\cdots$ \ml{;} $\cdots$ \ml{]} (lists, the \HOL{} theory of)|)}

\subsection{Possibly infinite sequences (\theoryimp{llist})}

\index{lazy lists, the HOL theory of@``lazy'' lists, the \HOL{} theory of|(}

The theory \theoryimp{llist} contains the definition of a type of
possibly infinite sequences.  This type is similar to the ``lazy
lists'' of programming languages like Haskell, hence the name of the
theory.  The \theoryimp{llist} theory has a number of constants that
are analogous to constants in the theory of finite
lists.  The \theoryimp{llist} versions of these constants have the
same names, but with a capital `L\/' prepended.  Thus, some of the core
constants in this theory are:
\begin{hol}
\begin{verbatim}
   LNIL  : 'a llist
   LCONS : 'a -> 'a llist -> 'a llist
   LHD   : 'a llist -> 'a option
   LTL   : 'a llist -> 'a llist option
\end{verbatim}
\end{hol}

The \ml{LHD} and \ml{LTL} constants return \ml{NONE} when applied to
the empty sequence, \ml{LNIL}.  This use of an option type is another
way of modelling the essential partiality of these constants.  (In the
theory of lists, the analogous \ml{HD} and \ml{TL} functions simply
have unspecified values when applied to empty lists.)

The type \ml{llist} is not inductive, and there is no primitive
recursion theorem supporting the definition of functions that have
domains of type \ml{llist}.  Rather, \ml{llist} is a coinductive type,
and has an axiom that justifies the definition of (co-)recursive
functions that map \emph{into} the \ml{llist} type:
\begin{hol}
\begin{verbatim}
   llist_Axiom
      |- !f : 'a -> ('a # 'b) option.
           ?g : 'a -> 'b llist.
             (!x. LHD (g x) = OPTION_MAP SND (f x)) /\
             (!x. LTL (g x) = OPTION_MAP (g o FST) (f x))
\end{verbatim}
\end{hol}
\noindent An equivalent form of the above is
\begin{hol}
\begin{verbatim}
   llist_Axiom_1
      |- !f. ?g.
           !x. g x =
               case f x
                of NONE -> LNIL
                || SOME (x',y) -> LCONS y (g x')
\end{verbatim}
\end{hol}

Other constants in the theory \theoryimp{llist} include \ml{LMAP}, \ml{LFINITE},
\ml{LNTH}, \ml{LTAKE}, \ml{LDROP}, and \ml{LFILTER}. Their types are
%
\index{mapping functions, in the HOL logic@mapping functions, in the \HOL{} logic!for possibly infinite sequences}
\begin{hol}
\begin{verbatim}
   LMAP    : ('a -> 'b) -> 'a llist -> 'b llist
   LFINITE : 'a llist -> bool
   LNTH    : num -> 'a llist -> 'a option
   LTAKE   : num -> 'a llist -> 'a list option
   LDROP   : num -> 'a llist -> 'a llist option
   LFILTER : ('a -> bool) -> 'a llist -> 'a llist
\end{verbatim}
\end{hol}
They are characterised by the following theorems
\begin{hol}
\begin{verbatim}
   LMAP
      |- (LMAP f LNIL = LNIL) /\
         (LMAP f (LCONS h t) = LCONS (f h) (LMAP f t))
   LFINITE_THM
      |- (LFINITE LNIL = T) /\
         (LFINITE (LCONS h t) = LFINITE t)
   LNTH_THM
      |- (!n. LNTH n LNIL = NONE) /\
         (!h t. LNTH 0 (LCONS h t) = SOME h) /\
         (!n h t. LNTH (SUC n) (LCONS h t) = LNTH n t)
   LTAKE_THM
      |- (LTAKE 0 l = SOME []) /\
         (LTAKE (SUC n) LNIL = NONE) /\
         (LTAKE (SUC n) (LCONS h t) = OPTION_MAP (CONS h) (LTAKE n t)
   LDROP_THM
      |- (LDROP 0 ll = SOME ll) /\
         (LDROP (SUC n) ll = NONE) /\
         (LDROP (SUC n) (LCONS h t) = LDROP n t)
   LFILTER_THM
      |- (LFILTER P LNIL = LNIL) /\
         (LFILTER P (LCONS h t) = if P h then LCONS h (LFILTER P t)
                                         else LFILTER P t)
\end{verbatim}
\end{hol}

\paragraph{Concatenation}

Two lazy lists may be concatenated by \ml{LAPPEND}. If the first lazy
list is infinite, elements of the second are inaccessible in the
result.  A lazy list of lazy lists can be flattened to a lazy list by
\ml{LFLATTEN}.
\begin{hol}\begin{verbatim}
   LAPPEND
      |- (!x. LAPPEND LNIL x = x) /\
         (!h t x. LAPPEND (LCONS h t) x = LCONS h (LAPPEND t x))
   LFLATTEN_THM
      |- (LFLATTEN LNIL = LNIL) /\
         (!tl. LFLATTEN (LCONS LNIL t) = LFLATTEN t) /\
         (!h t tl. LFLATTEN (LCONS (LCONS h t) tl) =
                      LCONS h (LFLATTEN (LCONS t tl)))
\end{verbatim}\end{hol}

\paragraph{Lists and lazy lists}

Mapping back and forth from lists to lazy lists is accomplished
by \ml{fromList} and \ml{toList}:
\begin{hol}\begin{verbatim}
   fromList
      |- (fromList [] = LNIL) /\
         (!h t. fromList (h::t) = LCONS h (fromList t))
   toList_THM
      |- (toList LNIL = SOME []) /\
         (!h t. toList (LCONS h t) = OPTION_MAP (CONS h) (toList t))
\end{verbatim}\end{hol}

\paragraph{Proof principles}

Finally, there are two very important proof principles for proving
that two \ml{llist} values are equal.  The first states that two
sequences are equal if they return the same prefixes of length $n$ for
all possible values of $n$:
\begin{hol}
\begin{verbatim}
   LTAKE_EQ |- (ll1 = ll2) = (!n. LTAKE n ll1 = LTAKE n ll2)
\end{verbatim}
\end{hol}
This theorem is subsequently used to derive the bisimulation
principle:
\begin{hol}
\begin{verbatim}
   LLIST_BISIMULATION
            |- (ll1 = ll2) =
               ?R. R ll1 ll2 /\
                   !ll3 ll4. R ll3 ll4 ==>
                             (ll3 = LNIL) /\ (ll4 = LNIL) \/
                             (LHD ll3 = LHD ll4) /\
                             R (THE (LTL ll3)) (THE (LTL ll4))
\end{verbatim}
\end{hol}
The principle of bisimulation states that two \ml{llist} values $l_1$
and $l_2$ are equal if (and only if) it is possible to find a
relation $R$ such that
\begin{itemize}
\item $R$ relates the two values, i.e., $R\;l_1\;l_2$; and
\item if $R$ holds of any two values $l_3$ and $l_4$, then either
  \begin{itemize}
  \item both $l_3$ and $l_4$ are empty; or
  \item the head elements of $l_3$ and $l_4$ are the same, and the
    tails of those two values are again related by $R$
  \end{itemize}
\end{itemize}
Of course, a possible $R$ would be equality itself, but the strength
of this theorem is that other, more convenient relations can also be
used.
\index{lazy lists, the HOL theory of@``lazy'' lists, the \HOL{} theory of|)}

\subsection{Labelled paths (\theoryimp{path})}

The theory \theoryimp{path}
\index{labelled paths, the HOL theory of@labelled paths, the \HOL{} theory of|(}
\index{reduction sequences, the HOL theory of@reduction sequences, the \HOL{} theory of|(}
defines a binary type operator $(\alpha,\beta)\ml{path}$, which
stands for possibly infinite paths of the following form
\[
  \alpha_1 \stackrel{\beta_1}{\longrightarrow}
  \alpha_2 \stackrel{\beta_2}{\longrightarrow}
  \alpha_3 \stackrel{\beta_3}{\longrightarrow} \cdots
  \alpha_n \stackrel{\beta_n}{\longrightarrow}
  \alpha_{n+1} \stackrel{\beta_{n+1}}{\longrightarrow}  \cdots
  \]
The \ml{path} type is thus an appropriate model for reduction
sequences, where the $\alpha$ parameter corresponds to ``states'', and
the $\beta$ parameter corresponds to the labels on the arrows.

The model of $(\alpha,\beta)\ml{path}$ is $\alpha \times
((\alpha\times\beta)\ml{llist})$.  The type of paths has two
constructors:
\begin{hol}
\begin{verbatim}
   stopped_at : 'a -> ('a,'b) path
   pcons      : 'a -> 'b -> ('a,'b) path -> ('a,'b) path
\end{verbatim}
\end{hol}
The \holtxt{stopped\_at} constructor returns a path containing just one
state, and no transitions.  (Thus, the reduction sequence has
``stopped at'' this state.)  The \ml{pcons} constructor takes a state,
a label, and a path, and returns a path which is now headed by the
state argument, and which moves from that state via the label argument
to the path.  Graphically, $\ml{pcons}\;x\;l\;p$ is equal to
\[
x \stackrel{l}{\longrightarrow}
\underbrace{p_1 \stackrel{l_1}{\longrightarrow} p_2
  \stackrel{l_2}{\longrightarrow} \cdots\quad}_p
\]
Other constants defined in theory \theoryimp{path} include
%
\index{mapping functions, in the HOL logic@mapping functions, in the \HOL{} logic!for labelled paths}
%
\begin{hol}
\begin{verbatim}
   finite  : ('a,'b) path -> bool
   first   : ('a,'b) path -> 'a
   labels  : ('a,'b) path -> 'b llist
   last    : ('a,'b) path -> 'a
   length  : ('a,'b) path -> num option
   okpath  : ('a -> 'b -> 'a -> bool) -> ('a,'b) path -> bool
   pconcat : ('a,'b) path -> 'b -> ('a,'b) path -> ('a,'b) path
   pmap    : ('a -> 'c) -> ('b -> 'd) -> ('a,'b)path -> ('c,'d)path
\end{verbatim}
\end{hol}

The \ml{first} function returns the first element of a path.
There always is such an element, and the defining equations are
\begin{hol}
\begin{verbatim}
   first_thm  |- (first (stopped_at x) = x) /\
                 (first (pcons x l p) = x)
\end{verbatim}
\end{hol}

On the other hand, the \ml{last} function does not always have a
well-specified value, though it still has nice characterising
equations:
\begin{hol}
\begin{verbatim}
   last_thm   |- (last (stopped_at x) = x) /\
                 (last (pcons x l p) = last p)
\end{verbatim}
\end{hol}

The theorem for \ml{finite} has a similar feel, but has a definite
value (\ml{F}, or \emph{false}) on infinite paths), whereas the
value of \ml{last} on such paths is unspecified:
\begin{hol}
\begin{verbatim}
   finite_thm |- (finite (stopped_at x) = T) /\
                 (finite (pcons x l p) = finite p)
\end{verbatim}
\end{hol}

The function \ml{pconcat} concatenates two paths, linking them
with a provided label.  If the first path is infinite, then the result
is equal to that first path.  The defining equation is
\begin{hol}
\begin{verbatim}
   pconcat_thm |- (pconcat (stopped_at x) lab p2 = pcons x lab p2) /\
                  (pconcat (pcons x r p) lab p2 =
                       pcons x r (pconcat p lab p2)
\end{verbatim}
\end{hol}
%
These equations are true even when the first argument to
\ml{pconcat} is an infinite path.

The \ml{okpath} predicate tests whether or not a path is a valid
transition given a ternary transition relation.  Its characterising
theorem is
\begin{hol}
\begin{verbatim}
  okpath_thm |-
     (okpath R (stopped_at x)) /\
     (okpath R (pcons x r p) = R x r (first p) /\ okpath R p)
\end{verbatim}
\end{hol}
%
There is also an induction principle that simplifies reasoning about
finite $R$-paths:
%
\begin{hol}
\begin{verbatim}
   finite_okpath_ind |-
       (!x. P (stopped_at x)) /\
       (!x r p. okpath R p /\ finite p /\ R x r (first p) /\ P p ==>
                P (pcons x r p)) ==>
       !p. okpath R p /\ finite p ==> P p
\end{verbatim}
\end{hol}
\index{labelled paths, the HOL theory of@labelled paths, the \HOL{} theory of|)}
\index{reduction sequences, the HOL theory of@reduction sequences, the \HOL{} theory of|)}


\subsection{Character strings (\theoryimp{string})}
\index{strings, the HOL theory of@strings, the \HOL{} theory of|(}

The theory \theoryimp{string} defines a type of characters and a type
of finite strings built from those characters, along with a useful suite of
definitions for operating on strings.

\paragraph {Characters}
\index{characters, the HOL theory of@characters, the \HOL{} theory of}

The type \holtxt{char} is represented by the numbers less than 256. Two
constants are defined: {\small\verb+CHR +}$: \konst{num}\to\konst{char}$ and
{\small\verb+ORD +}$: \konst{char}\to\konst{num}$. The following theorems
hold:
\begin{hol}
\begin{verbatim}
  CHR_ORD  |- !a. CHR (ORD a) = a
  ORD_CHR  |- !r. r < 256 = (ORD (CHR r) = r)
\end{verbatim}
\end{hol}

\paragraph {Strings}

The type \holtxt{string} is inductively characterized by the
constructors
%
\begin{hol}
\index{EMPTYSTRING, the HOL constant@\holtxt{EMPTYSTRING}, the \HOL{} constant}
\index{STRING, the HOL constant@\holtxt{STRING}, the \HOL{} constant}
\begin{verbatim}
   EMPTYSTRING : string
   STRING      : char -> string -> string
\end{verbatim}
\end{hol}
The \HOL{} parser maps the syntax \holtxt{""} to \holtxt{EMPTYSTRING},
and the \HOL{} printer inverts this.  The parser expands string
literals of the form \holtxt{"$c_1 c_2 \ldots c_n$"} to the compound
term
\[
\holtxt{STRING} \;c_1\; (\holtxt{STRING}\;c_2\,\ldots\,
 (\holtxt{STRING} \;c_{n-1} \; (\holtxt{STRING}\;
c_n \; \holtxt{EMPTYSTRING})) \,\ldots\, )
\]
As a result of the characterization, the following basic theorems
hold:
%
\begin{hol}
\begin{verbatim}
   STRING_11
     |- !c1 c2 s1 s2. (STRING c1 s1 = STRING c2 s2) = (c1=c2) /\ (s1=s2)
   STRING_DISTINCT
     |- !c s. ~("" = STRING c s)) /\ (!c s. ~(STRING c s = ""))
   string_Axiom
     |- !b g. ?f.  (f "" = b) /\
                   (!c t. f (STRING c t) = g c t (f t))
   STRING_INDUCT_THM
     |- !P. P "" /\ (!s. P s ==> !c. P (STRING c s)) ==> !s. P s
   STRING_CASES
     |- !s. (s = "") \/ (?c str. s = STRING c str)
\end{verbatim}
\end{hol}
There is also a destructor function {\small\verb+DEST_STRING+} for
strings which returns an option type.
\begin{hol}
\begin{verbatim}
   DEST_STRING
     |- (DEST_STRING "" = NONE) /\
        (DEST_STRING (STRING c rst) = SOME(c,rst))
\end{verbatim}
\end{hol}


\paragraph{Case expressions}

Compound \HOL{} expressions that branch based on
whether a term is an empty or non-empty string have the
surface syntax
\begin{hol}
\begin{verbatim}
   case s
    of "" -> e1
    || STRING c rst -> e2
\end{verbatim}
\end{hol}
%
Such an expression is translated to
\holtxt{string\_case $e_1$ ($\lambda c\; rst.\ e_2)\ s$} where the constant
\holtxt{string\_case} is defined as follows:
\begin{hol}
\begin{verbatim}
   STRING_CASE_DEF
     |- (string_case b f ""  = b) /\
        (string_case b f (STRING c s) = f c s)
\end{verbatim}
\end{hol}

\paragraph {Length and concatenation}

The length of a string (\holtxt{STRLEN}) is defined by primitive
recursion. The concatenation of strings (\holtxt{STRCAT}) may be expressed
recursively (\holtxt{STRCAT\_EQNS}) or as a fold (\holtxt{STRCAT\_EXPLODE}):
\begin{hol}
\begin{verbatim}
   STRLEN_DEF
     |- (STRLEN "" = 0) /\
        (STRLEN (STRING c s) = 1 + STRLEN s)

   STRCAT_EQNS = Q.store_thm
     |- (STRCAT "" s = s) /\
        (STRCAT s "" = s) /\
        (STRCAT (STRING c s1) s2 = STRING c (STRCAT s1 s2))
   STRCAT_EXPLODE
     |- !s1 s2. STRCAT s1 s2 = FOLDR STRING s2 (EXPLODE s1)
\end{verbatim}
\end{hol}


\paragraph {Strings and lists}

Strings are converted to lists of characters by \holtxt{EXPLODE}. This
is inverted by \holtxt{IMPLODE}.
%
\begin{hol}
\begin{verbatim}
   EXPLODE_EQNS
     |- (EXPLODE "" = []) /\
        (!c s. EXPLODE (STRING c s) = c::EXPLODE s)

   IMPLODE_EQNS
     |- (IMPLODE [] = "") /\
        (!c s. IMPLODE (c::t) = STRING c (IMPLODE t))
\end{verbatim}
\end{hol}

\paragraph {Prefix checking}

That string $s_1$ is a prefix of $s_2$ ({\small\verb+isPREFIX+}) can be
defined by recursion ({\small\verb+isPREFIX_DEF+}). From this, the
statement {\small\verb+isPREFIX_STRCAT+} can be easily derived.
%
\begin{hol}
\begin{verbatim}
   isPREFIX_DEF
     |- isPREFIX s1 s2 =
          case (DEST_STRING s1, DEST_STRING s2)
           of (NONE, _) -> T
           || (SOME __, NONE) -> F
           || (SOME(c1,t1),SOME(c2,t2)) -> (c1=c2) /\ isPREFIX t1 t2

   isPREFIX_STRCAT
     |- !s1 s2. isPREFIX s1 s2 = ?s3. s2 = STRCAT s1 s3
\end{verbatim}
\end{hol}
\index{strings, the HOL theory of@strings, the \HOL{} theory of|)}

\section{Collections}

Several different notions of a collection of elements are available in
\HOL: sets, multisets, relations, and finite maps.

\subsection{Sets (\theoryimp{pred\_set})}
\index{sets, the HOL theory of@sets, the \HOL{} theory of}

An extensive development of set theory is available in the theory
\theoryimp{pred\_set}. Sets are represented by functions of the type
$\alpha \to \konst{bool}$, \ie, they are so-called characteristic
functions.
%
\index{characteristic functions!as basis for \HOL{} theory of sets}
%
One can use the type abbreviation $\alpha\; \konst{set}$
instead of $\alpha \to \konst{bool}$. Sets may be finite or
infinite. All of the elements in a set must have the same type.

\emph{Set membership} is the basic notion that formalized set theory
is based on. In \HOL, membership is represented by a the infix
constant \holtxt{IN}, defined in theory \theoryimp{bool} for
convenience.
\begin{hol}
\begin{verbatim}
   IN_DEF   |- IN = \x f. f x
\end{verbatim}
\end{hol}
The \holtxt{IN} operator is merely a way of applying the
characteristic function to an item, as the following trivial
consequence of the definition shows:
\begin{hol}
\begin{verbatim}
   SPECIFICATION   |- !P x. x IN P = P x
\end{verbatim}
\end{hol}
Two sets are equal if they have the same elements.
\begin{hol}
\begin{verbatim}
   EXTENSION   |- !s t. (s = t) = (!x. (x IN s) = (x IN t))
\end{verbatim}
\end{hol}

\paragraph{Empty and universal sets}

The empty set is the characteristic function that is constantly
false. The constant {\small\verb+EMPTY+} denotes the empty set; it may
be written as {\small\verb+{}+}. The universal set {\small\verb+UNIV+}
on a type is the characteristic function that is always true for
elements of that type.
\begin{hol}
\begin{verbatim}
   EMPTY_DEF   |- {} = (\x. F)
   UNIV_DEF    |- UNIV = (\x. T)
\end{verbatim}
\end{hol}

\paragraph{Insertion, union, and intersection}

The insertion ({\small\verb+INSERT+}, written infix) of an element
into a set is defined with a set comprehension. Set comprehension is
discussed in the next subsection. Set union ({\small\verb+UNION+},
written infix) and intersection ({\small\verb+INTER+}, also infix)
are given their usual definitions by set comprehension.
\begin{hol}
\begin{verbatim}
   INSERT_DEF  |- !x s. x INSERT s = {y | (y = x) \/ y IN s}
   UNION_DEF   |- !s t. s UNION t = {x | x IN s \/ x IN t}
   INTER_DEF   |- !s t. s INTER t = {x | x IN s /\ x IN t}
\end{verbatim}
\end{hol}
\holtxt{UNION} and \holtxt{INTER} are binary
operations. Indexed union and intersection operations, \ie,
$\bigcup_{i \in P}$ and $\bigcap_{i \in P}$ are provided by the
definitions of  \holtxt{BIGUNION} and \holtxt{BIGINTER}.
\begin{hol}
\begin{verbatim}
   BIGUNION    |- !P. BIGUNION P = {x | ?s. s IN P /\ x IN s}
   BIGINTER    |- !P. BIGINTER P = {x | !s. s IN P ==> x IN s}
\end{verbatim}
\end{hol}
Both \holtxt{BIGUNION} and \holtxt{BIGINTER} reduce a set of sets to a
set and thus have the type
$((\alpha\to\konst{bool})\to\konst{bool})\to (\alpha\to\konst{bool})$.

\paragraph{Subsets}

Set inclusion (\holtxt{SUBSET}, infix) and proper set inclusion
(\holtxt{PSUBSET}, infix) are defined as follows:
%
\begin{hol}
\begin{verbatim}
   SUBSET_DEF  |- !s t. s SUBSET t = !x. x IN s ==> x IN t
   PSUBSET_DEF |- !s t. s PSUBSET t = s SUBSET t /\ ~(s = t)
\end{verbatim}
\end{hol}

\paragraph{Set difference and complement}

The difference between two sets (\holtxt{DIFF}, infix) is defined by a
set comprehension. Based on that, the deletion of a single element
(\holtxt{DELETE}, infix) from a set is straightforward. Since the
universe of a type is always available via \holtxt{UNIV}, the
complement (\holtxt{COMPL}) of a set may be taken.
\begin{hol}
\begin{verbatim}
   DIFF_DEF    |- !s t. s DIFF t = {x | x IN s /\ ~(x IN t)}
   DELETE_DEF  |- !s x. s DELETE x = s DIFF {x}
   COMPL_DEF   |- !P. COMPL P = UNIV DIFF P
\end{verbatim}
\end{hol}

\paragraph{Functions on sets}
The image of a function $f :\alpha \to \beta$ on
a set (\holtxt{IMAGE}) is defined with a set comprehension.
\begin{hol}
\begin{verbatim}
   IMAGE_DEF   |- !f s. IMAGE f s = {f x | x IN s}
\end{verbatim}
\end{hol}
%
Injections, surjections, and bijections between sets are defined
as follows:
%
\begin{hol}
\begin{verbatim}
   INJ_DEF
        |- !f s t.
             INJ f s t =
             (!x. x IN s ==> f x IN t) /\
             !x y. x IN s /\ y IN s ==> (f x = f y) ==> (x = y)
   SURJ_DEF
        |- !f s t.
             SURJ f s t =
             (!x. x IN s ==> f x IN t) /\
             !x. x IN t ==> ?y. y IN s /\ (f y = x)

   BIJ_DEF |- !f s t. BIJ f s t = INJ f s t /\ SURJ f s t
\end{verbatim}
\end{hol}

\paragraph{Finite sets}
The finite sets (\holtxt{FINITE}) are defined inductively as those
built from the empty set by a finite number of insertions.
%
\begin{hol}
\begin{verbatim}
   FINITE_DEF
     |- !s. FINITE s = !P. P {} /\ (!s. P s ==> !e. P (e INSERT s)) ==> P s
   INFINITE_DEF
     |- !s. INFINITE s = ~FINITE s
\end{verbatim}
\end{hol}
%
\noindent
A set is infinite iff it is not finite. The finite sets have an
induction theorem:
%
\index{induction theorems, in HOL logic@induction theorems, in \HOL{} logic!for finite sets}
%
\begin{hol}
\begin{verbatim}
   FINITE_INDUCT
     |- !P. P {} /\
           (!s. FINITE s /\ P s ==> !e. ~(e IN s) ==> P (e INSERT s))
           ==>  !s. FINITE s ==> P s
\end{verbatim}
\end{hol}
%
As mentioned, set operations apply to both finite and infinite
sets. However, some operations, such as cardinality
(\holtxt{CARD}), are only defined for finite sets.  The
cardinality of an infinite set is not specified.
%
\begin{hol}
\begin{verbatim}
   CARD_DEF
     |- (CARD {} = 0) /\
        !s. FINITE s ==>
            !x. CARD (x INSERT s) = if x IN s then CARD s else SUC (CARD s)
\end{verbatim}
\end{hol}
%
Since the finite and infinite sets are dealt with uniformly in
\theoryimp{pred\_set}, properties of operations on finite sets must
explicitly include constraints about finiteness. For example the
following theorem relating cardinality and subsets is only true for
finite sets.
%
\begin{hol}
\begin{verbatim}
   CARD_PSUBSET
     |- !s. FINITE s ==> !t. t PSUBSET s ==> CARD t < CARD s
\end{verbatim}
\end{hol}
%
An extensive suite of theorems dealing with finiteness and cardinality
is available in \theoryimp{pred\_set}.

\paragraph{Cross product}
The product of two sets ({\small\verb+CROSS+}, infix) is defined
with a set comprehension.
%
\begin{hol}
\begin{verbatim}
   CROSS_DEF   |- !P Q. P CROSS Q = {p | FST p IN P /\ SND p IN Q}
\end{verbatim}
\end{hol}
%
\noindent Cardinality and cross product are related by the following theorem:
\begin{hol}
\begin{verbatim}
   CARD_CROSS
     |- !P Q. FINITE P /\ FINITE Q ==> (CARD (P CROSS Q) = CARD P * CARD Q)
\end{verbatim}
\end{hol}

\paragraph{Recursive functions on sets}

Recursive functions on sets may be defined by wellfounded
recursion. Usually, the totality of such a function is established by
measuring the cardinality of the (finite) set. However, another
theorem may be used to justify a fold ({\small\verb+ITSET+}) for finite sets.
Provided a function $f:\alpha\to\beta\to\beta$ obeys a condition
known as \emph{left-commutativity}, namely, $f\;x\;(f\;y\;z) =
f\;y\;(f\;x\;z)$, then $f$ can be applied by folding it on the set
in a tail-recursive fashion.
\begin{hol}
\begin{verbatim}
   ITSET_EMPTY
     |- !f b. ITSET f {} b = b
   COMMUTING_ITSET_INSERT
     |- !f s. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE s ==>
              !x b. ITSET f (x INSERT s) b = ITSET f (s DELETE x) (f x b)
\end{verbatim}
\end{hol}
A recursive version is also available:
\begin{hol}
\begin{verbatim}
   COMMUTING_ITSET_RECURSES
     |- !f e s b.
          (!x y z. f x (f y z) = f y (f x z)) /\ FINITE s ==>
          (ITSET f (e INSERT s) b = f e (ITSET f (s DELETE e) b))
\end{verbatim}
\end{hol}
For the full derivation, see the sources of {\small\verb+pred_set+}.
The definition of {\small\verb+ITSET+} allows, for example, the
definition of summing the results of a function on a finite set of
elements, from which a recursive characterization and other useful
theorems are derived.
%
\begin{hol}
\begin{verbatim}
   SUM_IMAGE_DEF
     |- !f s. SIGMA f s = ITSET (\e acc. f e + acc) s 0
   SUM_IMAGE_THM
     |- !f. (SIGMA f {} = 0) /\
            !e s. FINITE s ==>
                  (SIGMA f (e INSERT s) = f e + SIGMA f (s DELETE e))
\end{verbatim}
\end{hol}

\paragraph{Other definitions and theorems}

There are more definitions in \theoryimp{pred\_set}, but they are not
as heavily used as the ones presented here. Similarly, most theorems
in \theoryimp{pred\_set} relate the various common set operations to
each other, but do not express any deep theorems of set theory.

However, one notable theorem is Koenig's Lemma, which states that
every finitely branching infinite tree has an infinite path. There are
many ways to formulate this theorem, depending on how the notion of
tree is formalized. In \theoryimp{pred\_set}, finite branching is
defined as a predicate on a relation.
%
\begin{hol}
\begin{verbatim}
   finite_branching_def
     |- !R. finitely_branching R = !x. FINITE {y | R x y}
\end{verbatim}
\end{hol}
%
From this, the following version of Koenig's Lemma is stated and
proved:
\begin{hol}
\begin{verbatim}
   KoenigsLemma
     |- finitely_branching R ==>
          !x. ~FINITE {y | RTC R x y} ==>
              ?f. (f 0 = x) /\ !n. R (f n) (f (SUC n))
\end{verbatim}
\end{hol}


\subsubsection{Syntax for sets}\index{set theory notation}

The special purpose set-theoretic notations
{\small\verb%{%}$t_1 ;t_2 ; \ldots ; t_n${\small\verb%}%} and
{\small\verb%{%}$t${\small\verb% | %}$p${\small\verb%}%} are recognized
by the \HOL{} parser and printer when the theory \theoryimp{pred\_set}
is loaded.

The normal interpretation of $\holtxt{\{}t_1 ;t_2 ; \ldots ;
t_n\holtxt{\}}$ is the finite set containing just $t_1,t_2,\ldots,
t_n$. This can be modelled by starting with the empty set and
performing a sequence of insertions. For example, \holtxt{\{1;2;3;4\}}
parses to

\begin{hol}
\begin{verbatim}
   1 INSERT (2 INSERT (3 INSERT (4 INSERT EMPTY)))
\end{verbatim}
\end{hol}

\paragraph {Set comprehensions}

The normal interpretation of
{\small\verb%{%}$t${\small\verb% | %}$p${\small\verb%}%} is
the set of all $t$s such that $p$. In \HOL, such syntax parses to:
%
\ml{GSPEC(\bs($x_1$,$\ldots$,$x_n$).($t$,$p$))}
%
\noindent where $x_1, \ldots, x_n$ are those free variables that
occur in both $t$ and $p$.  If there are no such free variables
then an error results. The order in which the variables are listed in
the variable structure of the paired abstraction is an unspecified
function of the structure of $t$ (it is approximately left to
right). For example,
%
\begin{hol}
\begin{verbatim}
   {p+q | p < q /\ q < r}
\end{verbatim}
\end{hol}
%
parses to:
%
\begin{hol}
\begin{verbatim}
   GSPEC(\(p,q). ((p+q), (p < q /\ q < r)))
\end{verbatim}
\end{hol}
%
where \ml{GSPEC} is characterized by:
%
\begin{hol}
\begin{verbatim}
   GSPECIFICATION  |- !f v. (v IN GSPEC f) = (?x. (v,T) = f x)
\end{verbatim}
\end{hol}

This somewhat cryptic specification can be understood by exercising an
example. The syntax
%
\begin{hol}
\begin{verbatim}
   a IN {p+q | p < q /\ q < r}
\end{verbatim}
\end{hol}
%
is mapped by the \HOL{} parser to
\begin{hol}
\begin{verbatim}
   a IN GSPEC(\(p,q). ((p+q), (p < q /\ q < r)))
\end{verbatim}
\end{hol}
%
which, by \ml{GSPECIFICATION}, is equal to
\begin{hol}
\begin{verbatim}
   ?x. (a,T) = (\(p,q). ((p+q), (p < q /\ q < r))) x
\end{verbatim}
\end{hol}
%
The existentially quantified variable \verb+x+ has a pair type,
so it can be replaced by a pair \verb+(p,q)+ and a
paired-$\beta$-reduction can be performed, yielding
%
\begin{hol}
\begin{verbatim}
   ?(p,q). (a,T) = ((p+q), (p < q /\ q < r))
\end{verbatim}
\end{hol}
%
which is equal to the intended meaning of the original
syntax:
%
\begin{hol}
\begin{verbatim}
   ?(p,q). (a = p+q) /\ (p < q /\ q < r)
\end{verbatim}
\end{hol}

\subsection{Multisets (\theoryimp{bag})}\label{multiset}

Multisets, also known as \emph{bags}, are similar to sets, except that
they allow repeat occurrences of an element. Whereas sets are
represented by functions of type $\alpha\to\konst{bool}$, which signal
the presence, or absence, of an element, multisets are represented
by functions of type $\alpha\to\konst{num}$, which give the
multiplicity of each element in the multiset. Multisets may be finite
or infinite.

The type abbreviations $\alpha\;\konst{multiset}$ and
$\alpha\;\konst{bag}$ can be used instead of $\alpha\to\konst{num}$.

\paragraph {Empty multiset}

The empty bag has no elements. Thus, the function implementing it
returns $0$ for every input.
%
\begin{hol}
\begin{verbatim}
   EMPTY_BAG  |- EMPTY_BAG = K 0
\end{verbatim}
\end{hol}

\noindent The special syntax {\verb+{||}+} can be used to represent the empty
bag.

\paragraph {Membership}

Much of the theory can be based on the notion of membership in a
bag. There are two notions: does an element occur at least $n$ times
in a bag ({\small\verb+BAG_INN+}); and does an element occur in a bag
at all ({\small\verb+BAG_IN+}).
%
\begin{hol}
\begin{verbatim}
   BAG_INN  |- BAG_INN e n b = (b e >= n)
   BAG_IN   |- BAG_IN e b = BAG_INN e 1 b
\end{verbatim}
\end{hol}
%
Two bags are equal if all elements have the same tally.
%
\begin{hol}
\begin{verbatim}
   BAG_EXTENSION
     |- !b1 b2. (b1 = b2) = (!n e. BAG_INN e n b1 = BAG_INN e n b2)
\end{verbatim}
\end{hol}

\paragraph{Sub-multiset}

A sub-bag relationship (\holtxt{SUB\_BAG}) holds between $b_1$ and
$b_2$ provided that every element in $b_1$ occurs at least as often in
$b_2$. The notion of a proper sub-bag (\holtxt{PSUB\_BAG}) is easily
defined.
%
\begin{hol}
\begin{verbatim}
   SUB_BAG
     |- SUB_BAG b1 b2 = !x n. BAG_INN x n b1 ==> BAG_INN x n b2
   PSUB_BAG
     |- PSUB_BAG b1 b2 = SUB_BAG b1 b2 /\ ~(b1 = b2)
\end{verbatim}
\end{hol}

\paragraph{Insertion}

Inserting an element into a bag (\holtxt{BAG\_INSERT}) updates the
tally for that element and leaves the others unchanged.
%
\begin{hol}
\begin{verbatim}
   BAG_INSERT
     |- BAG_INSERT e b = (\x. if (x = e) then b e + 1 else b x)
\end{verbatim}
\end{hol}

Explicitly-given multisets are supported by the syntax
{\small\verb%{|%}$t_1 ;t_2 ; \ldots ; t_n${\small\verb%|}%}, where
there may, of course, be repetitions. This is modelled by starting with the empty
multiset and performing a sequence of insertions. For example,
\verb+{|1; 2; 3; 2; 1|}+ parses to

\begin{hol}
\begin{verbatim}
   BAG_INSERT 1 (BAG_INSERT 2 (BAG_INSERT 3
                                 (BAG_INSERT 2 (BAG_INSERT 1 {||}))))
\end{verbatim}
\end{hol}


\paragraph{Union and difference}

The union (\holtxt{BAG\_UNION}) and difference (\holtxt{BAG\_DIFF})
operations on bags both reduce to an arithmetic calculation on their
elements. Deleting a single element from a bag may be expressed by
taking the multiset difference with a single-element multiset;
however, there is also a relational presentation
(\holtxt{BAG\_DELETE}) which relates its first and last arguments only
if the first contains exactly one more occurrence of the middle
argument than the last.  This is not the same as using
\holtxt{BAG\_DIFF} to remove a one-element bag because it insists that
the element being removed actually appear in the larger bag.
%
\begin{hol}
\begin{verbatim}
   BAG_UNION
     |- BAG_UNION b c = \x. b x + c x
   BAG_DIFF
     |- BAG_DIFF b1 b2 = \x. b1 x - b2 x
   BAG_DELETE
     |- BAG_DELETE b0 e b = (b0 = BAG_INSERT e b)
\end{verbatim}
\end{hol}

\paragraph {Intersection, merge, and filter}

The intersection of two bags (\holtxt{BAG\_INTER}) takes the pointwise
minimum. The dual operation, merging (\holtxt{BAG\_MERGE}), takes the
pointwise maximum. A bag can be `filtered' by a set to return the bag
where all the elements not in the set have been dropped
(\holtxt{BAG\_FILTER}).
%
\begin{hol}
\begin{verbatim}
   BAG_INTER
     |- BAG_INTER b1 b2 = (\x. if (b1 x < b2 x) then b1 x else b2 x)
   BAG_MERGE
     |- BAG_MERGE b1 b2 = (\x. if (b1 x < b2 x) then b2 x else b1 x)
   BAG_FILTER_DEF
     |- BAG_FILTER P b = (\e. if P e then b e else 0)
\end{verbatim}
\end{hol}

\paragraph {Sets and Multisets}

Moving between bags and sets is accomplished by the following two
definitions.
%
\begin{hol}
\begin{verbatim}
   SET_OF_BAG
     |- SET_OF_BAG b = \x. BAG_IN x b
   BAG_OF_SET
     |- BAG_OF_SET P = \x. if x IN P then 1 else 0
\end{verbatim}
\end{hol}

\paragraph {Image}

Taking the image of a function on a multiset to get a new multiset
seems to be simply a matter of applying the function to each element
of the multiset. However, there is a problem if $f$ is non-injective
and the multiset is infinite. For example, take the multiset
consisting of all the natural numbers and apply $\lambda x.\; 1$ to
each element. The resulting multiset would hold an infinite number of
$1$s. To avoid this requires some constraints: for example,
stipulating that the function be only finitely non-injective, or that
the input multiset be finite. Such conditions would be onerous in
proof; the compromise is to map the multipicity of problematic
elements to $0$.
%
\begin{hol}
\begin{verbatim}
   BAG_IMAGE_DEF
     |- BAG_IMAGE f b =
          \e. let sb = BAG_FILTER (\e0. f e0 = e) b
              in
                if FINITE_BAG sb then BAG_CARD sb else 0
\end{verbatim}
\end{hol}


\paragraph {Finite multisets}

The finite multisets (\holtxt{FINITE\_BAG}) are defined inductively as
those built from the empty bag by a finite number of insertions.
%
\begin{hol}
\begin{verbatim}
   FINITE_BAG
     |- FINITE_BAG b =
          !P. P EMPTY_BAG /\
              (!b. P b ==> (!e. P (BAG_INSERT e b))) ==> P b
\end{verbatim}
\end{hol}
%
The finite multisets have an induction theorem, and also a strong
induction theorem.
%
\index{induction theorems, in HOL logic@induction theorems, in \HOL{} logic!for finite bags}
%
\begin{hol}
\begin{verbatim}
   FINITE_BAG_INDUCT
     |- !P. P {||} /\
            (!b. P b ==> (!e. P (BAG_INSERT e b)))
            ==> (!b. FINITE_BAG b ==> P b)

   STRONG_FINITE_BAG_INDUCT
     |- !P. P {||} /\
            (!b. FINITE_BAG b /\ P b ==> !e. P (BAG_INSERT e b))
            ==> (!b. FINITE_BAG b ==> P b)
\end{verbatim}
\end{hol}
%
The cardinality (\holtxt{BAG\_CARD}) of a multiset counts the
total number of occurrences. It is only specified for finite multisets.
%
\begin{hol}
\begin{verbatim}
   BAG_CARD_THM
     |- (BAG_CARD {||} = 0) /\
        (!b. FINITE_BAG b ==>
               !e. BAG_CARD (BAG_INSERT e b) = BAG_CARD b + 1)
\end{verbatim}
\end{hol}

\paragraph{Recursive functions on multisets}

Recursive functions on multiset may be defined by wellfounded
recursion. Usually, the totality of such a function is established by
measuring the cardinality of the (finite) multiset. However, a fold
(\holtxt{ITBAG}) for finite sets is provided.  Provided a function
$f:\alpha\to\beta\to\beta$ obeys a condition known as
\emph{left-commutativity}, namely, $f\;x\;(f\;y\;z) =
f\;y\;(f\;x\;z)$, then $f$ can be applied by folding it on the
multiset in a tail-recursive fashion.
%
\begin{hol}
\begin{verbatim}
   ITBAG_EMPTY
     |- !f acc. ITSET f {||} acc = acc
   COMMUTING_ITBAG_INSERT
     |- !f b. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE_BAG b ==>
              !x a. ITBAG f (BAG_INSERT x b) a = ITBAG f b (f x a)
\end{verbatim}
\end{hol}
%
A recursive version is also available:
\begin{hol}
\begin{verbatim}
   COMMUTING_ITBAG_RECURSES
     |- !f e b a. (!x y z. f x (f y z) = f y (f x z)) /\ FINITE_BAG b ==>
                  (ITBAG f (BAG_INSERT e b) a = f e (ITBAG f b a))
\end{verbatim}
\end{hol}

\subsection{Relations (\theoryimp{relation})}\label{relation}

Mathematical relations can be represented in \HOL{} by the type
$\alpha \to\beta\to\konst{bool}$. (In most applications, the type of a
relation is an instance of $\alpha \to\alpha\to\konst{bool}$, but the
extra generality doesn't hurt.) The theory \theoryimp{relation}
provides definitions of basic properties and operations on relations,
defines various kinds of orders and closures, defines wellfoundedness
and proves the wellfounded recursion theorem, and develops some
basic results used in Term Rewriting.

\paragraph {Basic properties}

The following basic properties of relations are defined.
%
\begin{hol}
\begin{verbatim}
   transitive_def
     |- transitive R = !x y z. R x y /\ R y z ==> R x z
   reflexive_def
     |- reflexive R = (!x. R x x)
   irreflexive_def
     |- irreflexive R = (!x. ~R x x)
   symmetric_def
     |- symmetric R = (!x y. R x y = R y x)
   antisymmetric_def
     |- antisymmetric R = (!x y. R x y /\ R y x ==> (x = y))
   equivalence_def
     |- equivalence R = reflexive R /\ symmetric R /\ transitive R
   trichotomous
     |- trichotomous R = !a b. R a b \/ R b a \/ (a = b)
   total_def
     |- total R = (!x y. R x y \/ R y x)
\end{verbatim}
\end{hol}

\paragraph{Basic operations}

The following basic operations on relations are defined: the empty
relation (\holtxt{EMPTY\_REL}), relation composition (\holtxt{O},
infix), inversion (\holtxt{inv}), domain (\holtxt{RDOM}), and range
(\holtxt{RRANGE}).
%
\begin{hol}
\begin{verbatim}
   EMPTY_REL_DEF
     |- !x y. EMPTY_REL x y = F
   O_DEF
     |- $O R1 R2 x z = ?y. R1 x y /\ R2 y z
   inv_DEF
     |- inv R x y = R y x
   RDOM_DEF
     |- RDOM R x = ?y. R x y
   RRANGE
     |- RRANGE R y = ?x. R x y
\end{verbatim}
\end{hol}

Set operations lifted to work on relations include subset
(\holtxt{RSUBSET}, infix), union (\holtxt{RUNION}, infix),
intersection (\holtxt{RINTER}, infix), complement (\holtxt{RCOMPL}),
and universe (\holtxt{RUNIV}).
%
\begin{hol}
\begin{verbatim}
   RSUBSET
     |- $RSUBSET R1 R2 = !x y. R1 x y ==> R2 x y
   RUNION
     |- $RUNION R1 R2 x y = R1 x y \/ R2 x y
   RINTER
     |- $RINTER R1 R2 x y = R1 x y /\ R2 x y
   RCOMPL
     |- RCOMPL R x y = ~R x y
   RUNIV
     |- RUNIV x y = T
\end{verbatim}
\end{hol}

\paragraph {Orders}

A sequence of definitions capturing various notions of order are made
in \theoryimp{relation}.
%
\begin{hol}
\begin{verbatim}
   PreOrder
     |- PreOrder R = reflexive R /\ transitive R
   Order
     |- Order Z = antisymmetric Z /\ transitive Z
   WeakOrder
     |- WeakOrder Z = reflexive Z /\ antisymmetric Z /\ transitive Z
   StrongOrder
     |- StrongOrder Z = irreflexive Z /\ antisymmetric Z /\ transitive Z
   LinearOrder
     |- LinearOrder R = Order R /\ trichotomous R
   WeakLinearOrder
     |- WeakLinearOrder R = WeakOrder R /\ trichotomous R
   StrongLinearOrder
     |- StrongLinearOrder R = StrongOrder R /\ trichotomous R
\end{verbatim}
\end{hol}

\paragraph {Closures}

The transitive closure (\holtxt{TC}) of a relation $R : \alpha
\to\alpha\to\konst{bool}$ is defined inductively, as the least
relation including $R$ and closed under transitivity. Similarly, the
reflexive-transitive closure (\holtxt{RTC}) is defined to be the least
relation closed under transitivity and reflexivity.
%
\begin{hol}
\begin{verbatim}
   TC_DEF
     |- TC R a b =
          !P. (!x y. R x y ==> P x y) /\
              (!x y z. P x y /\ P y z ==> P x z) ==> P a b
   RTC_DEF
     |- RTC R a b =
          !P. (!x. P x x) /\
              (!x y z. R x y /\ P y z ==> P x z) ==> P a b
\end{verbatim}
\end{hol}

\noindent
From these definitions, one can recover the initial rules.
%
\begin{hol}
\begin{verbatim}
   TC_RULES
     |- !R. (!x y. R x y ==> TC R x y) /\
            (!x y z. TC R x y /\ TC R y z ==> TC R x z)
   RTC_RULES
     |- !R. (!x. RTC R x x) /\
            (!x y z. R x y /\ RTC R y z ==> RTC R x z)
   RTC_RULES_RIGHT1
     |- !R. (!x. RTC R x x) /\
            (!x y z. RTC R x y /\ R y z ==> RTC R x z)
\end{verbatim}
\end{hol}
%
Notice that {\small\verb+RTC_RULES+}, in keeping with the definition
of {\small\verb+RTC+}, extends an \verb+R+-step from \verb+x+ to
\verb+y+ with a a sequence of \verb+R+-steps from \verb+y+ to \verb+z+
to construct \verb+RTC x z+. The theorem
{\small\verb+RTC_RULES_RIGHT1+} first makes a sequence of \verb+R+
steps and then a single \verb+R+ step to form \verb+RTC x z+. Similar
alternative theorems are proved for case analysis and induction.

For example, {\small\verb+TC_CASES1+} and {\small\verb+TC_CASES2+} in the
following decompose {\small\verb+RTC R x z+} to either
{\small\verb+R x y+} followed by {\small\verb+RTC R y z+}
({\small\verb+TC_CASES1+})
or
{\small\verb+RTC R x y+} followed by {\small\verb+R y z+}
({\small\verb+TC_CASES2+}).

%
\begin{hol}
\begin{verbatim}
   TC_CASES1
     |- !R x z. TC R x z ==> R x z \/ ?y. R x y /\ TC R y z
   TC_CASES2
     |- !R x z. TC R x z ==> R x z \/ ?y. TC R x y /\ R y z

   RTC_CASES1
     |- !R x y. RTC R x y = (x = y) \/ ?u. R x u /\ RTC R u y
   RTC_CASES2
     |- !R x y. RTC R x y = (x = y) \/ ?u. RTC R x u /\ R u y
   RTC_CASES_RTC_TWICE
     |- !R x y. RTC R x y = ?u. RTC R x u /\ RTC R u y
\end{verbatim}
\end{hol}

As well as the basic induction theorems for {\small\verb+TC+} and
{\small\verb+RTC+}, there are so-called \emph{strong} induction
theorems, which have stronger induction hypotheses.
%
\begin{hol}
\begin{verbatim}
   TC_INDUCT
     |- !R P. (!x y. R x y ==> P x y) /\
              (!x y z. P x y /\ P y z ==> P x z)
              ==> !u v. TC R u v ==> P u v
   RTC_INDUCT
     |- ! R P. (!x. P x x) /\
               (!x y z. R x y /\ P y z ==> P x z) ==>
               (!x y. RTC R x y ==> P x y)
   TC_STRONG_INDUCT
     |- !R P. (!x y. R x y ==> P x y) /\
              (!x y z. P x y /\ P y z /\ TC R x y /\ TC R y z ==> P x z) ==>
              (!u v. TC R u v ==> P u v)
   RTC_STRONG_INDUCT
     |- !R P. (!x. P x x) /\
              (!x y z. R x y /\ RTC R y z /\ P y z ==> P x z) ==>
              (!x y. RTC R x y ==> P x y)
\end{verbatim}
\end{hol}
Variants of these induction theorems are also available which break
apart the closure from the left or right, as for the case analysis theorems.

\medskip

The reflexive ({\small\verb+RC+}) and symmetric closures
({\small\verb+RC+}) are straightforward to define. The equivalence
closure ({\small\verb+EQC+}) is the symmetric then transitive then
reflexive closure of $R$.
%
\begin{hol}
\begin{verbatim}
   RC_DEF   |- RC R x y = (x = y) \/ R x y
   SC_DEF   |- SC R x y = R x y \/ R y x
   EQC_DEF  |- EQC R = RC (TC (SC R))
\end{verbatim}
\end{hol}

\paragraph {Wellfounded relations}

A relation $R$ is wellfounded ({\small\verb+WF+}) if every non-empty set
has an $R$-minimal element. Wellfoundedness is used to justify the
principle of wellfounded induction ({\small\verb+WF_INDUCTION_THM+}).
%
\begin{hol}
\begin{verbatim}
   WF_DEF
     |- !R. WF R = !B. (?w. B w) ==> ?min. B min /\ !b. R b min ==> ~B b
   WF_INDUCTION_THM
     |- !R WF R ==> !P. (!x. (!y. R y x ==> P y) ==> P x) ==> !x. P x
\end{verbatim}
\end{hol}

The \emph{wellfounded part} ({\small\verb+WFP+}) of a relation can be
inductively defined, from which its rules, case-analysis theorem and
induction theorems may be derived.
%
\begin{hol}
\begin{verbatim}
   WFP_DEF
     |- WFP R a = !P. (!x. (!y. R y x ==> P y) ==> P x) ==> P a
   WFP_RULES
     |- !R x. (!y. R y x ==> WFP R y) ==> WFP R x
   WFP_CASES
     |- !R x. WFP R x = !y. R y x ==> WFP R y
   WFP_INDUCT
     |- !R P. (!x. (!y. R y x ==> P y) ==> P x)
              ==> !x. WFP R x ==> P x
   WFP_STRONG_INDUCT
     |- !R. (!x. WFP R x /\ (!y. R y x ==> P y) ==> P x)
            ==> !x. WFP R x ==> P x
\end{verbatim}
\end{hol}

Wellfoundedness can also be used to justify a general recursion
theorem. Intuitively, a collection of recursion equations can be
admitted into the \HOL{} logic with no loss of consistency provided
that every possible sequence of recursive calls is finite. Wellfounded
relations are used to capture this notion: if there is a wellfounded
relation $R$ on the domain of the desired function such that every
sequence of recursive calls is $R$-decreasing, then the recursion
equations specify a unique total function and the equations can be
admitted into the logic.

The recursion theorems {\small\verb+WFREC_COROLLARY+} and
{\small\verb+WF_RECURSION_THM+} use the notion of a function
restriction ({\small\verb+RESTRICT+}) in order to force the recursive
function to be applied to $R$-smaller arguments in recursive calls..
%
\begin{hol}
\begin{verbatim}
   RESTRICT_DEF
     |- !f R x. RESTRICT f R x = \y. if R y x then f y else ARB

   WFREC_COROLLARY
     |- !M R f. (f = WFREC R M) ==> WF R ==> !x. f x = M (RESTRICT f R x) x

   WF_RECURSION_THM
     |- !R. WF R ==> !M. ?!f. !x. f x = M (RESTRICT f R x) x
\end{verbatim}
\end{hol}

\noindent The theorems {\small\verb+WF_INDUCTION_THM+} and
{\small\verb+WFREC_COROLLARY+} are used to automate recursive
definitions; see Section \ref{TFL}. A few basic operators for
wellfounded relations are also defined, along with theorems stating
that they propagate wellfoundedness.

\begin{hol}
\begin{verbatim}
   inv_image_def  |- !R f. inv_image R f = \x y. R (f x) (f y)

   WF_inv_image   |- !R f. WF R ==> WF (inv_image R f)
   WF_SUBSET      |- !R P. WF R /\ (!x y. P x y ==> R x y) ==> WF P
   WF_TC          |- !R. WF R ==> WF (TC R)
   WF_Empty       |- WF EMPTY_REL
\end{verbatim}
\end{hol}

\paragraph {Term Rewriting}

A few basic definitions from Term Rewriting theory
(the diamond property (\verb+diamond+), the Church-Rosser
property ({\small\verb+CR+} and {\small\verb+WCR+}), and Strong
Normalization ({\small\verb+SN+})) appear
in \theoryimp{relation}.
%
\begin{hol}
\begin{verbatim}
   diamond_def
     |- diamond R = !x y z. R x y /\ R x z ==> ?u. R y u /\ R z u
   CR_def
     |- CR R = diamond (RTC R)
   WCR_def
     |- WCR R = !x y z. R x y /\ R x z ==> ?u. RTC R y u /\ RTC R z u
   SN_def
     |- SN R = WF (inv R)
\end{verbatim}
\end{hol}
%
From those, Newman's Lemma is proved.
%
\begin{hol}
\begin{verbatim}
   Newmans_lemma  |- !R. WCR R /\ SN R ==> CR R
\end{verbatim}
\end{hol}

\subsection{Finite maps (\theoryimp{finite\_map})}\label{finite_map}

The theory \theoryimp{finite\_map} formalizes a type
$(\alpha,\beta)\,\holtxt{fmap}$ of finite functions. These notionally
have type $\alpha\to\beta$, but additionally have only finitely many
elements in their domain. Finite maps are useful for formalizing
substitutions and arrays. The representing type is $\alpha\to\beta +
\konst{one}$, where only a finite number of the $\alpha$ map to a
$\beta$ and the rest map to \verb+one+. The syntax
$\alpha\,\holtxt{|->}\,\beta$ is recognized by the parser as an
alternative to $(\alpha,\beta)\,\holtxt{fmap}$.

\paragraph {Basic notions}

The empty map (\holtxt{FEMPTY}), the updating of a map
(\holtxt{FUPDATE}), the application of a map to an argument
(\holtxt{FAPPLY}), and the domain of a map (\holtxt{FDOM}) are the
main notions in the theory.
\begin{hol}
\begin{verbatim}
   FEMPTY  : 'a |-> 'b
   FUPDATE : ('a |-> 'b) -> 'a # 'b -> ('a |-> 'b)
   FAPPLY  : ('a |-> 'b) -> 'a -> 'b
   FDOM    : ('a |-> 'b) -> 'a set
\end{verbatim}
\end{hol}

The \HOL{} parser and printer will treat the syntax \verb+f ' x+ as
the application of finite map \verb+f+ to argument \verb+x+, ie, as
{\small\verb+FAPPLY f x+}. The notation \verb#f |+ (x,y)# represents
{\small\verb+FUPDATE f (x,y)+}, \ie, the updating of finite map
\verb+f+ by the pair \verb+(x,y)+.

The basic constants have obscure definitions, from which more useful
properties are then derived. {\small\verb+FAPPLY_FUPDATE_THM+} relates
map update with map application.  {\small\verb+fmap_EXT+} is an
extensionality result: two maps are equal if they have the same domain
and agree when applied to arguments in that domain. One can prove
properties of finite maps by induction on the construction of the map
({\small\verb+fmap_INDUCT+}).  The cardinality of a finite map is
just the cardinality of its domain ({\small\verb+FCARD_DEF+}); from
this a recursive characterization ({\small\verb+FCARD_FUPDATE+}) is
derived.
\begin{hol}
\begin{verbatim}
   FAPPLY_FUPDATE_THM
     |- !f a b x. (f |+ (a,b)) ' x = (if x = a then b else f ' x)
   fmap_EXT
     |- !f g. (f = g) =
              (FDOM f = FDOM g) /\ (!x. x IN FDOM f ==> (f ' x = g ' x))
   fmap_INDUCT
     |- !P. P FEMPTY /\
            (!f. P f ==> !x y. ~(x IN FDOM f) ==> P (f |+ (x,y))) ==> !f. P f
   FCARD_DEF  |- FCARD fm = CARD (FDOM fm)
   FCARD_FUPDATE
     |- !fm a b. FCARD(fm |+ (a,b)) =
                   if a IN FDOM fm then FCARD fm else 1 + FCARD fm
\end{verbatim}
\end{hol}
Iterated updates (\holtxt{FUPDATE\_LIST}) to a map are useful. The
infix notation \holtxt{|++} may also be used.  For example, \holtxt{fm
  |++ [(k1,v1); (k2,v2)]} is equal to \holtxt{(fm |+ (k1,v1)) |+
  (k2,v2)}.
\begin{hol}
\begin{verbatim}
   FUPDATE_LIST  |- FUPDATE_LIST = FOLDL FUPDATE
   FUPDATE_LIST_THM
     |- !f. (f |++ [] = f) /\
            (!h t. f |++ (h::t) = (f |+ h) |++ t)
\end{verbatim}
\end{hol}


\paragraph {Domain and range}

The domain of a finite map is the set of elements that it applies to;
this can be characterized recursively
({\small\verb+FDOM_FUPDATE+}). The range of a map is defined in the
usual way.
\begin{hol}
\begin{verbatim}
   FDOM_FUPDATE
     |- !f a b. FDOM (f |+ (a,b)) = a INSERT (FDOM f)
   FRANGE_DEF
     |- FRANGE f = {y | ?x. x IN FDOM f /\ (f ' x = y)}
\end{verbatim}
\end{hol}
%
A finite map may have its domain ({\small\verb+DRESTRICT+})
or range ({\small\verb+RRESTRICT+}) restricted by intersection with a
set. These notions have recursive versions as well
({\small\verb+DRESTRICT_FUPDATE+} and {\small\verb+RRESTRICT_FUPDATE+}).
%
\begin{hol}
\begin{verbatim}
   DRESTRICT_DEF
     |- !f r. (FDOM (DRESTRICT f r) = (FDOM f) INTER r) /\
              (!x. DRESTRICT f r ' x =
                     (if x IN ((FDOM f) INTER r) then f ' x else FEMPTY'x))
   RRESTRICT_DEF
     |- !f r. (FDOM (RRESTRICT f r) = {x | x IN FDOM f /\ f ' x IN r}) /\
              (!x. RRESTRICT f r ' x =
                     (if x IN (FDOM f) /\ f ' x IN r then f ' x
                      else FEMPTY ' x))
   DRESTRICT_FUPDATE
     |- !f r x y.
           DRESTRICT (f |+ (x,y)) r =
             if x IN r then (DRESTRICT f r) |+ (x,y) else DRESTRICT f r
   RRESTRICT_FUPDATE
     |- !f r x y.
           RRESTRICT (f |+ (x,y)) r =
             if y IN r then (RRESTRICT f r) |+ (x,y)
                       else RRESTRICT (DRESTRICT f (COMPL {x})) r)
\end{verbatim}
\end{hol}
The removal of a single element from the domain of a map
(\holtxt{\bs\bs}, infix) is a simple application of
(\holtxt{DRESTRICT}), but sufficiently useful to deserve its own
definition. Again, this concept has a alternate recursive presentation
(\holtxt{DOMSUB\_FUPDATE\_THM}).
%
\begin{hol}
\begin{verbatim}
   fmap_domsub
     |- (fm \\ k) = DRESTRICT fm (COMPL {k})
   DOMSUB_FUPDATE_THM
     |- !fm k1 k2 v. (fm |+ (k1,v)) \\ k2 =
                      if (k1 = k2) then (fm \\ k2) else (fm \\ k2) |+ (k1, v)
\end{verbatim}
\end{hol}

\paragraph {Union and sub-maps}

Unlike the union of sets, the union of two finite maps
(\holtxt{FUNION\_DEF}) is not symmetric: the domain of the first map
takes precedence. The notion of a finite map being a submap of another
(\holtxt{SUBMAP}, infix) is an extension of how subsets are
formalized.
\begin{hol}
\begin{verbatim}
   FUNION_DEF
     |- !f g.
          (FDOM (FUNION f g) = FDOM f UNION FDOM g) /\
          !x. FUNION f g ' x = (if x IN FDOM f then f ' x else g ' x)
   SUBMAP_DEF
     |- !f g. (f SUBMAP g) = (!x. x IN FDOM f ==> x IN FDOM g /\
                             (f ' x = g ' x))
\end{verbatim}
\end{hol}

\paragraph {Finite maps and functions}

As much as possible, finite maps should be like ordinary functions.
Thus, if \holtxt{f} is a finite map, then \holtxt{FAPPLY f} is an
ordinary function. Similarly, there is an operation for
\emph{totalizing} a finite map (\holtxt{lookup}) so that an
application of it returns an ordinary function, the range of which is
the option type.  An ordinary function can be turned into a finite map
by restricting the function to a finite set of arguments
(\ml{FUN\_FMAP\_DEF}).
%
\begin{hol}
\begin{verbatim}
   lookup_DEF
     |- FLOOKUP f x = (if x IN FDOM f then SOME (f ' x) else NONE)
   FUN_FMAP_DEF
     |- !f P. FINITE P ==>
             (FDOM (FUN_FMAP f P) = P) /\
             (!x. x IN P ==> (FUN_FMAP f P ' x = f x))
\end{verbatim}
\end{hol}

\paragraph {Composition of maps}
\index{function composition, in HOL logic@function composition, in \HOL{} logic!of finite maps}

There are three new definitions of composition, determined by whether
the composed functions are finite maps or not. The composition of two
finite maps (\verb+f_o_f+, infix) has domain constraints
attached. Composition of a finite map with an ordinary function
(\verb+o_f+, infix) applies the finite map first, then the ordinary
function.  Composition of an ordinary function with a finite map
(\verb+f_o+, infix) applies the ordinary function and then the finite
map; the application of the ordinary function is achieved by turning
it into a finite map.
%
\begin{hol}
\begin{verbatim}
   f_o_f_DEF
     |- !f g.
          (FDOM (f f_o_f g) = (FDOM g) INTER {x | g ' x IN FDOM f}) /\
          !x. x IN FDOM (f f_o_f g) ==> ((f f_o_f g) ' x = f ' (g ' x))
   o_f_DEF
     |- !f g.
          (FDOM (f o_f g) = FDOM g) /\
          !x. x IN FDOM (f o_f g) ==> ((f o_f g) ' x = f (g ' x))
   f_o_DEF
     |- (f f_o g) = f f_o_f (FUN_FMAP g {x | g x IN FDOM f})
\end{verbatim}
\end{hol}

\section{While loops}
\label{sec:while-loops}

It is a curious fact that higher order logic, although a logic of
total functions, allows the definition of functions that don't
seem total, at least from a computational perspective. An example
is \holtxt{WHILE}-loops. The following equation is derived in theory
\theoryimp{while}:
%
\begin{hol}
\begin{verbatim}
   WHILE  |- !P g x. WHILE P g x = if P x then WHILE P g (g x) else x
\end{verbatim}
\end{hol}
%
Clearly, if \holtxt{P} in this theorem was instantiated to $\lambda
x.\;\konst{T}$, the resulting instance of \holtxt{WHILE} would `run
forever' if executed. Why is such an ``obviously'' partial function
definable in HOL?
%
The answer lies in a subtle definition of \holtxt{WHILE},
\footnote{The original idea is due to Wolfgang Goerigk,
          who suggested it for use in ACL2.}
which uses the expressive power of HOL to surprising effect. Consider
the following total and non-recursive function:
%
\begin{hol}
\begin{verbatim}
  \x. if (?n. P (FUNPOW g n x))
       then FUNPOW g (@n. P (FUNPOW g n x) /\
                          !m.  m < n ==> ~P (FUNPOW g m x)) x
       else ARB
\end{verbatim}
\end{hol}
%
This function does a case analysis on the iterations of function
\holtxt{g}: the finite ones return the first value in the iteration at
which \holtxt{P} holds (\ie, when the iteration stops); the infinite
ones are mapped to \holtxt{ARB}. This function is used as the witness
for \verb+f+ in the proof of the following theorem:
%
\begin{hol}
\begin{verbatim}
   ITERATION
     |- !P g. ?f. !x. f x = if P x then x else f (g x)
\end{verbatim}
\end{hol}
%
From this, it is a simple application of Skolemization and
\holtxt{new\_specification} to obtain the equation for \holtxt{WHILE}.

\paragraph{Reasoning about \holtxt{WHILE} loops}

The induction theorem for \holtxt{WHILE} loops is proved by
wellfounded induction, and carries wellfoundedness constraints
limiting its application. In order to apply \verb+WHILE_INDUCTION+,
the instantiations for \verb+B+ and \verb+C+ must be known before
a wellfounded relation for \verb+R+ is found and used to eliminate the
constraints.
%
\begin{hol}
\begin{verbatim}
   WHILE_INDUCTION
     |- !B C R.
          WF R /\ (!s. B s ==> R (C s) s) ==>
          !P. (!s. (B s ==> P (C s)) ==> P s) ==> !v. P v
\end{verbatim}
\end{hol}
%
A more refined level of support is provided by the standard Hoare
Logic \holtxt{WHILE} rule, phrased in terms of Hoare triples
(\holtxt{HOARE\_SPEC}).
%
\begin{hol}
\begin{verbatim}
   HOARE_SPEC_DEF
     |- !P C Q. HOARE_SPEC P C Q = !s. P s ==> Q (C s)
   WHILE_RULE
     |- !R B C.
           WF R /\ (!s. B s ==> R (C s) s) ==>
           HOARE_SPEC (\s. P s /\ B s) C P ==>
           HOARE_SPEC P (WHILE B C) (\s. P s /\ ~B s)
\end{verbatim}
\end{hol}
%
As a follow-on, an operator for finding the least number with property
\verb+P+ is defined.
%
\begin{hol}
\begin{verbatim}
   LEAST_DEF  |- !P. $LEAST P = WHILE ($~ o P) SUC 0
\end{verbatim}
\end{hol}
%
A few theorems for reasoning about \holtxt{LEAST} may be found in
theory \theoryimp{while}.


\section{Partial orders}

\section{Further theories}
Other theories of interest in \HOL{} are listed and briefly described
in Figure~\ref{fig:further-hol-theories}.

\begin{figure}[hbtp]
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{p{0.2\textwidth}p{0.7\textwidth}}
\theoryimp{divides}, \theoryimp{gcd} &
Divisibility and the greatest common divisor.
\\
\theoryimp{poly} &
A theory of polynomials over $\mathbb{R}$, providing
a collection of operations on polynomials, and theorems about them.
\\
\theoryimp{Temporal\_Logic}, \theoryimp{Omega\_Automata}
&
Klaus Schneider's development of temporal logic and $\omega$-automata.
\\
\theoryimp{ctl}, \theoryimp{mu}
&
Computation Tree Logic and the $\mu$-calculus. See Hasan Amjad's
thesis.
\end{tabular}
\caption{A selection of \HOL{} theories}
\label{fig:further-hol-theories}
\end{figure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "description"
%%% End:
